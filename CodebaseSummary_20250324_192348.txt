This file is a comprehensive codebase snapshot for the OllamaModelEditor project, generated to facilitate analysis and development.

================================================================
File Summary
================================================================

Purpose:
--------
This document provides a consolidated view of the project's Python source code, 
excluding any files specified in the .gitignore file. It serves as a reference 
for developers, making it easier to understand the codebase structure and 
functionality in a single document.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
5. List of Program files
6. List of Documents

================================================================
Directory Structure
================================================================
.
├── ./AddThese
│   └── ./AddThese/IMPORTANT; add this to session starts.
├── ./AddTheseNow
├── ./Core
│   ├── ./Core/DatabaseIntegration.py
│   ├── ./Core/GitHubManager.py
│   └── ./Core/ProjectInitializer.py
├── ./Databases
├── ./Docs
│   ├── ./Docs/AIDEV-ProjectSetup Path.txt
│   ├── ./Docs/AIDEV-ProjectSetup Project Structure.md
│   ├── ./Docs/AIDEV-ProjectSetup: Session Continuity Document.md
│   ├── ./Docs/AIDEV-ProjectSetup Test Automation.md
│   ├── ./Docs/AIDEV-ProjectSetup: Test Plan.md
│   ├── ./Docs/API
│   ├── ./Docs/How to Test Manually.txt
│   ├── ./Docs/KnowledgeDatabaseIndex
│   │   ├── ./Docs/KnowledgeDatabaseIndex/00-00 INDEX-DocumentMaster.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/00-10 GUIDE-DocumentMap.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/00-20 STATUS-ProjectHimalaya.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/00-40 LOG-Decisions.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/00-60 GUIDE-ActiveSessions.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/10-10 Project Himalaya: Strategic Roadmap & Evolution Plan.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/10-20 Project Himalaya: Vision Document.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/10-30 Project Himalaya: Comprehensive Scope Definition.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/10-40 Project Himalaya: Comprehensive Scope Definition.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/20-10 STANDARD-AIDEV-PascalCase Standards 1.6.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/20-20 STANDARD-AUTHORSHIP.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/20-30 STANDARD-FoundationDesignPrinciples.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/20-40 SPEC-DocumentManager.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/20-50 STANDARD-DatabaseSchema.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/30-10 TEMPLATE-Component Plan.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/30-20 SPEC-[ComponentName].md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/30-30 REF-[SubProjectName].md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/30-40 TEMPLATE-Project Himalaya: Session Continuity.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/40-20 Project Knowledge Database Structure.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/40-30 STANDARD-MetadataSchema.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/50-10 IMPL-DocumentManager.md
│   │   ├── ./Docs/KnowledgeDatabaseIndex/60-50a STANDARD-AutomatedTesting.md
│   │   └── ./Docs/KnowledgeDatabaseIndex/60-50 TEMPLATE-TestCase.md
│   └── ./Docs/Notes
│       └── ./Docs/Notes/2024-03-21
├── ./GUI
│   └── ./GUI/DirectoryEditor.py.py
├── ./license.txt
├── ./readme.md
├── ./requirements.txt
├── ./Resources
│   ├── ./Resources/Icons
│   │   └── ./Resources/Icons/BowersWorld Icon  (Ttrans).png
│   └── ./Resources/Templates
│       ├── ./Resources/Templates/gitignore.template
│       ├── ./Resources/Templates/LICENSE.template
│       ├── ./Resources/Templates/README.md.template
│       └── ./Resources/Templates/requirements-txt.txt
├── ./Scripts
├── ./setup_templates_script.sh
├── ./setup_templates.sh
├── ./SysUtils
│   ├── ./SysUtils/AIDEV-DocMManager_Setup.py
│   ├── ./SysUtils/BuildDirectories.py
│   ├── ./SysUtils/CodebaseSummary.sh
│   ├── ./SysUtils/GitPushUpdates.sh
│   ├── ./SysUtils/MyDiff.py
│   └── ./SysUtils/PushGitHub.sh
├── ./TestDatabaseIntegration.py
├── ./TestReports
│   ├── ./TestReports/assets
│   │   └── ./TestReports/assets/style.css
│   ├── ./TestReports/db_report_20250324_172025.txt
│   ├── ./TestReports/html_report_2025-03-24.html
│   └── ./TestReports/test_report_2025-03-24.txt
├── ./Tests
│   ├── ./Tests/conftest.py
│   ├── ./Tests/Integration
│   └── ./Tests/Unit
│       ├── ./Tests/Unit/test_database_integration.py
│       ├── ./Tests/Unit/test_integration.py
│       └── ./Tests/Unit/test_project_setup.py
├── ./UI
└── ./Utils
    ├── ./Utils/ConfigManager.py
    └── ./Utils/DirectoryParser.py

23 directories, 61 files

================================================================
Files
================================================================

================
File: Core/DatabaseIntegration.py
================
# File: DatabaseIntegration.py
# Path: AIDEV-ProjectSetup/Core/DatabaseIntegration.py
# Standard: AIDEV-PascalCase-1.6
# Created: 2025-03-23
# Last Modified: 2025-03-24  1:15PM
# Description: Database integration functionality

"""
Database integration functionality.

This module provides functionality for interacting with the Himalaya database
and setting up project-specific databases.
"""

import os
import sqlite3
from pathlib import Path
from datetime import datetime
import platform

class DatabaseIntegration:
    """Database integration functionality."""
    
    def __init__(self, ConfigManager):
        """
        Initialize DatabaseIntegration.
        
        Args:
            ConfigManager: Configuration manager instance
        """
        self.Config = ConfigManager
        self.HimalayaDbPath = self.Config.Get('DatabasePath')
        
        # Initialize Himalaya database if it doesn't exist
        self.InitializeHimalayaDatabase()
    
    def InitializeHimalayaDatabase(self):
        """Initialize Himalaya core database if it doesn't exist."""
        if not os.path.exists(self.HimalayaDbPath):
            try:
                # Ensure parent directory exists
                os.makedirs(os.path.dirname(self.HimalayaDbPath), exist_ok=True)
                
                # Connect to database (creates if not exists)
                Connection = sqlite3.connect(self.HimalayaDbPath)
                Cursor = Connection.cursor()
                
                # Create core tables according to the schema in STANDARD-DatabaseSchema.md
                self.CreateProjectTable(Cursor)
                self.CreateComponentTable(Cursor)
                self.CreateStandardTable(Cursor)
                self.CreateValidationRuleTable(Cursor)
                
                # Commit changes
                Connection.commit()
                Connection.close()
                
                print(f"Initialized Himalaya database at {self.HimalayaDbPath}")
                
            except Exception as E:
                print(f"Error initializing Himalaya database: {str(E)}")
    
    def CreateProjectTable(self, Cursor):
        """Create project table in Himalaya database."""
        Cursor.execute('''
        CREATE TABLE IF NOT EXISTS project (
            project_id TEXT PRIMARY KEY,
            name TEXT NOT NULL,
            description TEXT NOT NULL,
            path TEXT NOT NULL,
            created_at TEXT NOT NULL,
            updated_at TEXT NOT NULL,
            version INTEGER NOT NULL DEFAULT 1,
            is_active INTEGER NOT NULL DEFAULT 1,
            
            UNIQUE(name)
        )
        ''')
    
    def CreateComponentTable(self, Cursor):
        """Create component table in Himalaya database."""
        Cursor.execute('''
        CREATE TABLE IF NOT EXISTS component (
            component_id TEXT PRIMARY KEY,
            project_id_fk TEXT NOT NULL,
            name TEXT NOT NULL,
            type TEXT NOT NULL,
            layer INTEGER NOT NULL,
            description TEXT NOT NULL,
            created_at TEXT NOT NULL,
            updated_at TEXT NOT NULL,
            version INTEGER NOT NULL DEFAULT 1,
            is_active INTEGER NOT NULL DEFAULT 1,
            
            FOREIGN KEY (project_id_fk) REFERENCES project(project_id),
            UNIQUE(project_id_fk, name)
        )
        ''')
    
    def CreateStandardTable(self, Cursor):
        """Create standard table in Himalaya database."""
        Cursor.execute('''
        CREATE TABLE IF NOT EXISTS standard (
            standard_id TEXT PRIMARY KEY,
            name TEXT NOT NULL,
            version TEXT NOT NULL,
            description TEXT NOT NULL,
            content TEXT NOT NULL,
            created_at TEXT NOT NULL,
            updated_at TEXT NOT NULL,
            is_active INTEGER NOT NULL DEFAULT 1,
            
            UNIQUE(name, version)
        )
        ''')
    
    def CreateValidationRuleTable(self, Cursor):
        """Create validation rule table in Himalaya database."""
        Cursor.execute('''
        CREATE TABLE IF NOT EXISTS validation_rule (
            rule_id TEXT PRIMARY KEY,
            standard_id_fk TEXT NOT NULL,
            name TEXT NOT NULL,
            description TEXT NOT NULL,
            rule_type TEXT NOT NULL,
            rule_pattern TEXT NOT NULL,
            severity TEXT NOT NULL,
            created_at TEXT NOT NULL,
            updated_at TEXT NOT NULL,
            is_active INTEGER NOT NULL DEFAULT 1,
            
            FOREIGN KEY (standard_id_fk) REFERENCES standard(standard_id),
            UNIQUE(standard_id_fk, name)
        )
        ''')
    
    def InitializeProjectDatabase(self, DbPath, ProjectConfig):
        """
        Initialize project-specific database.
        
        Args:
            DbPath: Path to project database
            ProjectConfig: Project configuration
            
        Returns:
            bool: True if initialization was successful
        """
        try:
            # Ensure parent directory exists
            os.makedirs(os.path.dirname(DbPath), exist_ok=True)
            
            # Connect to database (creates if not exists)
            Connection = sqlite3.connect(DbPath)
            Cursor = Connection.cursor()
            
            # Enable foreign keys
            Cursor.execute("PRAGMA foreign_keys = ON")
            
            # Create schema version table first
            Cursor.execute('''
            CREATE TABLE IF NOT EXISTS schema_version (
                version INTEGER PRIMARY KEY,
                applied_at TEXT NOT NULL,
                description TEXT NOT NULL
            )
            ''')
            
            # Insert initial schema version
            Cursor.execute(
                "INSERT OR IGNORE INTO schema_version (version, applied_at, description) VALUES (?, ?, ?)",
                (1, datetime.now().isoformat(), "Initial schema creation")
            )
            
            # Create core tables
            self.CreateProjectConfigTable(Cursor)
            self.CreateDocumentationTable(Cursor)
            self.CreateHelpContentTable(Cursor)
            self.CreateProjectStateTable(Cursor)
            self.CreateSubProjectsTable(Cursor)
            
            # Insert initial data
            self.InsertInitialData(Cursor, ProjectConfig)
            
            # Commit changes
            Connection.commit()
            Connection.close()
            
            return True
            
        except Exception as E:
            print(f"Error initializing project database: {str(E)}")
            return False
    
    def CreateProjectConfigTable(self, Cursor):
        """
        Create project configuration table.
        
        Args:
            Cursor: Database cursor
        """
        Cursor.execute('''
        CREATE TABLE IF NOT EXISTS ProjectConfig (
            ConfigId INTEGER PRIMARY KEY AUTOINCREMENT,
            ConfigKey TEXT NOT NULL UNIQUE,
            ConfigValue TEXT NOT NULL,
            ConfigType TEXT NOT NULL,
            Description TEXT,
            LastModified TEXT NOT NULL
        )
        ''')
    
    def CreateDocumentationTable(self, Cursor):
        """
        Create documentation table.
        
        Args:
            Cursor: Database cursor
        """
        Cursor.execute('''
        CREATE TABLE IF NOT EXISTS Documentation (
            DocId INTEGER PRIMARY KEY AUTOINCREMENT,
            DocType TEXT NOT NULL,
            Title TEXT NOT NULL,
            Content TEXT NOT NULL,
            Format TEXT NOT NULL,
            Tags TEXT,
            CreationDate TEXT NOT NULL,
            LastModified TEXT NOT NULL
        )
        ''')
    
    def CreateHelpContentTable(self, Cursor):
        """
        Create help content table.
        
        Args:
            Cursor: Database cursor
        """
        Cursor.execute('''
        CREATE TABLE IF NOT EXISTS HelpContent (
            HelpId INTEGER PRIMARY KEY AUTOINCREMENT,
            Topic TEXT NOT NULL,
            Content TEXT NOT NULL,
            Keywords TEXT,
            RelatedTopics TEXT,
            ContextTriggers TEXT,
            LastModified TEXT NOT NULL
        )
        ''')
    
    def CreateProjectStateTable(self, Cursor):
        """
        Create project state table.
        
        Args:
            Cursor: Database cursor
        """
        Cursor.execute('''
        CREATE TABLE IF NOT EXISTS ProjectState (
            StateId INTEGER PRIMARY KEY AUTOINCREMENT,
            StateName TEXT NOT NULL,
            CurrentPhase TEXT NOT NULL,
            StateData TEXT NOT NULL,
            CreationDate TEXT NOT NULL,
            LastModified TEXT NOT NULL
        )
        ''')
    
    def CreateSubProjectsTable(self, Cursor):
        """
        Create sub-projects table.
        
        Args:
            Cursor: Database cursor
        """
        Cursor.execute('''
        CREATE TABLE IF NOT EXISTS SubProjects (
            SubProjectId INTEGER PRIMARY KEY AUTOINCREMENT,
            SubProjectName TEXT NOT NULL,
            GitHubRepo TEXT,
            Relationship TEXT NOT NULL,
            Active INTEGER NOT NULL DEFAULT 1
        )
        ''')
    
    def InsertInitialData(self, Cursor, ProjectConfig):
        """
        Insert initial data into the database.
        
        Args:
            Cursor: Database cursor
            ProjectConfig: Project configuration
        """
        # Current timestamp
        Now = datetime.now().isoformat()
        
        # Insert project configuration
        Cursor.execute(
            """
            INSERT INTO ProjectConfig 
            (ConfigKey, ConfigValue, ConfigType, Description, LastModified)
            VALUES (?, ?, ?, ?, ?)
            """,
            ('ProjectName', ProjectConfig.get('ProjectName', ''), 'STRING', 
             'Project name', Now)
        )
        
        Cursor.execute(
            """
            INSERT INTO ProjectConfig 
            (ConfigKey, ConfigValue, ConfigType, Description, LastModified)
            VALUES (?, ?, ?, ?, ?)
            """,
            ('ProjectDescription', ProjectConfig.get('Description', ''), 'STRING', 
             'Project description', Now)
        )
        
        Cursor.execute(
            """
            INSERT INTO ProjectConfig 
            (ConfigKey, ConfigValue, ConfigType, Description, LastModified)
            VALUES (?, ?, ?, ?, ?)
            """,
            ('GitHubRepo', f"{ProjectConfig.get('GitHubAccount', '')}/{ProjectConfig.get('RepositoryName', '')}", 
             'STRING', 'GitHub repository', Now)
        )
        
        # Insert initial project state
        Cursor.execute(
            """
            INSERT INTO ProjectState 
            (StateName, CurrentPhase, StateData, CreationDate, LastModified)
            VALUES (?, ?, ?, ?, ?)
            """,
            ('Initial', 'Setup', '{}', Now, Now)
        )
        
        # Insert initial documentation
        Cursor.execute(
            """
            INSERT INTO Documentation 
            (DocType, Title, Content, Format, Tags, CreationDate, LastModified)
            VALUES (?, ?, ?, ?, ?, ?, ?)
            """,
            ('Setup', 'Project Setup Documentation', 
             f"# {ProjectConfig.get('ProjectName', '')}\n\nProject setup completed on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.", 
             'Markdown', 'setup,documentation', Now, Now)
        )
    
    def CreateDatabaseLink(self, ProjectPath, ProjectConfig):
        """
        Create symbolic link to Himalaya database.
        
        Args:
            ProjectPath: Path to project directory
            ProjectConfig: Project configuration
            
        Returns:
            bool: True if link creation was successful
        """
        try:
            # Target directory for link
            DirectoriesPath = ProjectPath / 'Directories'
            DirectoriesPath.mkdir(exist_ok=True)
            
            # Link path
            LinkPath = DirectoriesPath / 'Himalaya.db'
            
            # Check if we're running on Windows
            if platform.system() == 'Windows':
                # Windows requires admin privileges for symlinks, use copy instead
                import shutil
                shutil.copy2(self.HimalayaDbPath, LinkPath)
                print(f"Created copy of Himalaya database at {LinkPath}")
            else:
                # Create symbolic link
                if LinkPath.exists():
                    LinkPath.unlink()
                os.symlink(self.HimalayaDbPath, LinkPath)
                print(f"Created symbolic link to Himalaya database at {LinkPath}")
            
            return True
            
        except Exception as E:
            print(f"Error creating database link: {str(E)}")
            return False
    
    def RegisterProject(self, ProjectConfig):
        """
        Register project in Himalaya database.
        
        Args:
            ProjectConfig: Project configuration
            
        Returns:
            bool: True if registration was successful
        """
        try:
            # Connect to Himalaya database
            Connection = sqlite3.connect(self.HimalayaDbPath)
            Cursor = Connection.cursor()
            
            # Enable foreign keys
            Cursor.execute("PRAGMA foreign_keys = ON")
            
            # Check if projects table exists, create if not
            Cursor.execute('''
            CREATE TABLE IF NOT EXISTS project (
                project_id TEXT PRIMARY KEY,
                name TEXT NOT NULL,
                description TEXT NOT NULL,
                path TEXT NOT NULL,
                created_at TEXT NOT NULL,
                updated_at TEXT NOT NULL,
                version INTEGER NOT NULL DEFAULT 1,
                is_active INTEGER NOT NULL DEFAULT 1,
                
                UNIQUE(name)
            )
            ''')
            
            # Generate unique project ID
            import uuid
            ProjectId = f"project-{uuid.uuid4().hex[:8]}"
            
            # Current timestamp
            Now = datetime.now().isoformat()
            
            # Insert project
            Cursor.execute(
                """
                INSERT OR REPLACE INTO project 
                (project_id, name, description, path, created_at, updated_at, version, is_active)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    ProjectId, 
                    ProjectConfig.get('ProjectName', ''),
                    ProjectConfig.get('Description', ''),
                    str(Path(ProjectConfig.get('ProjectPath', '')) / ProjectConfig.get('ProjectName', '')),
                    Now,
                    Now,
                    1,
                    1
                )
            )
            
            # Commit changes
            Connection.commit()
            Connection.close()
            
            return True
            
        except Exception as E:
            print(f"Error registering project in Himalaya database: {str(E)}")
            return False

================
File: Core/GitHubManager.py
================
# File: GitHubManager.py
# Path: AIDEV-ProjectSetup/Core/GitHubManager.py
# Standard: AIDEV-PascalCase-1.6
# Created: 2025-03-23
# Last Modified: 2025-03-23  1:10PM
# Description: GitHub repository management functionality

"""
GitHub repository management functionality.

This module provides functionality for interacting with GitHub repositories,
including validation, creation, and updating.
"""

import os
import subprocess
import requests
from pathlib import Path

class GitHubManager:
    """GitHub repository management functionality."""
    
    def __init__(self, ConfigManager):
        """
        Initialize GitHubManager.
        
        Args:
            ConfigManager: Configuration manager instance
        """
        self.Config = ConfigManager
    
    def ValidateRepository(self, Account, RepoName, Token=None):
        """
        Validate GitHub repository.
        
        Args:
            Account: GitHub account name
            RepoName: Repository name
            Token: GitHub PAT (optional)
            
        Returns:
            dict: Validation results with status and message
        """
        # Use token from config if not provided
        if not Token:
            Token = self.Config.GetGitHubToken()
        
        # Prepare headers
        Headers = {}
        if Token:
            Headers['Authorization'] = f"token {Token}"
        
        # Check if repository exists
        Url = f"https://api.github.com/repos/{Account}/{RepoName}"
        try:
            Response = requests.get(Url, headers=Headers)
            
            if Response.status_code == 404:
                # Repository doesn't exist
                return {
                    'Status': 'NotFound',
                    'Message': f"Repository {Account}/{RepoName} not found. You'll need to create it first."
                }
            
            if Response.status_code != 200:
                # Error checking repository
                return {
                    'Status': 'Error',
                    'Message': f"Error checking repository: {Response.status_code} - {Response.text}"
                }
            
            # Repository exists, check if it's empty
            RepoData = Response.json()
            if RepoData.get('size', 0) > 0:
                # Repository is not empty
                return {
                    'Status': 'NotEmpty',
                    'Message': f"Repository {Account}/{RepoName} is not empty. Please use an empty repository."
                }
            
            # Repository exists and is empty
            return {
                'Status': 'Valid',
                'Message': f"Repository {Account}/{RepoName} is valid and empty."
            }
            
        except Exception as E:
            return {
                'Status': 'Error',
                'Message': f"Error validating repository: {str(E)}"
            }
    
    def PushToRemote(self, ProjectPath, Account, RepoName, Token):
        """
        Push to remote GitHub repository.
        
        Args:
            ProjectPath: Path to project directory
            Account: GitHub account name
            RepoName: Repository name
            Token: GitHub personal access token
            
        Returns:
            bool: True if push was successful
        """
        try:
            # Create URL with token for push
            RemoteUrl = f"https://{Account}:{Token}@github.com/{Account}/{RepoName}.git"
            
            # Set remote URL with token
            subprocess.run(
                ['git', 'remote', 'set-url', 'origin', RemoteUrl],
                cwd=ProjectPath,
                check=True,
                capture_output=True  # Hide output to avoid showing token
            )
            
            # Push to remote
            Result = subprocess.run(
                ['git', 'push', '-u', 'origin', 'master'], 
                cwd=ProjectPath,
                check=True,
                capture_output=True
            )
            
            # Reset remote URL without token
            PublicRemoteUrl = f"https://github.com/{Account}/{RepoName}.git"
            subprocess.run(
                ['git', 'remote', 'set-url', 'origin', PublicRemoteUrl],
                cwd=ProjectPath,
                check=True,
                capture_output=True
            )
            
            return True
            
        except subprocess.CalledProcessError as E:
            print(f"Error pushing to remote: {E.stderr.decode('utf-8')}")
            return False
        except Exception as E:
            print(f"Error pushing to remote: {str(E)}")
            return False
    
    def CreateRepository(self, Account, RepoName, Description, Token):
        """
        Create new GitHub repository.
        
        Args:
            Account: GitHub account name
            RepoName: Repository name
            Description: Repository description
            Token: GitHub personal access token
            
        Returns:
            dict: Creation results with status and message
        """
        # Prepare headers
        Headers = {
            'Authorization': f"token {Token}",
            'Accept': 'application/vnd.github.v3+json'
        }
        
        # Prepare data
        Data = {
            'name': RepoName,
            'description': Description,
            'private': False,
            'auto_init': False
        }
        
        # Create repository
        Url = f"https://api.github.com/user/repos"
        try:
            Response = requests.post(Url, headers=Headers, json=Data)
            
            if Response.status_code != 201:
                return {
                    'Status': 'Error',
                    'Message': f"Error creating repository: {Response.status_code} - {Response.text}"
                }
            
            return {
                'Status': 'Created',
                'Message': f"Repository {Account}/{RepoName} created successfully."
            }
            
        except Exception as E:
            return {
                'Status': 'Error',
                'Message': f"Error creating repository: {str(E)}"
            }
    
    def CreateUpdateScript(self, ProjectPath):
        """
        Create update script for the project.
        
        Args:
            ProjectPath: Path to project directory
            
        Returns:
            Path: Path to created script
        """
        ScriptPath = ProjectPath / 'Scripts' / 'update-repo.sh'
        
        # Ensure Scripts directory exists
        (ProjectPath / 'Scripts').mkdir(exist_ok=True)
        
        # Create script content
        Content = """#!/bin/bash
# update-repo.sh - Script for updating repository
# Created by AIDEV-ProjectSetup

# Get current date in MM/DD/YY format
DATE=$(date +"%m/%d/%y %I:%M%p")

# Default commit message
DEFAULT_MESSAGE="Update $DATE"

# Use provided message or default
MESSAGE=${1:-$DEFAULT_MESSAGE}

echo "Committing changes with message: $MESSAGE"

# Add all files to staging
git add .

# Commit changes
git commit -m "$MESSAGE"

# Push to remote
git push

echo "Repository updated successfully."
"""
        
        # Write script file
        with open(ScriptPath, 'w') as File:
            File.write(Content)
        
        # Make script executable
        os.chmod(ScriptPath, 0o755)
        
        return ScriptPath

================
File: Core/ProjectInitializer.py
================
# File: ProjectInitializer.py
# Path: AIDEV-ProjectSetup/Core/ProjectInitializer.py
# Standard: AIDEV-PascalCase-1.6
# Created: 2025-03-23
# Last Modified: 2025-03-24  1:30PM
# Description: Core project initialization functionality

"""
Core project initialization functionality.

This module provides the main functionality for initializing new projects,
including directory structure creation, database setup, and GitHub integration.
"""

import os
import subprocess
import shutil
import sqlite3
from pathlib import Path
from datetime import datetime
from string import Template

from Core.GitHubManager import GitHubManager
from Core.DatabaseIntegration import DatabaseIntegration
from Utils.DirectoryParser import DirectoryParser

class ProjectInitializer:
    """Project initialization functionality."""
    
    def __init__(self, ConfigManager):
        """
        Initialize ProjectInitializer.
        
        Args:
            ConfigManager: Configuration manager instance
        """
        self.Config = ConfigManager
        self.GitHubManager = GitHubManager(ConfigManager)
        self.DatabaseIntegration = DatabaseIntegration(ConfigManager)
        self.DirectoryParser = DirectoryParser()
    
    def InitializeProject(self, ProjectConfig):
        """
        Initialize a new project.
        
        Args:
            ProjectConfig: Project configuration dictionary
            
        Returns:
            bool: True if initialization was successful
        """
        try:
            # Extract configuration
            ProjectName = ProjectConfig.get('ProjectName')
            ProjectPath = ProjectConfig.get('ProjectPath')
            if not ProjectPath:
                return False
            
            # Create full project path - ensure Path object is used
            ProjectPath = Path(ProjectPath)
            FullProjectPath = ProjectPath / ProjectName
            
            # Check if project directory already exists
            if FullProjectPath.exists():
                print(f"Project directory already exists: {FullProjectPath}")
                return False
            
            # Create project directory
            FullProjectPath.mkdir(parents=True, exist_ok=True)
            
            # Create directory structure
            self.CreateDirectoryStructure(FullProjectPath, ProjectConfig)
            
            # Setup project database
            self.SetupDatabase(FullProjectPath, ProjectConfig)
            
            # Create initial files
            self.CreateInitialFiles(FullProjectPath, ProjectConfig)
            
            # Initialize git repository
            self.InitializeGit(FullProjectPath, ProjectConfig)
            
            # Register project in Himalaya database
            self.RegisterProject(ProjectConfig)
            
            return True
            
        except Exception as E:
            print(f"Error initializing project: {str(E)}")
            return False
    
    def CreateDirectoryStructure(self, ProjectPath, ProjectConfig):
        """
        Create directory structure for project.
        
        Args:
            ProjectPath: Full path to project directory
            ProjectConfig: Project configuration
        """
        # Get directory structure from config
        Structure = ProjectConfig.get('DirectoryStructure')
        
        if not Structure:
            # Use default structure
            Content = self.Config.Get('DefaultStructure')
            Structure = self.DirectoryParser.ParseStructure(Content)
        
        # Create directories
        self.CreateDirectories(ProjectPath, Structure)
        
        # Create special directories
        DirectoriesPath = ProjectPath / 'Directories'
        DirectoriesPath.mkdir(exist_ok=True)
    
    def CreateDirectories(self, BasePath, Structure, CurrentPath=None):
        """
        Recursively create directories from structure.
        
        Args:
            BasePath: Base project path
            Structure: Directory structure dictionary
            CurrentPath: Current path for recursion
        """
        if CurrentPath is None:
            CurrentPath = BasePath
        
        for Name, Children in Structure.items():
            # Skip files
            if '.' in Name and not Name.startswith('.'):
                continue
            
            # Create directory
            NewPath = CurrentPath / Name
            NewPath.mkdir(exist_ok=True)
            
            # Process children
            if Children:
                self.CreateDirectories(BasePath, Children, NewPath)
    
    def SetupDatabase(self, ProjectPath, ProjectConfig):
        """
        Setup project database.
        
        Args:
            ProjectPath: Full path to project directory
            ProjectConfig: Project configuration
        """
        ProjectName = ProjectConfig.get('ProjectName')
        
        # Create project database
        DirectoriesPath = ProjectPath / 'Directories'
        DirectoriesPath.mkdir(exist_ok=True)
        ProjectDbPath = DirectoriesPath / f"{ProjectName}.db"
        
        # Initialize database
        self.DatabaseIntegration.InitializeProjectDatabase(ProjectDbPath, ProjectConfig)
        
        # Create symbolic link to Himalaya database
        self.DatabaseIntegration.CreateDatabaseLink(ProjectPath, ProjectConfig)
    
    def CreateInitialFiles(self, ProjectPath, ProjectConfig):
        """
        Create initial project files.
        
        Args:
            ProjectPath: Full path to project directory
            ProjectConfig: Project configuration
        """
        # Get template path - ensure it's a Path object
        TemplatesPath = Path(self.Config.Get('TemplatesPath'))
        
        # Create README.md
        self.CreateFileFromTemplate(
            TemplatesPath / 'README.md.template',
            ProjectPath / 'README.md',
            ProjectConfig
        )
        
        # Create LICENSE
        self.CreateFileFromTemplate(
            TemplatesPath / 'LICENSE.template',
            ProjectPath / 'LICENSE',
            ProjectConfig
        )
        
        # Create .gitignore
        self.CreateFileFromTemplate(
            TemplatesPath / 'gitignore.template',
            ProjectPath / '.gitignore',
            ProjectConfig
        )
        
        # Create initial requirements.txt
        with open(ProjectPath / 'requirements.txt', 'w') as File:
            File.write("# Project dependencies\n")
            File.write("# Add your dependencies here\n")
            File.write("sqlite3\n")
            File.write("pyside6\n")
            File.write("python-dotenv\n")
    
    def CreateFileFromTemplate(self, TemplatePath, OutputPath, ProjectConfig):
        """
        Create file from template.
        
        Args:
            TemplatePath: Path to template file
            OutputPath: Path to output file
            ProjectConfig: Project configuration
        """
        # If template doesn't exist, create with hardcoded defaults
        if not os.path.exists(TemplatePath):
            print(f"Template file not found: {TemplatePath}")
            if TemplatePath.name == 'README.md.template':
                self.CreateDefaultReadme(OutputPath, ProjectConfig)
            elif TemplatePath.name == 'LICENSE.template':
                self.CreateDefaultLicense(OutputPath, ProjectConfig)
            elif TemplatePath.name == 'gitignore.template':
                self.CreateDefaultGitignore(OutputPath)
            return
        
        try:
            # Read template
            with open(TemplatePath, 'r') as File:
                TemplateContent = File.read()
            
            # Prepare template variables
            TemplateVars = {
                'ProjectName': ProjectConfig.get('ProjectName', ''),
                'Description': ProjectConfig.get('Description', ''),
                'Author': 'Herbert J. Bowers',
                'Date': datetime.now().strftime('%Y-%m-%d'),
                'Year': datetime.now().strftime('%Y'),
                'GitHubAccount': ProjectConfig.get('GitHubAccount', ''),
                'RepositoryName': ProjectConfig.get('RepositoryName', '')
            }
            
            # Apply template
            Template_ = Template(TemplateContent)
            Content = Template_.safe_substitute(TemplateVars)
            
            # Write output file
            with open(OutputPath, 'w') as File:
                File.write(Content)
                
        except Exception as E:
            print(f"Error creating file from template: {str(E)}")
    
    def CreateDefaultReadme(self, OutputPath, ProjectConfig):
        """Create default README.md if template is missing."""
        Content = f"""# {ProjectConfig.get('ProjectName', '')}

## Overview

{ProjectConfig.get('Description', '')}

## Project Structure

This project follows the Project Himalaya organization standards.

## Installation

1. Clone the repository:
   ```
   git clone https://github.com/{ProjectConfig.get('GitHubAccount', '')}/{ProjectConfig.get('RepositoryName', '')}.git
   ```

2. Install dependencies:
   ```
   pip install -r requirements.txt
   ```

## License

This project is licensed under the terms specified in the LICENSE file.

## Author

Herbert J. Bowers

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers
"""
        with open(OutputPath, 'w') as File:
            File.write(Content)
    
    def CreateDefaultLicense(self, OutputPath, ProjectConfig):
        """Create default LICENSE if template is missing."""
        Content = f"""MIT License

Copyright (c) {datetime.now().strftime('%Y')} Herbert J. Bowers

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
"""
        with open(OutputPath, 'w') as File:
            File.write(Content)
    
    def CreateDefaultGitignore(self, OutputPath):
        """Create default .gitignore if template is missing."""
        Content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
*.manifest
*.spec

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Unit test / coverage reports
htmlcov/
.tox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# IDE specific files
.idea/
.vscode/
*.swp
*.swo

# OS specific files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Project specific
**/local_settings.py
db.sqlite3
"""
        with open(OutputPath, 'w') as File:
            File.write(Content)
    
    def InitializeGit(self, ProjectPath, ProjectConfig):
        """
        Initialize Git repository.
        
        Args:
            ProjectPath: Full path to project directory
            ProjectConfig: Project configuration
        """
        try:
            # Initialize repository
            subprocess.run(['git', 'init'], cwd=ProjectPath, check=True)
            
            # Add all files
            subprocess.run(['git', 'add', '.'], cwd=ProjectPath, check=True)
            
            # Initial commit
            CommitMessage = f"Initial commit for {ProjectConfig.get('ProjectName')}"
            subprocess.run(['git', 'commit', '-m', CommitMessage], cwd=ProjectPath, check=True)
            
            # Add remote if GitHub settings are provided
            GitHubAccount = ProjectConfig.get('GitHubAccount')
            RepoName = ProjectConfig.get('RepositoryName')
            if GitHubAccount and RepoName:
                RemoteUrl = f"https://github.com/{GitHubAccount}/{RepoName}.git"
                subprocess.run(['git', 'remote', 'add', 'origin', RemoteUrl], cwd=ProjectPath, check=True)
                
                # Push to remote if GitHub PAT is provided
                GitHubPAT = ProjectConfig.get('GitHubPAT') or self.Config.GetGitHubToken()
                if GitHubPAT:
                    self.GitHubManager.PushToRemote(ProjectPath, GitHubAccount, RepoName, GitHubPAT)
        
        except Exception as E:
            print(f"Error initializing Git repository: {str(E)}")
    
    def RegisterProject(self, ProjectConfig):
        """
        Register project in Himalaya database.
        
        Args:
            ProjectConfig: Project configuration
        """
        self.DatabaseIntegration.RegisterProject(ProjectConfig)

================
File: ..Exclude/conftest.py
================
# File: conftest.py
# Path: Tests/conftest.py
# Standard: AIDEV-PascalCase-1.6
# Created: March 24, 2025
# Last Modified: March 24, 2025  4:20PM
# Description: pytest configuration for Project Himalaya tests

"""
pytest configuration for Project Himalaya tests.

This module contains fixtures and hooks for pytest that apply to all
test modules in the Project Himalaya framework.
"""

import os
import sys
import pytest
from pathlib import Path
from datetime import datetime


def pytest_configure(config):
    """Configure pytest settings for Project Himalaya."""
    # Register custom markers
    config.addinivalue_line(
        "markers", 
        "database: marks tests that interact with databases"
    )
    config.addinivalue_line(
        "markers", 
        "integration: marks tests that require multiple components"
    )
    
    # Set default HTML report path if --html not specified
    if not config.getoption("--html", None):
        ReportDir = Path("TestReports")
        ReportDir.mkdir(exist_ok=True)
        Timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        HtmlReportPath = ReportDir / f"html_report_{Timestamp}.html"
        config.option.htmlpath = str(HtmlReportPath)


def pytest_terminal_summary(terminalreporter, exitstatus, config):
    """Generate custom text report after tests complete."""
    # Create timestamped report filename
    Timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    ReportDir = Path("TestReports")
    ReportDir.mkdir(exist_ok=True)
    TextReportPath = ReportDir / f"test_report_{Timestamp}.txt"
    
    # Write report using test results
    with open(TextReportPath, "w") as File:
        # Write header
        File.write("=" * 80 + "\n")
        File.write("PROJECT HIMALAYA TEST REPORT\n")
        File.write("=" * 80 + "\n")
        File.write(f"Generated: {datetime.now().isoformat()}\n")
        File.write(f"Test Status: {'PASSED' if exitstatus == 0 else 'FAILED'}\n\n")
        
        # Write test summary
        Stats = terminalreporter.stats
        File.write("Test Summary:\n")
        File.write("-" * 40 + "\n")
        File.write(f"Total tests: {sum(len(x) for x in Stats.values())}\n")
        File.write(f"Passed tests: {len(Stats.get('passed', []))}\n")
        File.write(f"Failed tests: {len(Stats.get('failed', []))}\n")
        File.write(f"Skipped tests: {len(Stats.get('skipped', []))}\n")
        
        # Calculate session duration - end time minus start time
        import time
        SessionDuration = time.time() - terminalreporter._sessionstarttime
        File.write(f"Execution time: {SessionDuration:.2f} seconds\n\n")
        
        # Write test details
        File.write("Test Details:\n")
        File.write("-" * 40 + "\n")
        
        # Process passed tests
        if Stats.get('passed'):
            File.write("\nPASSED TESTS:\n")
            for Report in Stats['passed']:
                if hasattr(Report, 'nodeid'):
                    File.write(f"✓ {Report.nodeid}\n")
        
        # Process failed tests
        if Stats.get('failed'):
            File.write("\nFAILED TESTS:\n")
            for Report in Stats['failed']:
                if hasattr(Report, 'nodeid'):
                    File.write(f"✗ {Report.nodeid}\n")
                    if hasattr(Report, 'longrepr'):
                        File.write(f"  Error: {str(Report.longrepr).split('E       ')[1].split('\\n')[0]}\n")
        
        # Process skipped tests
        if Stats.get('skipped'):
            File.write("\nSKIPPED TESTS:\n")
            for Report in Stats['skipped']:
                if hasattr(Report, 'nodeid'):
                    File.write(f"- {Report.nodeid}\n")
    
    print(f"\nTest report saved to: {TextReportPath}")


@pytest.fixture(scope="function")
def test_timestamp():
    """Generate a timestamp for test identification."""
    return datetime.now().strftime("%Y%m%d_%H%M%S")


@pytest.fixture(scope="session")
def project_root():
    """Get project root directory for consistent path resolution."""
    # First try environment variable
    ProjectRoot = os.environ.get("PROJECT_ROOT")
    
    if ProjectRoot:
        return Path(ProjectRoot)
    
    # Otherwise resolve from this file location
    return Path(__file__).parent.parent


@pytest.fixture(scope="session")
def report_dir(project_root):
    """Get report directory path and ensure it exists."""
    ReportDir = project_root / "TestReports"
    ReportDir.mkdir(exist_ok=True)
    return ReportDir

================
File: ..Exclude/directory-parser-fix (1).py
================
# File: DirectoryParser.py
# Path: AIDEV-ProjectSetup/Utils/DirectoryParser.py
# Standard: AIDEV-PascalCase-1.6
# Created: 2025-03-23
# Last Modified: 2025-03-23  5:10PM
# Description: Parser for directory structure text files

"""
Directory structure parser utility.

This module provides functionality for parsing directory structure
from text files or string input in tree-like format.
"""

import re

class DirectoryParser:
    """Parser for directory structure text files."""
    
    def __init__(self):
        """Initialize DirectoryParser."""
        # Patterns for line parsing
        self.IndentPattern = re.compile(r'^(\s*)(├── |└── |│   |\s\s\s)(.+)$')
        self.DirectPattern = re.compile(r'^(\s*)(.+)$')
    
    def ParseStructure(self, Content):
        """
        Parse directory structure from string content.
        
        Args:
            Content: String containing directory structure in tree format
            
        Returns:
            Dict: Hierarchical representation of directory structure
        """
        if not Content or not isinstance(Content, str):
            return {}
            
        Lines = Content.strip().split('\n')
        Structure = {}
        
        # Skip empty lines and the root '.' line
        ProcessedLines = []
        for Line in Lines:
            Line = Line.rstrip()
            if Line and not Line.strip() == '.':
                ProcessedLines.append(Line)
        
        if not ProcessedLines:
            return Structure
        
        # Process lines
        IndentStack = [-1]
        DictStack = [Structure]
        
        for Line in ProcessedLines:
            # Try to match standard tree format
            Match = self.IndentPattern.match(Line)
            if not Match:
                # Try direct format (just indentation)
                Match = self.DirectPattern.match(Line)
                if not Match:
                    continue
                
                Indent = len(Match.group(1))
                Name = Match.group(2).strip()
            else:
                Indent = len(Match.group(1))
                Name = Match.group(3).strip()
            
            # Skip files (containing periods, except directories starting with '.')
            if '.' in Name and not Name.startswith('.') and Name != '..':
                # Special files like README.md and LICENSE
                if Name in ['README.md', 'LICENSE', 'requirements.txt', '.gitignore']:
                    # Handle special files
                    CurrentDict = DictStack[-1]
                    CurrentDict[Name] = {}
                continue
            
            # Process indentation
            while len(IndentStack) > 0 and Indent <= IndentStack[-1]:
                IndentStack.pop()
                DictStack.pop()
            
            # Get current dictionary
            if not DictStack:
                # This is a safety check in case the stack became empty
                DictStack = [Structure]
                IndentStack = [-1]
            
            CurrentDict = DictStack[-1]
            
            # Add new directory
            CurrentDict[Name] = {}
            
            # Update stacks
            IndentStack.append(Indent)
            DictStack.append(CurrentDict[Name])
        
        return Structure
    
    def FormatStructureToText(self, Structure, Prefix=""):
        """
        Format directory structure to text representation.
        
        Args:
            Structure: Dictionary representing directory structure
            Prefix: Prefix for indentation (used in recursion)
            
        Returns:
            list: Lines of text representation of structure
        """
        Result = []
        
        # Handle empty structure
        if not Structure:
            return Result
            
        # Get sorted keys
        Keys = sorted(Structure.keys())
        
        for i, Name in enumerate(Keys):
            IsLast = (i == len(Keys) - 1)
            
            # Determine prefix and connector
            if IsLast:
                Connector = "└── "
                ChildPrefix = Prefix + "    "
            else:
                Connector = "├── "
                ChildPrefix = Prefix + "│   "
            
            # Add line for current directory
            Line = Prefix + Connector + Name
            Result.append(Line)
            
            # Process children recursively
            if Structure[Name]:
                ChildLines = self.FormatStructureToText(
                    Structure[Name], ChildPrefix
                )
                Result.extend(ChildLines)
        
        return Result

================
File: ..Exclude/run-tests-script.py
================
# File: run_tests.py
# Path: AIDEV-ProjectSetup/run_tests.py
# Standard: AIDEV-PascalCase-1.6
# Created: 2025-03-23
# Last Modified: 2025-03-23  4:10PM
# Description: Script to run all tests for AIDEV-ProjectSetup

"""
Test runner for AIDEV-ProjectSetup.

This script runs all unit and integration tests for the AIDEV-ProjectSetup application
and generates a report of the results.
"""

import os
import sys
import time
import unittest
import datetime
from pathlib import Path

def RunTests():
    """Run all tests and return results."""
    # Start timing
    StartTime = time.time()
    
    # Get test directory
    TestDir = Path(__file__).parent / 'Tests'
    
    # Discover and run tests
    Loader = unittest.TestLoader()
    Suite = Loader.discover(str(TestDir), pattern='test_*.py')
    
    # Create test result
    Result = unittest.TextTestRunner(verbosity=2).run(Suite)
    
    # End timing
    EndTime = time.time()
    
    return {
        'total': Result.testsRun,
        'failures': len(Result.failures),
        'errors': len(Result.errors),
        'skipped': len(Result.skipped),
        'time': EndTime - StartTime,
        'success_rate': (Result.testsRun - len(Result.failures) - len(Result.errors)) / Result.testsRun * 100 if Result.testsRun > 0 else 0,
        'result': Result
    }

def GenerateReport(Results):
    """Generate a report from test results."""
    # Create report directory if it doesn't exist
    ReportDir = Path(__file__).parent / 'TestReports'
    ReportDir.mkdir(exist_ok=True)
    
    # Create report filename with timestamp
    Timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    ReportPath = ReportDir / f'test_report_{Timestamp}.txt'
    
    # Generate report content
    Content = [
        "AIDEV-ProjectSetup Test Report",
        f"Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "-" * 50,
        f"Total Tests: {Results['total']}",
        f"Passed: {Results['total'] - Results['failures'] - Results['errors']}",
        f"Failed: {Results['failures']}",
        f"Errors: {Results['errors']}",
        f"Skipped: {Results['skipped']}",
        f"Success Rate: {Results['success_rate']:.2f}%",
        f"Total Time: {Results['time']:.2f} seconds",
        "-" * 50,
    ]
    
    # Add failure details
    if Results['failures']:
        Content.append("\nTest Failures:")
        for i, (Test, Trace) in enumerate(Results['result'].failures, 1):
            Content.append(f"\n{i}. {Test}")
            Content.append(f"   {Trace.split('Traceback')[0].strip()}")
    
    # Add error details
    if Results['errors']:
        Content.append("\nTest Errors:")
        for i, (Test, Trace) in enumerate(Results['result'].errors, 1):
            Content.append(f"\n{i}. {Test}")
            Content.append(f"   {Trace.split('Traceback')[0].strip()}")
    
    # Add summary
    if Results['failures'] == 0 and Results['errors'] == 0:
        Content.append("\nALL TESTS PASSED!")
    else:
        Content.append("\nSOME TESTS FAILED. See details above.")
    
    # Write report to file
    with open(ReportPath, 'w') as File:
        File.write('\n'.join(Content))
    
    print(f"Test report generated: {ReportPath}")
    return ReportPath

def Main():
    """Main entry point for the test runner."""
    print("Running AIDEV-ProjectSetup tests...")
    
    # Run tests
    Results = RunTests()
    
    # Display summary
    print("\nTest Summary:")
    print(f"Total Tests: {Results['total']}")
    print(f"Passed: {Results['total'] - Results['failures'] - Results['errors']}")
    print(f"Failed: {Results['failures']}")
    print(f"Errors: {Results['errors']}")
    print(f"Success Rate: {Results['success_rate']:.2f}%")
    print(f"Total Time: {Results['time']:.2f} seconds")
    
    # Generate report
    ReportPath = GenerateReport(Results)
    
    # Return exit code
    return 0 if Results['failures'] == 0 and Results['errors'] == 0 else 1

if __name__ == '__main__':
    sys.exit(Main())

================
File: ..Exclude/TestDatabaseIntegration.py
================
# Test class for DatabaseIntegration
# You can add this to your test_project_setup.py file

import os
import tempfile
import sqlite3
from pathlib import Path
from unittest.mock import MagicMock
import unittest
import shutil
from Core.DatabaseIntegration import DatabaseIntegration

class TestDatabaseIntegration(unittest.TestCase):
    """Test cases for DatabaseIntegration component."""
    
    def setUp(self):
        """Set up test environment."""
        # Create temporary directories and files
        self.TempDir = Path(tempfile.mkdtemp())
        
        # Create temporary database files
        self.HimalayaDbPath = self.TempDir / 'Himalaya.db'
        
        # Mock ConfigManager
        self.MockConfig = MagicMock()
        self.MockConfig.Get.return_value = str(self.HimalayaDbPath)
        
        # Create DatabaseIntegration with mock config
        self.database_integration = DatabaseIntegration(self.MockConfig)
        
        # Sample project config
        self.ProjectConfig = {
            'ProjectName': 'AIDEV-TestProject',
            'Description': 'Test project description',
            'GitHubAccount': 'TestAccount',
            'RepositoryName': 'TestRepo',
            'ProjectPath': str(self.TempDir)
        }
    
    def tearDown(self):
        """Clean up test environment."""
        shutil.rmtree(self.TempDir)
    
    def test_initialize_project_database(self):
        """Test initializing project database."""
        # Create project database file path
        ProjectDbPath = self.TempDir / 'AIDEV-TestProject.db'
        
        # Initialize database
        Result = self.database_integration.InitializeProjectDatabase(ProjectDbPath, self.ProjectConfig)
        
        # Verify initialization
        self.assertTrue(Result)
        
        # Connect to database and verify tables
        Connection = sqlite3.connect(ProjectDbPath)
        Cursor = Connection.cursor()
        
        # Check if tables exist
        Cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        Tables = [row[0] for row in Cursor.fetchall()]
        
        self.assertIn('ProjectConfig', Tables)
        self.assertIn('Documentation', Tables)
        self.assertIn('HelpContent', Tables)
        self.assertIn('ProjectState', Tables)
        self.assertIn('SubProjects', Tables)
        
        Connection.close()

================
File: GUI/DirectoryEditor.py.py
================
# File: DirectoryEditor.py
# Path: AIDEV-ProjectSetup/GUI/DirectoryEditor.py
# Standard: AIDEV-PascalCase-1.6
# Created: 2025-03-23
# Last Modified: 2025-03-23  12:35PM
# Description: Directory structure editor for AIDEV-ProjectSetup

"""
Directory structure editor component.

This module provides the interface for viewing and modifying
the project directory structure.
"""

from PySide6.QtWidgets import (QWidget, QVBoxLayout, QHBoxLayout, 
                             QTreeView, QToolBar, QAction, QPushButton,
                             QFileDialog, QLabel, QMenu, QInputDialog,
                             QMessageBox)
from PySide6.QtCore import Qt, QStandardItemModel, QStandardItem
from PySide6.QtGui import QIcon

from Utils.DirectoryParser import DirectoryParser

class DirectoryEditor(QWidget):
    """Directory structure editor component."""
    
    def __init__(self, Initializer):
        """Initialize the directory editor."""
        super().__init__()
        
        self.Initializer = Initializer
        self.DirectoryParser = DirectoryParser()
        
        self.SetupUI()
        self.LoadDefaultStructure()
    
    def SetupUI(self):
        """Set up the user interface components."""
        # Create main layout
        self.MainLayout = QVBoxLayout(self)
        
        # Create header label
        self.HeaderLabel = QLabel("Project Directory Structure")
        self.HeaderLabel.setAlignment(Qt.AlignCenter)
        self.MainLayout.addWidget(self.HeaderLabel)
        
        # Create toolbar
        self.ToolBar = QToolBar()
        self.MainLayout.addWidget(self.ToolBar)
        
        # Add actions to toolbar
        self.LoadDefaultAction = QAction("Load Default", self)
        self.LoadFromFileAction = QAction("Load from File", self)
        self.AddFolderAction = QAction("Add Folder", self)
        self.RemoveFolderAction = QAction("Remove Folder", self)
        
        self.ToolBar.addAction(self.LoadDefaultAction)
        self.ToolBar.addAction(self.LoadFromFileAction)
        self.ToolBar.addAction(self.AddFolderAction)
        self.ToolBar.addAction(self.RemoveFolderAction)
        
        # Connect actions
        self.LoadDefaultAction.triggered.connect(self.LoadDefaultStructure)
        self.LoadFromFileAction.triggered.connect(self.LoadFromFile)
        self.AddFolderAction.triggered.connect(self.AddFolder)
        self.RemoveFolderAction.triggered.connect(self.RemoveFolder)
        
        # Create tree view
        self.DirectoryTree = QTreeView()
        self.DirectoryModel = QStandardItemModel()
        self.DirectoryModel.setHorizontalHeaderLabels(["Directory Structure"])
        self.DirectoryTree.setModel(self.DirectoryModel)
        self.DirectoryTree.setContextMenuPolicy(Qt.CustomContextMenu)
        self.DirectoryTree.customContextMenuRequested.connect(self.ShowContextMenu)
        
        self.MainLayout.addWidget(self.DirectoryTree)
        
        # Add description label
        self.DescriptionLabel = QLabel(
            "Define the directory structure for your project. "
            "You can use the default structure, load from a file, "
            "or manually edit the structure."
        )
        self.DescriptionLabel.setWordWrap(True)
        self.MainLayout.addWidget(self.DescriptionLabel)
        
        # Add error label
        self.ErrorLabel = QLabel("")
        self.ErrorLabel.setObjectName("error")
        self.ErrorLabel.setAlignment(Qt.AlignCenter)
        self.ErrorLabel.setVisible(False)
        self.MainLayout.addWidget(self.ErrorLabel)
    
    def GetDefaultStructure(self):
        """Get the default directory structure."""
        return """
.
├── AddThese
├── AddTheseNow
├── Core
├── Docs
│   └── API
├── GUI
├── KnowledgeDatabase
├── LICENSE
├── Models
├── Notes
├── README.md
├── requirements.txt
├── Scripts
├── SysUtils
├── Tests
└── Utils
"""
    
    def LoadDefaultStructure(self):
        """Load the default directory structure."""
        # Clear existing model
        self.DirectoryModel.clear()
        self.DirectoryModel.setHorizontalHeaderLabels(["Directory Structure"])
        
        # Parse default structure
        Structure = self.DirectoryParser.ParseStructure(self.GetDefaultStructure())
        
        # Build the tree
        self.BuildDirectoryTree(Structure, self.DirectoryModel.invisibleRootItem())
        
        # Expand all items
        self.DirectoryTree.expandAll()
    
    def LoadFromFile(self):
        """Load directory structure from a text file."""
        FilePath, _ = QFileDialog.getOpenFileName(
            self, "Load Directory Structure", "", 
            "Text Files (*.txt);;All Files (*)"
        )
        
        if not FilePath:
            return
        
        try:
            with open(FilePath, 'r') as File:
                Content = File.read()
                
            # Parse structure
            Structure = self.DirectoryParser.ParseStructure(Content)
            
            # Clear existing model
            self.DirectoryModel.clear()
            self.DirectoryModel.setHorizontalHeaderLabels(["Directory Structure"])
            
            # Build the tree
            self.BuildDirectoryTree(Structure, self.DirectoryModel.invisibleRootItem())
            
            # Expand all items
            self.DirectoryTree.expandAll()
            
        except Exception as E:
            self.ShowError(f"Failed to load structure: {str(E)}")
    
    def BuildDirectoryTree(self, Structure, ParentItem):
        """Build tree structure from parsed directory structure."""
        for Name, Children in Structure.items():
            Item = QStandardItem(Name)
            ParentItem.appendRow(Item)
            
            if Children:
                self.BuildDirectoryTree(Children, Item)
    
    def AddFolder(self):
        """Add a new folder to the structure."""
        # Get selected item or use root if none selected
        SelectedIndexes = self.DirectoryTree.selectedIndexes()
        if SelectedIndexes:
            ParentItem = self.DirectoryModel.itemFromIndex(SelectedIndexes[0])
        else:
            ParentItem = self.DirectoryModel.invisibleRootItem()
        
        # Get folder name
        FolderName, Ok = QInputDialog.getText(
            self, "Add Folder", "Folder Name:", QLineEdit.Normal, ""
        )
        
        if Ok and FolderName:
            # Check if folder already exists
            for Row in range(ParentItem.rowCount()):
                if ParentItem.child(Row).text() == FolderName:
                    self.ShowError(f"Folder '{FolderName}' already exists.")
                    return
            
            # Add new folder
            NewItem = QStandardItem(FolderName)
            ParentItem.appendRow(NewItem)
            
            # Expand parent item
            if ParentItem != self.DirectoryModel.invisibleRootItem():
                ParentIndex = ParentItem.index()
                self.DirectoryTree.expand(ParentIndex)
    
    def RemoveFolder(self):
        """Remove selected folder from the structure."""
        SelectedIndexes = self.DirectoryTree.selectedIndexes()
        if not SelectedIndexes:
            self.ShowError("Please select a folder to remove.")
            return
        
        # Get selected item
        SelectedItem = self.DirectoryModel.itemFromIndex(SelectedIndexes[0])
        
        # Confirm deletion
        Reply = QMessageBox.question(
            self, "Remove Folder", 
            f"Are you sure you want to remove '{SelectedItem.text()}'?",
            QMessageBox.Yes | QMessageBox.No, QMessageBox.No
        )
        
        if Reply == QMessageBox.Yes:
            # Remove item from model
            ParentItem = SelectedItem.parent()
            if ParentItem:
                ParentItem.removeRow(SelectedItem.row())
            else:
                self.DirectoryModel.removeRow(SelectedItem.row())
    
    def ShowContextMenu(self, Position):
        """Show context menu for tree view."""
        ContextMenu = QMenu(self)
        
        AddAction = ContextMenu.addAction("Add Folder")
        RemoveAction = ContextMenu.addAction("Remove Folder")
        RenameAction = ContextMenu.addAction("Rename Folder")
        
        # Get selected item
        SelectedIndexes = self.DirectoryTree.selectedIndexes()
        if not SelectedIndexes:
            RemoveAction.setEnabled(False)
            RenameAction.setEnabled(False)
        
        # Show context menu
        Action = ContextMenu.exec_(self.DirectoryTree.viewport().mapToGlobal(Position))
        
        if Action == AddAction:
            self.AddFolder()
        elif Action == RemoveAction:
            self.RemoveFolder()
        elif Action == RenameAction:
            self.RenameFolder()
    
    def RenameFolder(self):
        """Rename selected folder."""
        SelectedIndexes = self.DirectoryTree.selectedIndexes()
        if not SelectedIndexes:
            return
        
        # Get selected item
        SelectedItem = self.DirectoryModel.itemFromIndex(SelectedIndexes[0])
        
        # Get new name
        NewName, Ok = QInputDialog.getText(
            self, "Rename Folder", "New Name:", 
            QLineEdit.Normal, SelectedItem.text()
        )
        
        if Ok and NewName:
            # Check if name already exists in parent
            ParentItem = SelectedItem.parent()
            if not ParentItem:
                ParentItem = self.DirectoryModel.invisibleRootItem()
                
            for Row in range(ParentItem.rowCount()):
                ChildItem = ParentItem.child(Row)
                if ChildItem != SelectedItem and ChildItem.text() == NewName:
                    self.ShowError(f"Folder '{NewName}' already exists.")
                    return
            
            # Update name
            SelectedItem.setText(NewName)
    
    def ShowError(self, Message):
        """Display an error message."""
        self.ErrorLabel.setText(Message)
        self.ErrorLabel.setStyleSheet("color: red; font-weight: bold;")
        self.ErrorLabel.setVisible(True)
        
        # Hide after 5 seconds
        QTimer.singleShot(5000, lambda: self.ErrorLabel.setVisible(False))
    
    def ValidateStep(self):
        """Validate the current step before proceeding."""
        # Check if structure is not empty
        if self.DirectoryModel.rowCount() == 0:
            self.ShowError("Directory structure cannot be empty.")
            return False
        
        return True
    
    def GetConfiguration(self):
        """Get the directory structure configuration."""
        # Extract structure from model
        Structure = {}
        self.ExtractStructure(self.DirectoryModel.invisibleRootItem(), Structure)
        
        return {
            "DirectoryStructure": Structure
        }
    
    def ExtractStructure(self, ParentItem, Structure):
        """Recursively extract directory structure from model."""
        for Row in range(ParentItem.rowCount()):
            Item = ParentItem.child(Row)
            ChildStructure = {}
            Structure[Item.text()] = ChildStructure
            self.ExtractStructure(Item, ChildStructure)

================
File: SysUtils/AIDEV-DocMManager_Setup.py
================
# File: setup.py
# Path: setup.py
# Standard: AIDEV-PascalCase-1.6
# Created: March 22, 2025
# Last Modified: March 22, 2025  8:50 PM
# Description: Installation script for DocumentRenamer

"""
Installation script for the DocumentRenamer package.

This script configures package metadata and entry points for installation.
"""

from setuptools import setup, find_packages

setup(
    name="AIDEV-DocManager",
    version="0.1.0",
    description="Document management tool for Project Himalaya",
    author="Herbert J. Bowers",
    author_email="herb@bowersworld.com",
    package_dir={"": "src"},
    packages=find_packages(where="src"),
    install_requires=[
        # tkinter is part of standard Python library
    ],
    entry_points={
        "console_scripts": [
            "document-renamer=ProjectHimalaya.DocumentRenamer:Main",
        ],
    },
    classifiers=[
        "Development Status :: 3 - Alpha",
        "Intended Audience :: Developers",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
    ],
    python_requires=">=3.8",
)

================
File: SysUtils/BuildDirectories.py
================
# BuildDirectories.py

import os

def create_directory(path):
    try:
        os.makedirs(path, exist_ok=True)
        print(f"Created: {path}")
    except Exception as e:
        print(f"Failed to create {path}: {e}")

def main():
    base_dir = os.getcwd()

    directories = [
        "..Exclude",
        "AddThese",
        "AddTheseNow",
        "Core",
        "Docs/API",
        "GUI",
        "KnowledgeDatabase/OldVersions",
        "Notes/2024-03-21",
        "Scripts",
        "SysUtils",
        "Tests/Integration",
        "Tests/Unit",
        "UI",
        "Utils"
    ]

    for directory in directories:
        create_directory(os.path.join(base_dir, directory))

    # Create empty placeholder files to represent the structure (optional)
    print("\nDirectory structure created.")

if __name__ == "__main__":
    main()

================
File: SysUtils/MyDiff.py
================
# File: MyDiff.py
# Path: SysUtils/MyDiff.py
# Standard: AIDEV-PascalCase-1.6
# Created: 2025-03-20
# Last Modified: 2025-03-20  10:30AM
# Description: File diff generation tool with GUI interface

import sys
from PySide6.QtWidgets import QApplication, QWidget, QVBoxLayout, QHBoxLayout, QPushButton, QTextEdit, QFileDialog, QLabel
from PySide6.QtGui import QColor, QFont, QFontDatabase
from PySide6.QtCore import Qt

import difflib

class DiffWindow(QWidget):
    """
    GUI window for comparing and displaying differences between two files.
    
    This class provides a graphical interface for selecting two files,
    generating a diff between them, and visualizing the differences.
    """
    
    def __init__(self):
        """Initialize the diff window with UI components."""
        super().__init__()
        self.setWindowTitle("File Diff Generator")

        self.File1Path = ""
        self.File2Path = ""

        # Widgets
        self.File1Button = QPushButton("Select Original File")
        self.File1Label = QLabel("Original File: Not selected")
        self.File2Button = QPushButton("Select New File")
        self.File2Label = QLabel("New File: Not selected")
        self.GenerateButton = QPushButton("Generate Diff")
        self.GenerateButton.setEnabled(False)  # Disable initially

        self.OriginalText = QTextEdit()
        self.OriginalText.setReadOnly(True)
        self.NewText = QTextEdit()
        self.NewText.setReadOnly(True)
        self.DiffText = QTextEdit()
        self.DiffText.setReadOnly(True)

        self.OriginalHideButton = QPushButton("Hide Original")
        self.NewHideButton = QPushButton("Hide New")
        self.DiffHideButton = QPushButton("Hide Diff")

        self.OriginalVisible = True
        self.NewVisible = True
        self.DiffVisible = True

        # Layout
        FileLayout = QHBoxLayout()
        FileLayout.addWidget(self.File1Button)
        FileLayout.addWidget(self.File1Label)
        FileLayout.addWidget(self.File2Button)
        FileLayout.addWidget(self.File2Label)

        HideLayout = QHBoxLayout()
        HideLayout.addWidget(self.OriginalHideButton)
        HideLayout.addWidget(self.NewHideButton)
        HideLayout.addWidget(self.DiffHideButton)

        self.TextLabelLayout = QHBoxLayout()
        self.TextLabelLayout.addWidget(QLabel("Original File"))
        self.TextLabelLayout.addWidget(QLabel("New File"))
        self.TextLabelLayout.addWidget(QLabel("Diff"))

        self.DisplayLayout = QHBoxLayout()
        self.DisplayLayout.addWidget(self.OriginalText)
        self.DisplayLayout.addWidget(self.NewText)
        self.DisplayLayout.addWidget(self.DiffText)

        MainLayout = QVBoxLayout()
        MainLayout.addLayout(FileLayout)
        MainLayout.addWidget(self.GenerateButton)
        MainLayout.addLayout(HideLayout)
        MainLayout.addLayout(self.TextLabelLayout)
        MainLayout.addLayout(self.DisplayLayout)

        self.setLayout(MainLayout)

        # Connections
        self.File1Button.clicked.connect(self.SelectFile1)
        self.File2Button.clicked.connect(self.SelectFile2)
        self.GenerateButton.clicked.connect(self.GenerateDiff)

        self.OriginalHideButton.clicked.connect(self.ToggleOriginal)
        self.NewHideButton.clicked.connect(self.ToggleNew)
        self.DiffHideButton.clicked.connect(self.ToggleDiff)

    def SelectFile1(self):
        """Open a file dialog to select the first (original) file."""
        File1Path, _ = QFileDialog.getOpenFileName(self, "Select Original File")
        if File1Path:
            self.File1Path = File1Path
            self.File1Label.setText("Original File: " + self.File1Path)
            self.CheckEnableGenerate()

    def SelectFile2(self):
        """Open a file dialog to select the second (new) file."""
        File2Path, _ = QFileDialog.getOpenFileName(self, "Select New File")
        if File2Path:
            self.File2Path = File2Path
            self.File2Label.setText("New File: " + self.File2Path)
            self.CheckEnableGenerate()

    def CheckEnableGenerate(self):
        """Enable the Generate button if both files have been selected."""
        if self.File1Path and self.File2Path:
            self.GenerateButton.setEnabled(True)
        else:
            self.GenerateButton.setEnabled(False)

    def GenerateDiff(self):
        """Generate and display the diff between the two selected files."""
        try:
            with open(self.File1Path, 'r') as F1:
                File1Lines = F1.readlines()
            with open(self.File2Path, 'r') as F2:
                File2Lines = F2.readlines()

            # Display original and new files with specified colors
            self.OriginalText.setHtml(f"<pre><span style='color: green;'>{''.join(File1Lines)}</span></pre>")
            self.NewText.setHtml(f"<pre><span style='color: red;'>{''.join(File2Lines)}</span></pre>")

            Diff = difflib.Differ().compare(File1Lines, File2Lines)
            DiffText = ""
            for Line in Diff:
                if Line.startswith('  '):
                    DiffText += f"<span style='color: white;'>  {Line[2:]}</span>"  # Common lines
                elif Line.startswith('- '):
                    DiffText += f"<span style='color: red;'>1: {Line[2:]}</span>"  # File 1 lines
                elif Line.startswith('+ '):
                    DiffText += f"<span style='color: green;'>2: {Line[2:]}</span>"  # File 2 lines
                elif Line.startswith('? '):
                    DiffText += f"<span style='color: yellow;'>? {Line[2:]}</span>"  # Questionable lines
                else:
                    DiffText += f"<span style='color: darkgray;'>{Line}</span>"  # Other lines (e.g. ---, +++)

            if not DiffText:
                self.DiffText.setText("No differences found.")
            else:
                self.DiffText.setHtml(f"<pre>{DiffText}</pre>")

        except FileNotFoundError:
            self.OriginalText.setText("Error: One or both files not found.")
            self.NewText.setText("Error: One or both files not found.")
            self.DiffText.setText("Error: One or both files not found.")
        except Exception as e:
            self.DiffText.setText(f"Error: {str(e)}")

    def ToggleOriginal(self):
        """Toggle visibility of the original file pane."""
        self.OriginalVisible = not self.OriginalVisible
        self.OriginalText.setVisible(self.OriginalVisible)
        self.UpdateLayout()

    def ToggleNew(self):
        """Toggle visibility of the new file pane."""
        self.NewVisible = not self.NewVisible
        self.NewText.setVisible(self.NewVisible)
        self.UpdateLayout()

    def ToggleDiff(self):
        """Toggle visibility of the diff pane."""
        self.DiffVisible = not self.DiffVisible
        self.DiffText.setVisible(self.DiffVisible)
        self.UpdateLayout()

    def UpdateLayout(self):
        """Update the layout to reflect current visibility settings."""
        # Remove all widgets from the layout
        for i in reversed(range(self.DisplayLayout.count())):
            Widget = self.DisplayLayout.itemAt(i).widget()
            if Widget is not None:
                Widget.setParent(None)

        # Add the visible widgets back to the layout
        if self.OriginalVisible:
            self.DisplayLayout.addWidget(self.OriginalText)
        if self.NewVisible:
            self.DisplayLayout.addWidget(self.NewText)
        if self.DiffVisible:
            self.DisplayLayout.addWidget(self.DiffText)

def Main():
    """Main entry point for the application."""
    App = QApplication(sys.argv)
    Window = DiffWindow()
    Window.show()
    sys.exit(App.exec())

if __name__ == '__main__':
    Main()

================
File: TestDatabaseIntegration.py
================
# File: TestDatabaseIntegration.py
# Path: Tests/Unit/TestDatabaseIntegration.py
# Standard: AIDEV-PascalCase-1.6
# Created: March 24, 2025
# Last Modified: March 24, 2025  2:30PM
# Description: Unit tests for the DatabaseIntegration component

"""
Unit tests for DatabaseIntegration component.

This module contains tests that verify the functionality of the DatabaseIntegration
component, which handles database initialization, schema creation, and project 
registration in the Project Himalaya framework.
"""

import os
import sys
import unittest
import tempfile
import sqlite3
from pathlib import Path
from unittest.mock import MagicMock, patch
import shutil

# Add parent directory to path for imports
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from Core.DatabaseIntegration import DatabaseIntegration


class TestDatabaseIntegration(unittest.TestCase):
    """Test cases for DatabaseIntegration component."""
    
    def setUp(self):
        """Set up test environment with mock configuration and temporary directories."""
        # Create temporary directories and files
        self.TempDir = Path(tempfile.mkdtemp())
        
        # Output test environment information
        print(f"\n============================================================")
        print(f"Test Environment Information")
        print(f"------------------------------------------------------------")
        print(f"Test directory: {self.TempDir}")
        print(f"Created at: {self.GetCurrentTimestamp()}")
        print(f"============================================================")
        
        # Create temporary database files
        self.HimalayaDbPath = self.TempDir / 'Himalaya.db'
        
        # Create empty Himalaya database for testing
        Connection = sqlite3.connect(self.HimalayaDbPath)
        Connection.close()
        print(f"Created mock Himalaya database at: {self.HimalayaDbPath}")
        
        # Mock ConfigManager
        self.MockConfig = MagicMock()
        self.MockConfig.Get.return_value = str(self.HimalayaDbPath)
        
        # Create DatabaseIntegration with mock config
        self.DatabaseIntegration = DatabaseIntegration(self.MockConfig)
        
        # Sample project config for testing
        self.ProjectConfig = {
            'ProjectName': 'AIDEV-TestProject',
            'Description': 'Test project for DatabaseIntegration',
            'GitHubAccount': 'TestAccount',
            'RepositoryName': 'TestRepo',
            'ProjectPath': str(self.TempDir)
        }
        
        # Create project directory
        self.ProjectPath = self.TempDir / self.ProjectConfig['ProjectName']
        self.ProjectPath.mkdir(exist_ok=True)
        
        # Create Directories folder
        self.DirectoriesPath = self.ProjectPath / 'Directories'
        self.DirectoriesPath.mkdir(exist_ok=True)
    
    def tearDown(self):
        """Clean up test environment after test execution."""
        print(f"\n============================================================")
        print(f"Test Cleanup")
        print(f"------------------------------------------------------------")
        print(f"Removing test directory: {self.TempDir}")
        print(f"Completed at: {self.GetCurrentTimestamp()}")
        print(f"============================================================")
        shutil.rmtree(self.TempDir)
    
    def GetCurrentTimestamp(self):
        """Get current timestamp in ISO format."""
        from datetime import datetime
        return datetime.now().isoformat()
    
    def PrintTableInfo(self, Cursor, TableName):
        """Print schema and sample data for a table."""
        print(f"\n  Table: {TableName}")
        print(f"  -----------------------------------------------")
        
        # Print schema
        Cursor.execute(f"PRAGMA table_info({TableName})")
        Columns = Cursor.fetchall()
        print(f"  Schema ({len(Columns)} columns):")
        for Column in Columns:
            # Column structure: (cid, name, type, notnull, dflt_value, pk)
            ColumnId, Name, Type, NotNull, DefaultValue, PrimaryKey = Column
            Constraints = []
            if PrimaryKey:
                Constraints.append("PRIMARY KEY")
            if NotNull:
                Constraints.append("NOT NULL")
            if DefaultValue is not None:
                Constraints.append(f"DEFAULT {DefaultValue}")
                
            ConstraintStr = " ".join(Constraints)
            if ConstraintStr:
                print(f"    - {Name} ({Type}) {ConstraintStr}")
            else:
                print(f"    - {Name} ({Type})")
        
        # Print row count
        Cursor.execute(f"SELECT COUNT(*) FROM {TableName}")
        RowCount = Cursor.fetchone()[0]
        print(f"\n  Data: {RowCount} rows")
        
        # Print sample data if available
        if RowCount > 0:
            print(f"  Sample data (up to 3 rows):")
            Cursor.execute(f"SELECT * FROM {TableName} LIMIT 3")
            Rows = Cursor.fetchall()
            for RowIndex, Row in enumerate(Rows):
                print(f"    Row {RowIndex + 1}: {Row}")
    
    def test_InitializeProjectDatabase(self):
        """Test initializing project database with schema and initial data."""
        # Define project database path
        ProjectDbPath = self.DirectoriesPath / f"{self.ProjectConfig['ProjectName']}.db"
        
        print(f"\n============================================================")
        print(f"Test: Initialize Project Database")
        print(f"------------------------------------------------------------")
        print(f"Project database path: {ProjectDbPath}")
        
        # Initialize database
        Result = self.DatabaseIntegration.InitializeProjectDatabase(ProjectDbPath, self.ProjectConfig)
        
        # Verify initialization result
        self.assertTrue(Result, "Database initialization should return True")
        self.assertTrue(ProjectDbPath.exists(), "Database file should exist")
        print(f"Database initialization successful: {Result}")
        print(f"Database file size: {ProjectDbPath.stat().st_size} bytes")
        
        # Connect to database and verify tables
        Connection = sqlite3.connect(ProjectDbPath)
        Cursor = Connection.cursor()
        
        # Get all tables
        Cursor.execute("SELECT name FROM sqlite_master WHERE type='table' ORDER BY name")
        Tables = [row[0] for row in Cursor.fetchall()]
        
        print(f"\nDatabase contains {len(Tables)} tables:")
        for TableName in Tables:
            self.PrintTableInfo(Cursor, TableName)
        
        # Verify required tables exist
        RequiredTables = [
            'ProjectConfig', 
            'Documentation', 
            'HelpContent', 
            'ProjectState', 
            'SubProjects'
        ]
        
        for Table in RequiredTables:
            self.assertIn(Table, Tables, f"Required table '{Table}' should exist")
        
        # Verify initial data was inserted
        Cursor.execute("SELECT COUNT(*) FROM ProjectConfig")
        ConfigCount = Cursor.fetchone()[0]
        self.assertGreater(ConfigCount, 0, "ProjectConfig should contain initial data")
        
        Cursor.execute("SELECT COUNT(*) FROM ProjectState")
        StateCount = Cursor.fetchone()[0]
        self.assertGreater(StateCount, 0, "ProjectState should contain initial data")
        
        Connection.close()
    
    def test_CreateDatabaseLink(self):
        """Test creating a symbolic link or copy to the Himalaya database."""
        print(f"\n============================================================")
        print(f"Test: Create Database Link")
        print(f"------------------------------------------------------------")
        
        # Call method under test
        Result = self.DatabaseIntegration.CreateDatabaseLink(self.ProjectPath, self.ProjectConfig)
        
        # Verify link was created
        self.assertTrue(Result, "CreateDatabaseLink should return True")
        
        LinkPath = self.DirectoriesPath / 'Himalaya.db'
        self.assertTrue(LinkPath.exists(), "Link to Himalaya database should exist")
        
        print(f"Link creation successful: {Result}")
        print(f"Link path: {LinkPath}")
        print(f"Link type: {'Symbolic link' if os.path.islink(LinkPath) else 'File copy'}")
        print(f"Link size: {LinkPath.stat().st_size} bytes")
    
    def test_RegisterProject(self):
        """Test registering a project in the Himalaya database."""
        print(f"\n============================================================")
        print(f"Test: Register Project")
        print(f"------------------------------------------------------------")
        
        # Call method under test
        Result = self.DatabaseIntegration.RegisterProject(self.ProjectConfig)
        
        # Verify registration
        self.assertTrue(Result, "RegisterProject should return True")
        
        # Connect to Himalaya database to verify project registration
        Connection = sqlite3.connect(self.HimalayaDbPath)
        Cursor = Connection.cursor()
        
        # Check if project table exists
        Cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='project'")
        TableExists = Cursor.fetchone() is not None
        
        self.assertTrue(TableExists, "Project table should be created in Himalaya database")
        
        if TableExists:
            # Check if project was registered
            Cursor.execute("SELECT * FROM project WHERE name=?", (self.ProjectConfig['ProjectName'],))
            ProjectRecord = Cursor.fetchone()
            
            self.assertIsNotNone(ProjectRecord, "Project should be registered in Himalaya database")
            
            if ProjectRecord:
                # Display project record
                Cursor.execute("PRAGMA table_info(project)")
                Columns = [column[1] for column in Cursor.fetchall()]
                
                print(f"Project registered in Himalaya database:")
                for i, Column in enumerate(Columns):
                    print(f"  {Column}: {ProjectRecord[i]}")
        
        Connection.close()


if __name__ == '__main__':
    # Setup output capture to both console and file
    import sys
    from datetime import datetime
    from io import StringIO
    import os
    
    # Create timestamped filename for test report
    Timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    ReportFileName = f"test_report_{Timestamp}.txt"
    
    # Use absolute path to project root TestReports directory
    # This ensures reports are saved outside the temporary test directory
    ProjectRoot = os.environ.get('PROJECT_ROOT')
    if not ProjectRoot:
        # Default to a location relative to the script, outside any temp dirs
        ProjectRoot = Path(__file__).resolve().parent.parent.parent
        
    ReportDir = Path(ProjectRoot) / "TestReports"
    ReportPath = ReportDir / ReportFileName
    
    # Ensure TestReports directory exists
    ReportDir.mkdir(exist_ok=True, parents=True)
    
    print(f"\n============================================================")
    print(f"Test Report Configuration")
    print(f"------------------------------------------------------------")
    print(f"Report will be saved to: {ReportPath}")
    print(f"This location persists after test completion")
    print(f"============================================================")
    
    # Create a custom test runner that captures output
    class TestRunner:
        def __init__(self, ReportPath):
            self.ReportPath = ReportPath
            self.OutputStream = StringIO()
            self.OriginalStdout = sys.stdout
            
        def __enter__(self):
            # Redirect stdout to our string buffer
            sys.stdout = self.__class__.TeeOutput(self.OriginalStdout, self.OutputStream)
            return self
            
        def __exit__(self, exc_type, exc_val, exc_tb):
            # Restore original stdout
            sys.stdout = self.OriginalStdout
            
            # Write captured output to file
            with open(self.ReportPath, 'w') as f:
                f.write(self.OutputStream.getvalue())
                
            print(f"\nTest report saved to: {self.ReportPath}")
            
        class TeeOutput:
            """Class to duplicate output to both console and string buffer."""
            def __init__(self, original_stdout, string_buffer):
                self.original_stdout = original_stdout
                self.string_buffer = string_buffer
                
            def write(self, text):
                self.original_stdout.write(text)
                self.string_buffer.write(text)
                
            def flush(self):
                self.original_stdout.flush()
    
    # Run tests with output capture
    with TestRunner(ReportPath):
        unittest.main(exit=False)

================
File: Tests/conftest.py
================
# File: conftest.py
# Path: Tests/conftest.py
# Standard: AIDEV-PascalCase-1.6
# Created: March 24, 2025
# Last Modified: March 24, 2025  4:20PM
# Description: pytest configuration for Project Himalaya tests

"""
pytest configuration for Project Himalaya tests.

This module contains fixtures and hooks for pytest that apply to all
test modules in the Project Himalaya framework.
"""

import os
import sys
import pytest
from pathlib import Path
from datetime import datetime


def pytest_configure(config):
    """Configure pytest settings for Project Himalaya."""
    # Register custom markers
    config.addinivalue_line(
        "markers", 
        "database: marks tests that interact with databases"
    )
    config.addinivalue_line(
        "markers", 
        "integration: marks tests that require multiple components"
    )
    
    # Set default HTML report path if --html not specified
    if not config.getoption("--html", None):
        ReportDir = Path("TestReports")
        ReportDir.mkdir(exist_ok=True)
        CurrentDate = datetime.now().strftime("%Y-%m-%d")
        HtmlReportPath = ReportDir / f"html_report_{CurrentDate}.html"
        config.option.htmlpath = str(HtmlReportPath)


def pytest_terminal_summary(terminalreporter, exitstatus, config):
    """Generate custom text report after tests complete."""
    # Create report filename with just the date
    CurrentDate = datetime.now().strftime("%Y-%m-%d")  # Date in YYYY-MM-DD format
    ReportDir = Path("TestReports")
    ReportDir.mkdir(exist_ok=True)
    TextReportPath = ReportDir / f"test_report_{CurrentDate}.txt"
    
    # Write report using test results
    with open(TextReportPath, "w") as File:
        # Write header
        File.write("=" * 80 + "\n")
        File.write("PROJECT HIMALAYA TEST REPORT\n")
        File.write("=" * 80 + "\n")
        File.write(f"Generated: {datetime.now().isoformat()}\n")
        File.write(f"Test Status: {'PASSED' if exitstatus == 0 else 'FAILED'}\n\n")
        
        # Write test summary
        Stats = terminalreporter.stats
        File.write("Test Summary:\n")
        File.write("-" * 40 + "\n")
        File.write(f"Total tests: {sum(len(x) for x in Stats.values())}\n")
        File.write(f"Passed tests: {len(Stats.get('passed', []))}\n")
        File.write(f"Failed tests: {len(Stats.get('failed', []))}\n")
        File.write(f"Skipped tests: {len(Stats.get('skipped', []))}\n")
        
        # Calculate session duration - end time minus start time
        import time
        SessionDuration = time.time() - terminalreporter._sessionstarttime
        File.write(f"Execution time: {SessionDuration:.2f} seconds\n\n")
        
        # Write test details
        File.write("Test Details:\n")
        File.write("-" * 40 + "\n")
        
        # Process passed tests
        if Stats.get('passed'):
            File.write("\nPASSED TESTS:\n")
            for Report in Stats['passed']:
                if hasattr(Report, 'nodeid'):
                    File.write(f"✓ {Report.nodeid}\n")
        
        # Process failed tests
        if Stats.get('failed'):
            File.write("\nFAILED TESTS:\n")
            for Report in Stats['failed']:
                if hasattr(Report, 'nodeid'):
                    File.write(f"✗ {Report.nodeid}\n")
                    if hasattr(Report, 'longrepr'):
                        File.write(f"  Error: {str(Report.longrepr).split('E       ')[1].split('\\n')[0]}\n")
        
        # Process skipped tests
        if Stats.get('skipped'):
            File.write("\nSKIPPED TESTS:\n")
            for Report in Stats['skipped']:
                if hasattr(Report, 'nodeid'):
                    File.write(f"- {Report.nodeid}\n")
    
    print(f"\nTest report saved to: {TextReportPath}")


@pytest.fixture(scope="function")
def test_timestamp():
    """Generate a timestamp for test identification."""
    return datetime.now().strftime("%Y%m%d_%H%M%S")


@pytest.fixture(scope="session")
def project_root():
    """Get project root directory for consistent path resolution."""
    # First try environment variable
    ProjectRoot = os.environ.get("PROJECT_ROOT")
    
    if ProjectRoot:
        return Path(ProjectRoot)
    
    # Otherwise resolve from this file location
    return Path(__file__).parent.parent


@pytest.fixture(scope="session")
def report_dir(project_root):
    """Get report directory path and ensure it exists."""
    ReportDir = project_root / "TestReports"
    ReportDir.mkdir(exist_ok=True)
    return ReportDir

================
File: Tests/Unit/test_database_integration.py
================
# File: test_database_integration.py
# Path: Tests/Unit/test_database_integration.py
# Standard: AIDEV-PascalCase-1.6
# Created: March 24, 2025
# Last Modified: March 24, 2025  4:15PM
# Description: pytest tests for DatabaseIntegration component

"""
pytest tests for DatabaseIntegration component.

This module contains tests that verify the functionality of the DatabaseIntegration
component, which handles database initialization, schema creation, and project 
registration in the Project Himalaya framework.
"""

import os
import sys
import sqlite3
from pathlib import Path
from unittest.mock import MagicMock, patch
import pytest

# Add parent directory to path for imports
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from Core.DatabaseIntegration import DatabaseIntegration


@pytest.fixture
def mock_config():
    """Create a mock configuration object for testing."""
    MockConfig = MagicMock()
    return MockConfig


@pytest.fixture
def himalaya_db(tmp_path):
    """Create a temporary Himalaya database for testing."""
    # Create temporary Himalaya database file
    HimalayaDbPath = tmp_path / 'Himalaya.db'
    
    # Initialize with empty schema
    Connection = sqlite3.connect(HimalayaDbPath)
    Connection.close()
    
    return HimalayaDbPath


@pytest.fixture
def database_integration(mock_config, himalaya_db):
    """Create a DatabaseIntegration instance for testing."""
    # Configure mock to return path to test Himalaya DB
    mock_config.Get.return_value = str(himalaya_db)
    
    # Create instance
    return DatabaseIntegration(mock_config)


@pytest.fixture
def project_config(tmp_path):
    """Create a sample project configuration for testing."""
    return {
        'ProjectName': 'AIDEV-TestProject',
        'Description': 'Test project for DatabaseIntegration',
        'GitHubAccount': 'TestAccount',
        'RepositoryName': 'TestRepo',
        'ProjectPath': str(tmp_path)
    }


@pytest.fixture
def project_structure(tmp_path, project_config):
    """Create project directory structure for testing."""
    # Create project directory
    ProjectPath = tmp_path / project_config['ProjectName']
    ProjectPath.mkdir(exist_ok=True)
    
    # Create Directories folder
    DirectoriesPath = ProjectPath / 'Directories'
    DirectoriesPath.mkdir(exist_ok=True)
    
    return {
        'ProjectPath': ProjectPath,
        'DirectoriesPath': DirectoriesPath
    }


@pytest.fixture
def db_reporter():
    """Fixture to capture and report database information."""
    Reports = []
    
    def _report_db(DbPath, Description=""):
        """Capture database information for reporting."""
        # Connect to database
        Connection = sqlite3.connect(DbPath)
        Cursor = Connection.cursor()
        
        # Get tables
        Cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        Tables = [row[0] for row in Cursor.fetchall()]
        
        # Build report
        Report = {
            "path": str(DbPath),
            "description": Description,
            "tables": {},
        }
        
        # Get schema and sample data for each table
        for Table in Tables:
            Cursor.execute(f"PRAGMA table_info({Table})")
            Columns = Cursor.fetchall()
            
            Cursor.execute(f"SELECT COUNT(*) FROM {Table}")
            RowCount = Cursor.fetchone()[0]
            
            Cursor.execute(f"SELECT * FROM {Table} LIMIT 3")
            Rows = Cursor.fetchall()
            
            Report["tables"][Table] = {
                "columns": Columns,
                "row_count": RowCount,
                "rows": Rows
            }
        
        Reports.append(Report)
        Connection.close()
        
        # Print some basic info for console output
        print(f"\nDatabase: {DbPath}")
        print(f"Description: {Description}")
        print(f"Tables: {', '.join(Tables)}")
    
    yield _report_db
    
    # After all tests, write detailed report to file
    from datetime import datetime
    
    # Create timestamped report filename
    Timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    ReportDir = Path("TestReports")
    ReportDir.mkdir(exist_ok=True)
    ReportPath = ReportDir / f"db_report_{Timestamp}.txt"
    
    # Write report
    with open(ReportPath, "w") as File:
        File.write("=" * 80 + "\n")
        File.write("DATABASE TEST REPORT\n")
        File.write("=" * 80 + "\n")
        File.write(f"Generated: {datetime.now().isoformat()}\n")
        File.write(f"Number of databases: {len(Reports)}\n\n")
        
        for Index, Report in enumerate(Reports, 1):
            File.write("=" * 80 + "\n")
            File.write(f"DATABASE {Index}: {Report['path']}\n")
            File.write("-" * 80 + "\n")
            File.write(f"Description: {Report['description']}\n\n")
            
            for Table, Data in Report["tables"].items():
                File.write(f"TABLE: {Table}\n")
                File.write("-" * 40 + "\n")
                File.write(f"Row count: {Data['row_count']}\n")
                File.write(f"Columns: {len(Data['columns'])}\n\n")
                
                File.write("Schema:\n")
                for Column in Data["columns"]:
                    # Column structure: (cid, name, type, notnull, dflt_value, pk)
                    ColumnId, Name, Type, NotNull, DefaultValue, PrimaryKey = Column
                    Constraints = []
                    if PrimaryKey:
                        Constraints.append("PRIMARY KEY")
                    if NotNull:
                        Constraints.append("NOT NULL")
                    if DefaultValue is not None:
                        Constraints.append(f"DEFAULT {DefaultValue}")
                        
                    ConstraintStr = " ".join(Constraints)
                    if ConstraintStr:
                        File.write(f"  - {Name} ({Type}) {ConstraintStr}\n")
                    else:
                        File.write(f"  - {Name} ({Type})\n")
                
                File.write("\nSample data:\n")
                if Data["row_count"] > 0:
                    for RowIndex, Row in enumerate(Data["rows"]):
                        File.write(f"  Row {RowIndex + 1}: {Row}\n")
                else:
                    File.write("  No data\n")
                
                File.write("\n")
    
    print(f"\nDatabase report saved to: {ReportPath}")


def test_initialize_project_database(database_integration, project_config, 
                                    project_structure, db_reporter):
    """Test initializing project database with schema and initial data."""
    # Define project database path
    ProjectDbPath = project_structure['DirectoriesPath'] / f"{project_config['ProjectName']}.db"
    
    # Initialize database
    Result = database_integration.InitializeProjectDatabase(ProjectDbPath, project_config)
    
    # Report database state for detailed output
    db_reporter(ProjectDbPath, "After initialization")
    
    # Verify initialization result
    assert Result is True
    assert ProjectDbPath.exists()
    
    # Connect to database and verify tables
    Connection = sqlite3.connect(ProjectDbPath)
    Cursor = Connection.cursor()
    
    # Get all tables
    Cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
    Tables = [row[0] for row in Cursor.fetchall()]
    
    # Verify required tables exist
    RequiredTables = [
        'ProjectConfig', 
        'Documentation', 
        'HelpContent', 
        'ProjectState', 
        'SubProjects'
    ]
    
    for Table in RequiredTables:
        assert Table in Tables, f"Required table '{Table}' should exist"
    
    # Verify initial data was inserted
    Cursor.execute("SELECT COUNT(*) FROM ProjectConfig")
    ConfigCount = Cursor.fetchone()[0]
    assert ConfigCount > 0, "ProjectConfig should contain initial data"
    
    Cursor.execute("SELECT COUNT(*) FROM ProjectState")
    StateCount = Cursor.fetchone()[0]
    assert StateCount > 0, "ProjectState should contain initial data"
    
    Connection.close()


def test_create_database_link(database_integration, project_config, 
                             project_structure, himalaya_db):
    """Test creating a symbolic link or copy to the Himalaya database."""
    # Call method under test
    Result = database_integration.CreateDatabaseLink(
        project_structure['ProjectPath'], 
        project_config
    )
    
    # Verify link was created
    assert Result is True
    
    LinkPath = project_structure['DirectoriesPath'] / 'Himalaya.db'
    assert LinkPath.exists(), "Link to Himalaya database should exist"
    
    # Check if it's a link or copy - either is acceptable
    LinkType = "Symbolic link" if os.path.islink(LinkPath) else "File copy"
    print(f"Link type: {LinkType}")


def test_register_project(database_integration, project_config, himalaya_db, db_reporter):
    """Test registering a project in the Himalaya database."""
    # Call method under test
    Result = database_integration.RegisterProject(project_config)
    
    # Report Himalaya database state for detailed output
    db_reporter(himalaya_db, "After project registration")
    
    # Verify registration result
    assert Result is True
    
    # Connect to Himalaya database to verify project registration
    Connection = sqlite3.connect(himalaya_db)
    Cursor = Connection.cursor()
    
    # Check if project table exists
    Cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='project'")
    TableExists = Cursor.fetchone() is not None
    
    assert TableExists, "Project table should be created in Himalaya database"
    
    if TableExists:
        # Check if project was registered
        Cursor.execute("SELECT * FROM project WHERE name=?", (project_config['ProjectName'],))
        ProjectRecord = Cursor.fetchone()
        
        assert ProjectRecord is not None, "Project should be registered in Himalaya database"
    
    Connection.close()


def test_full_workflow(database_integration, project_config, 
                      project_structure, himalaya_db, db_reporter):
    """Test full workflow of project database setup and registration."""
    # Define project database path
    ProjectDbPath = project_structure['DirectoriesPath'] / f"{project_config['ProjectName']}.db"
    
    # Step 1: Initialize project database
    Result1 = database_integration.InitializeProjectDatabase(ProjectDbPath, project_config)
    assert Result1 is True
    
    # Step 2: Create database link
    Result2 = database_integration.CreateDatabaseLink(
        project_structure['ProjectPath'], 
        project_config
    )
    assert Result2 is True
    
    # Step 3: Register project
    Result3 = database_integration.RegisterProject(project_config)
    assert Result3 is True
    
    # Report database states
    db_reporter(ProjectDbPath, "Project database after full workflow")
    db_reporter(himalaya_db, "Himalaya database after full workflow")
    
    # Verify end state
    assert ProjectDbPath.exists()
    assert (project_structure['DirectoriesPath'] / 'Himalaya.db').exists()
    
    # Verify Himalaya DB registration
    Connection = sqlite3.connect(himalaya_db)
    Cursor = Connection.cursor()
    Cursor.execute("SELECT * FROM project WHERE name=?", (project_config['ProjectName'],))
    assert Cursor.fetchone() is not None
    Connection.close()


if __name__ == "__main__":
    print("This script contains pytest tests and should be run using the pytest command.")
    print("To run these tests, use:")
    print("  pytest Tests/Unit/test_database_integration.py -v")
    print("\nTo generate HTML reports, use:")
    print("  pytest Tests/Unit/test_database_integration.py --html=TestReports/report.html")

================
File: Tests/Unit/test_integration.py
================
# File: test_integration.py
# Path: AIDEV-ProjectSetup/Tests/IntegrationTests/test_integration.py
# Standard: AIDEV-PascalCase-1.6
# Created: 2025-03-23
# Last Modified: 2025-03-23  4:20PM
# Description: Integration tests for AIDEV-ProjectSetup application

"""
Integration test suite for AIDEV-ProjectSetup.

This module contains integration tests that verify the interaction between
multiple components of the AIDEV-ProjectSetup application.
"""

import os
import sys
import shutil
import tempfile
import unittest
import sqlite3
from pathlib import Path
from unittest.mock import patch, MagicMock

# Add parent directory to path to import application modules
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from Utils.ConfigManager import ConfigManager
from Core.GitHubManager import GitHubManager
from Core.DatabaseIntegration import DatabaseIntegration
from Core.ProjectInitializer import ProjectInitializer


class TestEndToEndProjectCreation(unittest.TestCase):
    """Integration test for end-to-end project creation process."""
    
    def setUp(self):
        """Set up test environment."""
        # Create temporary directories
        self.TempProjectDir = Path(tempfile.mkdtemp())
        self.TempConfigDir = Path(tempfile.mkdtemp())
        
        # Create mock Himalaya database
        self.HimalayaDbPath = self.TempConfigDir / 'Himalaya.db'
        
        # Mock configuration
        self.MockConfig = MagicMock()
        self.MockConfig.Get.side_effect = self.mock_config_get
        self.MockConfig.GetGitHubToken.return_value = 'mock_token'
        
        # Sample project config
        self.ProjectConfig = {
            'ProjectName': 'AIDEV-TestIntegration',
            'Description': 'Integration test project',
            'GitHubAccount': 'TestAccount',
            'RepositoryName': 'TestRepo',
            'ProjectPath': str(self.TempProjectDir),
            'DirectoryStructure': {
                'Core': {},
                'Docs': {'API': {}},
                'Utils': {},
                'Tests': {'UnitTests': {}, 'IntegrationTests': {}}
            }
        }
        
        # Create initializer with mock config
        self.Initializer = ProjectInitializer(self.MockConfig)
        
        # Mock GitHub responses
        self.github_patcher = patch('requests.get')
        self.mock_github_get = self.github_patcher.start()
        self.mock_github_response = MagicMock()
        self.mock_github_response.status_code = 200
        self.mock_github_response.json.return_value = {'size': 0}
        self.mock_github_get.return_value = self.mock_github_response
        
        # Mock subprocess for git operations
        self.subprocess_patcher = patch('subprocess.run')
        self.mock_subprocess = self.subprocess_patcher.start()
        self.mock_subprocess.return_value = MagicMock()
    
    def mock_config_get(self, key, default=None):
        """Mock implementation of ConfigManager.Get."""
        if key == 'DatabasePath':
            return str(self.HimalayaDbPath)
        elif key == 'TemplatesPath':
            return str(Path(__file__).parent.parent.parent / 'Resources' / 'Templates')
        elif key == 'DefaultStructure':
            return """
            .
            ├── Core
            ├── Docs
            │   └── API
            ├── Utils
            └── Tests
            """
        return default
    
    def tearDown(self):
        """Clean up test environment."""
        # Stop patchers
        self.github_patcher.stop()
        self.subprocess_patcher.stop()
        
        # Remove temporary directories
        shutil.rmtree(self.TempProjectDir)
        shutil.rmtree(self.TempConfigDir)
    
    def test_end_to_end_project_creation(self):
        """Test end-to-end project creation process."""
        # Initialize project
        Result = self.Initializer.InitializeProject(self.ProjectConfig)
        
        # Verify result
        self.assertTrue(Result, "Project initialization failed")
        
        # Verify project directory structure
        ProjectPath = self.TempProjectDir / 'AIDEV-TestIntegration'
        self.assertTrue(ProjectPath.exists(), "Project directory not created")
        self.assertTrue((ProjectPath / 'Core').exists(), "Core directory not created")
        self.assertTrue((ProjectPath / 'Docs' / 'API').exists(), "Docs/API directory not created")
        self.assertTrue((ProjectPath / 'Utils').exists(), "Utils directory not created")
        self.assertTrue((ProjectPath / 'Tests' / 'UnitTests').exists(), "Tests/UnitTests directory not created")
        self.assertTrue((ProjectPath / 'Tests' / 'IntegrationTests').exists(), "Tests/IntegrationTests directory not created")
        
        # Verify project files
        self.assertTrue((ProjectPath / 'README.md').exists(), "README.md not created")
        self.assertTrue((ProjectPath / 'LICENSE').exists(), "LICENSE not created")
        self.assertTrue((ProjectPath / '.gitignore').exists(), ".gitignore not created")
        
        # Verify Directories folder was created
        self.assertTrue((ProjectPath / 'Directories').exists(), "Directories folder not created")
        
        # Verify git operations were called
        self.mock_subprocess.assert_called(), "Git operations not performed"


class TestDatabaseIntegrationFlow(unittest.TestCase):
    """Integration test for database integration flow."""
    
    def setUp(self):
        """Set up test environment."""
        # Create temporary directories
        self.TempProjectDir = Path(tempfile.mkdtemp())
        self.TempConfigDir = Path(tempfile.mkdtemp())
        
        # Create Himalaya database
        self.HimalayaDbPath = self.TempConfigDir / 'Himalaya.db'
        Connection = sqlite3.connect(self.HimalayaDbPath)
        Connection.close()
        
        # Mock configuration
        self.MockConfig = MagicMock()
        self.MockConfig.Get.return_value = str(self.HimalayaDbPath)
        
        # Create DatabaseIntegration with mock config
        self.DatabaseIntegration = DatabaseIntegration(self.MockConfig)
        
        # Sample project config
        self.ProjectConfig = {
            'ProjectName': 'AIDEV-DBTest',
            'Description': 'Database integration test',
            'GitHubAccount': 'TestAccount',
            'RepositoryName': 'TestRepo',
            'ProjectPath': str(self.TempProjectDir)
        }
        
        # Create project directory
        self.ProjectPath = self.TempProjectDir / 'AIDEV-DBTest'
        self.ProjectPath.mkdir(parents=True)
        
        # Create Directories folder
        self.DirectoriesPath = self.ProjectPath / 'Directories'
        self.DirectoriesPath.mkdir()
    
    def tearDown(self):
        """Clean up test environment."""
        # Remove temporary directories
        shutil.rmtree(self.TempProjectDir)
        shutil.rmtree(self.TempConfigDir)
    
    def test_database_integration_flow(self):
        """Test full database integration flow."""
        # Create project-specific database
        ProjectDbPath = self.DirectoriesPath / 'AIDEV-DBTest.db'
        Result = self.DatabaseIntegration.InitializeProjectDatabase(ProjectDbPath, self.ProjectConfig)
        self.assertTrue(Result, "Project database initialization failed")
        self.assertTrue(ProjectDbPath.exists(), "Project database file not created")
        
        # Create symbolic link (or copy on Windows) to Himalaya.db
        LinkResult = self.DatabaseIntegration.CreateDatabaseLink(self.ProjectPath, self.ProjectConfig)
        self.assertTrue(LinkResult, "Database link creation failed")
        
        # Check if link (or copy) exists
        self.assertTrue((self.DirectoriesPath / 'Himalaya.db').exists(), "Himalaya.db link not created")
        
        # Register project in Himalaya database
        RegisterResult = self.DatabaseIntegration.RegisterProject(self.ProjectConfig)
        self.assertTrue(RegisterResult, "Project registration failed")
        
        # Verify project registration in Himalaya database
        Connection = sqlite3.connect(self.HimalayaDbPath)
        Cursor = Connection.cursor()
        
        # Check if project table exists
        Cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='project'")
        TableExists = Cursor.fetchone() is not None
        self.assertTrue(TableExists, "Project table not created in Himalaya.db")
        
        # Check if project is registered
        if TableExists:
            Cursor.execute("SELECT * FROM project WHERE name=?", (self.ProjectConfig['ProjectName'],))
            ProjectData = Cursor.fetchone()
            self.assertIsNotNone(ProjectData, "Project not registered in Himalaya.db")
        
        Connection.close()
        
        # Verify project database has required tables
        Connection = sqlite3.connect(ProjectDbPath)
        Cursor = Connection.cursor()
        
        # Check for required tables
        Cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        Tables = [row[0] for row in Cursor.fetchall()]
        
        self.assertIn('ProjectConfig', Tables, "ProjectConfig table not created")
        self.assertIn('Documentation', Tables, "Documentation table not created")
        self.assertIn('HelpContent', Tables, "HelpContent table not created")
        self.assertIn('ProjectState', Tables, "ProjectState table not created")
        self.assertIn('SubProjects', Tables, "SubProjects table not created")
        
        # Check if initial data was inserted
        Cursor.execute("SELECT * FROM ProjectConfig WHERE ConfigKey='ProjectName'")
        ConfigData = Cursor.fetchone()
        self.assertIsNotNone(ConfigData, "Project name not stored in ProjectConfig")
        
        Cursor.execute("SELECT * FROM ProjectState")
        StateData = Cursor.fetchone()
        self.assertIsNotNone(StateData, "Initial state not created in ProjectState")
        
        Cursor.execute("SELECT * FROM Documentation")
        DocData = Cursor.fetchone()
        self.assertIsNotNone(DocData, "Initial documentation not created")
        
        Connection.close()


if __name__ == '__main__':
    unittest.main()

================
File: Tests/Unit/test_project_setup.py
================
# File: test_project_setup.py
# Path: AIDEV-ProjectSetup/Tests/UnitTests/test_project_setup.py
# Standard: AIDEV-PascalCase-1.6
# Created: 2025-03-23
# Last Modified: 2025-03-23  4:00PM
# Description: Automated tests for AIDEV-ProjectSetup application

"""
Automated test suite for AIDEV-ProjectSetup.

This module contains tests for core components of the AIDEV-ProjectSetup application,
including directory structure parsing, configuration management, GitHub integration,
and database operations.
"""

import os
import sys
import shutil
import tempfile
import unittest
import sqlite3
from pathlib import Path
from unittest.mock import patch, MagicMock

# Add parent directory to path to import application modules
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from Utils.ConfigManager import ConfigManager
from Utils.DirectoryParser import DirectoryParser
from Core.GitHubManager import GitHubManager
from Core.DatabaseIntegration import DatabaseIntegration
from Core.ProjectInitializer import ProjectInitializer


class TestDirectoryParser(unittest.TestCase):
    """Test cases for DirectoryParser utility."""
    
    def setUp(self):
        """Set up test environment."""
        self.Parser = DirectoryParser()
        
        # Sample directory structure
        self.SampleStructure = """
        .
        ├── Core
        ├── Docs
        │   └── API
        ├── Utils
        └── Tests
        """
    
    def test_parse_structure(self):
        """Test parsing directory structure from text."""
        # Parse sample structure
        Structure = self.Parser.ParseStructure(self.SampleStructure)
        
        # Verify structure
        self.assertIn('Core', Structure)
        self.assertIn('Docs', Structure)
        self.assertIn('Utils', Structure)
        self.assertIn('Tests', Structure)
        self.assertIn('API', Structure['Docs'])
    
    def test_format_structure(self):
        """Test formatting structure to text."""
        # Parse and then format
        Structure = self.Parser.ParseStructure(self.SampleStructure)
        FormattedLines = self.Parser.FormatStructureToText(Structure)
        
        # Verify formatted text
        self.assertTrue(any('Core' in line for line in FormattedLines))
        self.assertTrue(any('Docs' in line for line in FormattedLines))
        self.assertTrue(any('API' in line for line in FormattedLines))


class TestConfigManager(unittest.TestCase):
    """Test cases for ConfigManager utility."""
    
    def setUp(self):
        """Set up test environment."""
        # Create temporary config file
        self.TempFile = tempfile.NamedTemporaryFile(delete=False, suffix='.json')
        self.TempFile.write(b'{"TestKey": "TestValue"}')
        self.TempFile.close()
        
        # Create ConfigManager with test file
        self.ConfigManager = ConfigManager(self.TempFile.name)
    
    def tearDown(self):
        """Clean up test environment."""
        os.unlink(self.TempFile.name)
    
    def test_load_from_file(self):
        """Test loading configuration from file."""
        self.assertEqual(self.ConfigManager.Get('TestKey'), 'TestValue')
    
    def test_get_default(self):
        """Test getting value with default."""
        self.assertEqual(self.ConfigManager.Get('NonExistentKey', 'DefaultValue'), 'DefaultValue')
    
    def test_set_value(self):
        """Test setting configuration value."""
        self.ConfigManager.Set('NewKey', 'NewValue')
        self.assertEqual(self.ConfigManager.Get('NewKey'), 'NewValue')
    
    def test_get_user_config_dir(self):
        """Test getting user config directory."""
        ConfigDir = self.ConfigManager.GetUserConfigDir()
        self.assertTrue(isinstance(ConfigDir, Path))
        self.assertTrue(ConfigDir.exists())


class TestDatabaseIntegration(unittest.TestCase):
    """Test cases for DatabaseIntegration component."""
    
    def setUp(self):
        """Set up test environment."""
        # Mock ConfigManager
        self.MockConfig = MagicMock()
        self.MockConfig.Get.return_value = ':memory:'  # Use in-memory database for testing
        
        # Create DatabaseIntegration with mock config
        self.DatabaseIntegration = DatabaseIntegration(self.MockConfig)
        
        # Create temporary directory for project
        self.TempDir = Path(tempfile.mkdtemp())
        
        # Sample project config
        self.ProjectConfig = {
            'ProjectName': 'AIDEV-TestProject',
            'Description': 'Test project description',
            'GitHubAccount': 'TestAccount',
            'RepositoryName': 'TestRepo',
            'ProjectPath': str(self.TempDir)
        }
    
    def tearDown(self):
        """Clean up test environment."""
        shutil.rmtree(self.TempDir)
    
    def test_initialize_project_database(self):
        """Test initializing project database."""
        # Create in-memory database for testing
        DbPath = ':memory:'
        
        # Initialize database
        Result = self.DatabaseIntegration.InitializeProjectDatabase(DbPath, self.ProjectConfig)
        
        # Verify initialization
        self.assertTrue(Result)
        
        # Connect to database and verify tables
        Connection = sqlite3.connect(DbPath)
        Cursor = Connection.cursor()
        
        # Check if tables exist
        Cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        Tables = [row[0] for row in Cursor.fetchall()]
        
        self.assertIn('ProjectConfig', Tables)
        self.assertIn('Documentation', Tables)
        self.assertIn('HelpContent', Tables)
        self.assertIn('ProjectState', Tables)
        self.assertIn('SubProjects', Tables)
        
        Connection.close()


class TestGitHubManager(unittest.TestCase):
    """Test cases for GitHubManager component."""
    
    def setUp(self):
        """Set up test environment."""
        # Mock ConfigManager
        self.MockConfig = MagicMock()
        self.MockConfig.GetGitHubToken.return_value = 'mock_token'
        
        # Create GitHubManager with mock config
        self.GitHubManager = GitHubManager(self.MockConfig)
    
    @patch('requests.get')
    def test_validate_repository_not_found(self, MockGet):
        """Test repository validation when repo doesn't exist."""
        # Mock response for non-existent repository
        MockResponse = MagicMock()
        MockResponse.status_code = 404
        MockGet.return_value = MockResponse
        
        # Validate repository
        Result = self.GitHubManager.ValidateRepository('TestAccount', 'NonExistentRepo')
        
        # Verify result
        self.assertEqual(Result['Status'], 'NotFound')
    
    @patch('requests.get')
    def test_validate_repository_non_empty(self, MockGet):
        """Test repository validation when repo is not empty."""
        # Mock response for non-empty repository
        MockResponse = MagicMock()
        MockResponse.status_code = 200
        MockResponse.json.return_value = {'size': 100}
        MockGet.return_value = MockResponse
        
        # Validate repository
        Result = self.GitHubManager.ValidateRepository('TestAccount', 'NonEmptyRepo')
        
        # Verify result
        self.assertEqual(Result['Status'], 'NotEmpty')
    
    @patch('requests.get')
    def test_validate_repository_valid(self, MockGet):
        """Test repository validation when repo is valid."""
        # Mock response for valid repository
        MockResponse = MagicMock()
        MockResponse.status_code = 200
        MockResponse.json.return_value = {'size': 0}
        MockGet.return_value = MockResponse
        
        # Validate repository
        Result = self.GitHubManager.ValidateRepository('TestAccount', 'ValidRepo')
        
        # Verify result
        self.assertEqual(Result['Status'], 'Valid')


class TestProjectInitializer(unittest.TestCase):
    """Test cases for ProjectInitializer component."""
    
    def setUp(self):
        """Set up test environment."""
        # Mock dependencies
        self.MockConfig = MagicMock()
        self.MockGitHub = MagicMock()
        self.MockDatabase = MagicMock()
        
        # Patch dependencies
        self.GitHubPatcher = patch('Core.ProjectInitializer.GitHubManager', return_value=self.MockGitHub)
        self.DatabasePatcher = patch('Core.ProjectInitializer.DatabaseIntegration', return_value=self.MockDatabase)
        
        # Start patchers
        self.MockGitHubClass = self.GitHubPatcher.start()
        self.MockDatabaseClass = self.DatabasePatcher.start()
        
        # Create ProjectInitializer
        self.Initializer = ProjectInitializer(self.MockConfig)
        
        # Create temporary directory for project
        self.TempDir = Path(tempfile.mkdtemp())
        
        # Sample project config
        self.ProjectConfig = {
            'ProjectName': 'AIDEV-TestProject',
            'Description': 'Test project description',
            'GitHubAccount': 'TestAccount',
            'RepositoryName': 'TestRepo',
            'ProjectPath': str(self.TempDir),
            'DirectoryStructure': {
                'Core': {},
                'Docs': {'API': {}},
                'Utils': {}
            }
        }
    
    def tearDown(self):
        """Clean up test environment."""
        # Stop patchers
        self.GitHubPatcher.stop()
        self.DatabasePatcher.stop()
        
        # Remove temporary directory
        shutil.rmtree(self.TempDir)
    
    @patch('Core.ProjectInitializer.subprocess.run')
    def test_initialize_project(self, MockRun):
        """Test project initialization."""
        # Mock subprocess.run
        MockRun.return_value = MagicMock()
        
        # Mock database operations
        self.MockDatabase.InitializeProjectDatabase.return_value = True
        self.MockDatabase.CreateDatabaseLink.return_value = True
        self.MockDatabase.RegisterProject.return_value = True
        
        # Initialize project
        Result = self.Initializer.InitializeProject(self.ProjectConfig)
        
        # Verify result
        self.assertTrue(Result)
        
        # Verify directories were created
        ProjectPath = self.TempDir / 'AIDEV-TestProject'
        self.assertTrue((ProjectPath / 'Core').exists())
        self.assertTrue((ProjectPath / 'Docs').exists())
        self.assertTrue((ProjectPath / 'Docs' / 'API').exists())
        self.assertTrue((ProjectPath / 'Utils').exists())
        
        # Verify database operations were called
        self.MockDatabase.InitializeProjectDatabase.assert_called_once()
        self.MockDatabase.CreateDatabaseLink.assert_called_once()
        self.MockDatabase.RegisterProject.assert_called_once()
        
        # Verify git operations were called
        MockRun.assert_called()  # git init, add, commit


if __name__ == '__main__':
    unittest.main()

================
File: Utils/ConfigManager.py
================
# File: ConfigManager.py
# Path: AIDEV-ProjectSetup/Utils/ConfigManager.py
# Standard: AIDEV-PascalCase-1.6
# Created: 2025-03-23
# Last Modified: 2025-03-24  3:45PM
# Description: Configuration management utility

"""
Configuration management utility.

This module provides functionality for managing application configuration,
including loading from files and environment variables.
"""

import os
import json
import re
from pathlib import Path
from dotenv import load_dotenv

class ConfigManager:
    """Configuration management utility."""
    
    def __init__(self, ConfigFile=None):
        """
        Initialize configuration manager.
        
        Args:
            ConfigFile: Optional path to configuration file
        """
        # Determine base path - the root directory of the application
        self.BasePath = Path(__file__).parent.parent
        
        # Create Resources/Templates directory if it doesn't exist
        self.TemplatesPath = self.BasePath / "Resources" / "Templates"
        os.makedirs(self.TemplatesPath, exist_ok=True)
        
        # Default configuration
        self.Config = {
            "DefaultGitHubAccount": "CallMeChewy",
            "DefaultStructure": self.GetDefaultStructure(),
            "DatabasePath": str(self.GetUserConfigDir() / "Himalaya.db"),
            "TemplatesPath": str(self.TemplatesPath)
        }
        
        # Load environment variables
        load_dotenv()
        
        # Load configuration file if provided
        if ConfigFile and os.path.exists(ConfigFile):
            self.LoadFromFile(ConfigFile)
        
        # Override with environment variables
        self.LoadFromEnvironment()
    
    def GetUserConfigDir(self):
        """
        Get user configuration directory.
        
        Returns:
            Path: Path to user configuration directory
        """
        # Use platform-specific user config directory
        if os.name == 'nt':  # Windows
            ConfigDir = Path(os.environ.get('APPDATA', '.')) / "ProjectHimalaya"
        else:  # Linux/Mac
            ConfigDir = Path.home() / ".config" / "ProjectHimalaya"
        
        # Create directory if it doesn't exist
        os.makedirs(ConfigDir, exist_ok=True)
        
        return ConfigDir
    
    def GetDefaultStructure(self):
        """
        Get default directory structure.
        
        Returns:
            str: Default directory structure
        """
        return """
.
├── Core
├── Docs
│   └── API
├── GUI
├── LICENSE
├── Models
├── README.md
├── requirements.txt
├── Scripts
├── SysUtils
├── Tests
└── Utils
"""
    
    def LoadFromFile(self, FilePath):
        """
        Load configuration from JSON file.
        
        Args:
            FilePath: Path to configuration file
        """
        try:
            with open(FilePath, 'r') as File:
                FileConfig = json.load(File)
                self.Config.update(FileConfig)
        except Exception as E:
            print(f"Error loading configuration file: {str(E)}")
    
    def LoadFromEnvironment(self):
        """Load configuration from environment variables."""
        # Pattern for environment variables: AIDEV_PROJECT_SETUP_*
        EnvPattern = re.compile(r'^AIDEV_PROJECT_SETUP_(.+)$')
        
        for Key, Value in os.environ.items():
            Match = EnvPattern.match(Key)
            if Match:
                # Convert to camel case
                ConfigKey = Match.group(1).lower()
                ConfigKey = ''.join(
                    word.capitalize() if i > 0 else word.lower()
                    for i, word in enumerate(ConfigKey.split('_'))
                )
                
                # Update configuration
                self.Config[ConfigKey] = Value
    
    def Get(self, Key, Default=None):
        """
        Get configuration value.
        
        Args:
            Key: Configuration key
            Default: Default value if key doesn't exist
            
        Returns:
            Configuration value or default if not found
        """
        return self.Config.get(Key, Default)
    
    def Set(self, Key, Value):
        """
        Set configuration value.
        
        Args:
            Key: Configuration key
            Value: Configuration value
        """
        self.Config[Key] = Value
    
    def GetGitHubToken(self):
        """
        Get GitHub personal access token.
        
        Returns:
            str: GitHub PAT from environment or None
        """
        return os.environ.get('GITHUB_PAT')
    
    def SaveToFile(self, FilePath):
        """
        Save configuration to JSON file.
        
        Args:
            FilePath: Path to configuration file
        """
        try:
            with open(FilePath, 'w') as File:
                json.dump(self.Config, File, indent=2)
        except Exception as E:
            print(f"Error saving configuration file: {str(E)}")

================
File: Utils/DirectoryParser.py
================
# File: DirectoryParser.py
# Path: AIDEV-ProjectSetup/Utils/DirectoryParser.py
# Standard: AIDEV-PascalCase-1.6
# Created: 2025-03-23
# Last Modified: 2025-03-24  3:30PM
# Description: Parser for directory structure text files

"""
Directory structure parser utility.

This module provides functionality for parsing directory structure
from text files or string input in tree-like format.
"""

import re

class DirectoryParser:
    """Parser for directory structure text files."""
    
    def __init__(self):
        """Initialize DirectoryParser."""
        # Patterns for line parsing
        self.IndentPattern = re.compile(r'^(\s*)(├── |└── |│   |\s\s\s)(.+)$')
        self.DirectPattern = re.compile(r'^(\s*)(.+)$')
    
    def ParseStructure(self, Content):
        """
        Parse directory structure from string content.
        
        Args:
            Content: String containing directory structure in tree format
            
        Returns:
            Dict: Hierarchical representation of directory structure
        """
        if not Content or not isinstance(Content, str):
            return {}
            
        Lines = Content.strip().split('\n')
        Structure = {}
        
        # Skip empty lines and the root '.' line
        ProcessedLines = []
        for Line in Lines:
            Line = Line.rstrip()
            if Line and not Line.strip() == '.':
                ProcessedLines.append(Line)
        
        if not ProcessedLines:
            return Structure
        
        # Process lines with a simpler approach using just indent tracking
        PrevIndent = -1
        Path = []
        
        for Line in ProcessedLines:
            # Try to match standard tree format first
            Match = self.IndentPattern.match(Line)
            if Match:
                Indent = len(Match.group(1))
                Name = Match.group(3).strip()
            else:
                # Try direct format (just indentation)
                Match = self.DirectPattern.match(Line)
                if not Match:
                    continue
                
                Indent = len(Match.group(1))
                Name = Match.group(2).strip()
            
            # Skip files (excluding special files)
            if '.' in Name and not Name.startswith('.') and Name not in ['..', 'README.md', 'LICENSE', 'requirements.txt', '.gitignore']:
                continue
                
            # Adjust path based on indentation level
            if Indent > PrevIndent:
                # Going deeper
                Path.append(Name)
            elif Indent < PrevIndent:
                # Going back up
                LevelDiff = (PrevIndent - Indent) // 2  # Assuming standard indentation of 2 spaces
                for _ in range(LevelDiff + 1):
                    if Path:
                        Path.pop()
                Path.append(Name)
            else:
                # Same level, replace last item
                if Path:
                    Path.pop()
                Path.append(Name)
            
            # Remember current indent for next iteration
            PrevIndent = Indent
            
            # Create path in structure
            Current = Structure
            for i, PathItem in enumerate(Path[:-1]):
                if PathItem not in Current:
                    Current[PathItem] = {}
                Current = Current[PathItem]
            
            # Add current item if not already there
            if Path and Path[-1] not in Current:
                Current[Path[-1]] = {}
        
        return Structure
    
    def FormatStructureToText(self, Structure, Prefix=""):
        """
        Format directory structure to text representation.
        
        Args:
            Structure: Dictionary representing directory structure
            Prefix: Prefix for indentation (used in recursion)
            
        Returns:
            list: List of lines representing the structure
        """
        if not Structure or not isinstance(Structure, dict):
            return []
            
        Result = []
        
        # Get sorted keys
        Keys = sorted(Structure.keys())
        
        for i, Name in enumerate(Keys):
            IsLast = (i == len(Keys) - 1)
            
            # Determine prefix and connector
            if IsLast:
                Connector = "└── "
                ChildPrefix = Prefix + "    "
            else:
                Connector = "├── "
                ChildPrefix = Prefix + "│   "
            
            # Add line for current directory
            Line = Prefix + Connector + Name
            Result.append(Line)
            
            # Process children recursively
            if Structure[Name]:
                ChildLines = self.FormatStructureToText(
                    Structure[Name], ChildPrefix
                )
                Result.extend(ChildLines)
        
        return Result

================
File: cs/AIDEV-ProjectSetup Project Structure.md
================
# AIDEV-ProjectSetup Project Structure

## Core Components

### Main Application

- **Main.py**: Application entry point
- **requirements.txt**: Project dependencies

### GUI Components

- **GUI/MainWindow.py**: Main application window
- **GUI/AppStyles.py**: Application styling definitions
- **GUI/ProjectConfigPanel.py**: Project configuration panel
- **GUI/DirectoryEditor.py**: Directory structure editor

### Core Functionality

- **Core/ProjectInitializer.py**: Core project initialization functionality
- **Core/GitHubManager.py**: GitHub repository management
- **Core/DatabaseIntegration.py**: Database setup and integration

### Utilities

- **Utils/ConfigManager.py**: Configuration management
- **Utils/DirectoryParser.py**: Directory structure parsing

### Resources

- **Resources/Templates/README.md.template**: Template for README.md
- **Resources/Templates/LICENSE.template**: Template for LICENSE
- **Resources/Templates/gitignore.template**: Template for .gitignore

## Implementation Status

| Component | Status | Description |
|-----------|--------|-------------|
| Main.py | Complete | Application entry point |
| GUI/MainWindow.py | Complete | Main application window |
| GUI/AppStyles.py | Complete | Application styling |
| GUI/ProjectConfigPanel.py | Complete | Project configuration panel |
| GUI/DirectoryEditor.py | Complete | Directory structure editor |
| Core/ProjectInitializer.py | Complete | Core initialization functionality |
| Core/GitHubManager.py | Complete | GitHub repository management |
| Core/DatabaseIntegration.py | Complete | Database integration |
| Utils/ConfigManager.py | Complete | Configuration management |
| Utils/DirectoryParser.py | Complete | Directory structure parsing |
| Templates | Complete | Project templates |

## Next Steps

1. **Testing**: Create comprehensive tests for all components
2. **Error Handling**: Enhance error handling and user feedback
3. **Logging**: Add detailed logging throughout the application
4. **Documentation**: Create in-app help and documentation
5. **UI Polishing**: Refine the user interface and experience

## Dependency Graph

```
Main.py
  ├── GUI/MainWindow.py
  │     ├── GUI/AppStyles.py
  │     ├── GUI/ProjectConfigPanel.py
  │     └── GUI/DirectoryEditor.py
  ├── Core/ProjectInitializer.py
  │     ├── Core/GitHubManager.py
  │     └── Core/DatabaseIntegration.py
  └── Utils/ConfigManager.py
        └── Utils/DirectoryParser.py
```

## Folder Structure

```
AIDEV-ProjectSetup/
├── Core/
│   ├── DatabaseIntegration.py
│   ├── GitHubManager.py
│   └── ProjectInitializer.py
├── GUI/
│   ├── AppStyles.py
│   ├── DirectoryEditor.py
│   ├── MainWindow.py
│   └── ProjectConfigPanel.py
├── Utils/
│   ├── ConfigManager.py
│   └── DirectoryParser.py
├── Resources/
│   ├── Icons/
│   │   └── ProjectSetupIcon.png
│   └── Templates/
│       ├── README.md.template
│       ├── LICENSE.template
│       └── gitignore.template
├── Tests/
│   ├── UnitTests/
│   └── IntegrationTests/
├── Directories/
├── Main.py
└── requirements.txt
```

## Running the Application

To run the application:

1. Make sure you have all the dependencies installed:
   ```
   pip install -r requirements.txt
   ```

2. Run the main script:
   ```
   python Main.py
   ```

This will launch the AIDEV-ProjectSetup application with a full GUI interface for creating new projects.

================
File: cs/AIDEV-ProjectSetup: Session Continuity Document.md
================
# AIDEV-ProjectSetup: Session Continuity Document
**Created: March 23, 2025 2:30 PM**
**Last Modified: March 23, 2025  2:30 PM**

[Context: Development_Session]
[Component: Layer3_ProjectSetup]
[Status: In_Progress]
[Version: 0.1]

## Session Summary

In this session, we designed and implemented the core components of the AIDEV-ProjectSetup application, a tool for creating new projects that conform to the Project Himalaya ecosystem standards. We defined the project's architecture, developed its user interface, and implemented the core functionality for project initialization, GitHub integration, and database setup.

## Key Accomplishments

1. Created comprehensive implementation plan for the AIDEV-ProjectSetup tool
2. Designed and implemented the main application structure
3. Developed the GUI components with PySide6
4. Implemented core functionality for:
   - Directory structure creation and management
   - GitHub repository validation and integration
   - Database setup (both Himalaya.db and project-specific databases)
   - Project template generation
5. Created templates for project files (README.md, LICENSE, .gitignore)
6. Implemented database schema creation for both central and project databases
7. Defined core styling with the silver/blue/gold/red color scheme

## Current Implementation State

All core components have been implemented and are ready for initial testing:

- **Application Flow**: Complete setup wizard from project configuration to creation
- **GUI Components**: All panels and editors are implemented
- **Core Logic**: Project initialization, GitHub integration, and database setup
- **Templates**: README.md, LICENSE, .gitignore templates created
- **Database Integration**: Automatic creation of both databases if they don't exist

The implementation follows the AIDEV-PascalCase standards and adheres to the modular design principles of Project Himalaya.

## Next Steps

### 1. Testing Phase

1. **Manual Testing**:
   - Test the application by creating several test projects
   - Verify GitHub integration with test repositories
   - Validate database creation and structure
   - Test special case handling (e.g., directories with '..' prefix)

2. **Bug Fixing**:
   - Address any issues discovered during testing
   - Refine error handling and user feedback
   - Enhance edge case handling

3. **Automated Testing**:
   - Create unit tests for core components
   - Implement integration tests for workflow validation
   - Setup CI/CD pipeline for ongoing testing

### 2. Enhancement Phase

1. **UI Enhancements**:
   - Implement progress visualization during project creation
   - Add animations and transitions for better user experience
   - Enhance visual feedback for validation results
   - Improve form layouts and responsiveness

2. **Feature Additions**:
   - Recent projects tracking
   - Multiple project templates
   - Template customization options
   - Database browser/viewer integration

3. **Documentation**:
   - In-app help system
   - User guide
   - Developer documentation
   - API reference

### 3. Refinement Phase

1. **Performance Optimization**:
   - Profile and optimize critical operations
   - Reduce startup time
   - Minimize memory usage

2. **User Experience Improvements**:
   - Conduct user testing
   - Refine workflows based on feedback
   - Add keyboard shortcuts
   - Improve accessibility

3. **Integration Enhancements**:
   - Tighter integration with other Project Himalaya tools
   - Enhanced database schema synchronization
   - More sophisticated GitHub integration

## Required Resources

1. **Testing Environment**:
   - Multiple test GitHub accounts/repositories
   - Various test project configurations
   - Different operating systems for cross-platform testing

2. **Development Resources**:
   - Additional icons and visual assets
   - More comprehensive template library
   - Database schema documentation

3. **Feedback Channels**:
   - Developer testing group
   - User experience evaluation
   - Integration testing with other Project Himalaya components

## Notes and Considerations

- The application currently creates both databases automatically if they don't exist, which simplifies initial testing (databases can be manually deleted between tests)
- The GitHub integration uses personal access tokens which will need to be properly secured in production
- The application follows a wizard-style flow which provides a clear, step-by-step experience
- Database schema is flexible to accommodate future expansion

---

*"Project Himalaya redefines software development by elevating AI to the role of primary implementer while positioning humans as strategic architects. Through rigorous standards, comprehensive testing, and database-driven accountability, we establish a new paradigm where quality, transparency, and continuity are inherent to the process rather than aspirational goals."*

— Herbert J. Bowers

================
File: cs/AIDEV-ProjectSetup Test Automation.md
================
# AIDEV-ProjectSetup Test Automation

This directory contains automated tests for the AIDEV-ProjectSetup application. These tests are designed to verify the functionality of all core components and their integration.

## Test Structure

The test suite is organized as follows:

- **Unit Tests**: Test individual components in isolation
- **Integration Tests**: Test interactions between components
- **End-to-End Tests**: Test complete workflows

## Running the Tests

To run all tests and generate a report:

```bash
python run_tests.py
```

To run specific test modules:

```bash
# Run unit tests only
python -m unittest Tests/UnitTests/test_project_setup.py

# Run integration tests only
python -m unittest Tests/IntegrationTests/test_integration.py
```

## Test Coverage

These tests cover the following core functionality:

### Unit Tests

- **DirectoryParser**: Parsing and formatting directory structures
- **ConfigManager**: Configuration loading and management
- **DatabaseIntegration**: Database initialization and schema creation
- **GitHubManager**: Repository validation and management
- **ProjectInitializer**: Project creation and setup

### Integration Tests

- **End-to-End Project Creation**: Full project setup process
- **Database Integration Flow**: Complete database setup and registration

## Test Dependencies

The tests use the following Python packages:

- unittest (standard library)
- tempfile (standard library)
- sqlite3 (standard library)
- unittest.mock (standard library)

## Adding New Tests

When adding new tests, please follow these guidelines:

1. **Naming Convention**: Test files should be named `test_*.py`
2. **Class Structure**: Each test class should inherit from `unittest.TestCase`
3. **Test Naming**: Test methods should start with `test_` and have descriptive names
4. **Setup/Teardown**: Use `setUp` and `tearDown` methods for test environment setup
5. **Mocking**: Use patches and mocks to isolate tests from external dependencies
6. **Test Documentation**: Include docstrings describing the purpose of each test

## Test Reports

Test reports are generated in the `TestReports` directory with timestamped filenames. These reports include:

- Test count and execution time
- Pass/fail statistics
- Detailed failure information
- Overall success rate

## Continuous Integration

These tests are designed to be run in a CI/CD pipeline. To integrate with GitHub Actions:

1. Create a `.github/workflows/tests.yml` file in your repository
2. Configure it to run `python run_tests.py` on push and pull requests
3. Set up failure notifications and reporting

## Troubleshooting

If tests fail, check the following:

1. **Dependencies**: Ensure all required packages are installed
2. **Environment**: Verify the test environment matches the expected configuration
3. **Mocks**: Ensure mocks are correctly configured for the expected behaviors
4. **Database**: Check database connection and schema issues
5. **File Paths**: Verify path

================
File: cs/AIDEV-ProjectSetup: Test Plan.md
================
# AIDEV-ProjectSetup: Test Plan
**Created: March 23, 2025 3:15 PM**
**Last Modified: March 23, 2025  3:15 PM**

[Context: Testing_Documentation]
[Component: Layer3_ProjectSetup]
[Status: Active]
[Version: 1.0]

## 1. Test Objectives

This test plan aims to verify that the AIDEV-ProjectSetup application correctly:
- Creates new projects with proper directory structure
- Sets up and configures databases (both Himalaya.db and project-specific)
- Integrates with GitHub repositories
- Provides an intuitive and responsive user interface
- Handles errors gracefully
- Follows all Project Himalaya standards and conventions

## 2. Test Environment Setup

### 2.1 Prerequisites

- Python 3.8 or higher
- PySide6 installed (pip install PySide6)
- python-dotenv installed (pip install python-dotenv)
- requests installed (pip install requests)
- Git installed and configured
- GitHub account with permission to create repositories
- GitHub Personal Access Token with repo scope

### 2.2 Test Configuration

- Create a `.env` file in the project root with `GITHUB_PAT=your_token_here`
- Backup and then delete any existing Himalaya.db to test fresh creation
- Ensure test directories are empty before each test run

## 3. Functional Test Cases

### 3.1 Application Startup Tests

| Test ID | Description | Steps | Expected Result |
|---------|-------------|-------|-----------------|
| ST-01 | Basic application startup | Run `python Main.py` | Application launches with main window visible |
| ST-02 | Configuration loading | Run application | Default configuration loads successfully |
| ST-03 | UI components display | Run application | All UI components render correctly with proper styling |

### 3.2 Project Configuration Tests

| Test ID | Description | Steps | Expected Result |
|---------|-------------|-------|-----------------|
| PC-01 | Project name validation | 1. Enter invalid project name (no AIDEV- prefix)<br>2. Click Next | Error message displayed |
| PC-02 | Project name validation (success) | 1. Enter valid project name (e.g., AIDEV-TestProject)<br>2. Click Next | Validation passes, advances to next step |
| PC-03 | Project location selection | 1. Click Browse button<br>2. Select a directory | Selected path appears in location field |
| PC-04 | GitHub account validation | 1. Clear GitHub account field<br>2. Click Next | Error message displayed |
| PC-05 | License selection | Select different license options | Selected license is recorded in configuration |

### 3.3 Directory Structure Tests

| Test ID | Description | Steps | Expected Result |
|---------|-------------|-------|-----------------|
| DS-01 | Default structure loading | Click "Load Default" button | Default structure displayed in tree view |
| DS-02 | Structure from file | 1. Create custom structure text file<br>2. Click "Load from File"<br>3. Select the file | Custom structure displayed in tree view |
| DS-03 | Adding folder | 1. Click "Add Folder" button<br>2. Enter folder name | New folder appears in tree view |
| DS-04 | Removing folder | 1. Select a folder<br>2. Click "Remove Folder" button<br>3. Confirm deletion | Folder is removed from tree view |
| DS-05 | Renaming folder | 1. Right-click a folder<br>2. Select "Rename Folder"<br>3. Enter new name | Folder name is updated in tree view |
| DS-06 | Structure validation | Empty the tree view and click Next | Error message displayed |

### 3.4 Project Creation Tests

| Test ID | Description | Steps | Expected Result |
|---------|-------------|-------|-----------------|
| CR-01 | Basic project creation | Complete wizard with valid inputs and click "Create Project" | Project is created with success message |
| CR-02 | Directory structure creation | Create a project with default structure | All directories created as specified |
| CR-03 | File generation | Create a project | README.md, LICENSE, .gitignore created with correct content |
| CR-04 | Himalaya.db creation | Create a project with no existing Himalaya.db | Himalaya.db is created in user config dir with required tables |
| CR-05 | Project database creation | Create a project | Project-specific database created in Directories folder |
| CR-06 | Database linking | Create a project | Symbolic link (or copy) to Himalaya.db created in Directories folder |
| CR-07 | Git initialization | Create a project | Git repository initialized with initial commit |
| CR-08 | GitHub integration | Create a project with valid GitHub settings | Repository connected and initial code pushed |

### 3.5 Error Handling Tests

| Test ID | Description | Steps | Expected Result |
|---------|-------------|-------|-----------------|
| EH-01 | Project directory exists | Try to create a project in existing directory | Error message displayed |
| EH-02 | Invalid GitHub credentials | Use invalid GitHub PAT | Error message displayed with specific issue |
| EH-03 | Network failure | Disconnect from network and try GitHub integration | Graceful error handling with message |
| EH-04 | Permission issues | Create project in location without write permission | Clear error message displayed |
| EH-05 | Database corruption | Create corrupted database file and run app | Application detects and attempts recovery |

## 4. Integration Test Cases

### 4.1 GitHub Integration

| Test ID | Description | Steps | Expected Result |
|---------|-------------|-------|-----------------|
| GH-01 | Repository validation | Test with existing empty repository | Validation passes |
| GH-02 | Repository validation | Test with non-existent repository | Validation fails with informative message |
| GH-03 | Repository validation | Test with non-empty repository | Validation fails with message about repository not being empty |
| GH-04 | Push to repository | Create project with GitHub integration | Code successfully pushed to remote repository |
| GH-05 | Update script | Run generated update script in created project | Changes committed and pushed to repository |

### 4.2 Database Integration

| Test ID | Description | Steps | Expected Result |
|---------|-------------|-------|-----------------|
| DB-01 | Himalaya.db project registration | Create a project | Project properly registered in Himalaya.db |
| DB-02 | Project database initialization | Create a project | All required tables created in project database |
| DB-03 | Initial data insertion | Create a project | Configuration data inserted into project database |
| DB-04 | Cross-database relationships | Query Himalaya.db for project, then access project DB | References are consistent and correct |
| DB-05 | Multiple project registration | Create multiple projects | All projects properly registered without conflicts |

## 5. User Interface Tests

### 5.1 Usability

| Test ID | Description | Steps | Expected Result |
|---------|-------------|-------|-----------------|
| UI-01 | Wizard navigation | Navigate forward and backward through wizard | Navigation works correctly, validation maintained |
| UI-02 | Form interactions | Test all input fields, buttons, and controls | All controls responsive and functional |
| UI-03 | Visual feedback | Trigger validation errors and successes | Clear visual indicators of state |
| UI-04 | Dialog operations | Test all dialogs (file selection, confirmation, etc.) | Dialogs display correctly and return proper values |
| UI-05 | Styling consistency | Inspect all UI components | Consistent styling per silver/blue/gold/red theme |

### 5.2 Responsiveness

| Test ID | Description | Steps | Expected Result |
|---------|-------------|-------|-----------------|
| RE-01 | Window resizing | Resize application window | UI adapts appropriately |
| RE-02 | Long operations | Create project with many directories | UI remains responsive, shows progress |
| RE-03 | Large file handling | Test with large custom directory structure | Application handles efficiently |

## 6. Security Tests

| Test ID | Description | Steps | Expected Result |
|---------|-------------|-------|-----------------|
| SE-01 | Token handling | Check for token exposure in logs or UI | Token never visible in plain text |
| SE-02 | Database security | Examine database files and connections | Proper permissions on created files |
| SE-03 | File path validation | Try path traversal in input fields | Validation prevents dangerous paths |

## 7. Compatibility Tests

| Test ID | Description | Steps | Expected Result |
|---------|-------------|-------|-----------------|
| CO-01 | Windows compatibility | Run on Windows | Application functions correctly |
| CO-02 | Linux compatibility | Run on Linux | Application functions correctly |
| CO-03 | macOS compatibility | Run on macOS | Application functions correctly |
| CO-04 | Python version compatibility | Test with Python 3.8, 3.9, 3.10 | Works across supported versions |

## 8. Performance Tests

| Test ID | Description | Steps | Expected Result |
|---------|-------------|-------|-----------------|
| PE-01 | Startup time | Measure application startup time | Startup under 2 seconds |
| PE-02 | Project creation time | Measure time to create a standard project | Complete in under 10 seconds (excluding network) |
| PE-03 | Memory usage | Monitor memory during operation | Memory usage remains under 200MB |
| PE-04 | CPU usage | Monitor CPU during operation | CPU spikes only during intensive operations |

## 9. Test Execution

### 9.1 Manual Testing Procedure

1. Set up test environment as specified in Section 2
2. Execute test cases in the following order:
   - Application Startup Tests
   - Project Configuration Tests
   - Directory Structure Tests
   - Project Creation Tests
   - Error Handling Tests
   - Integration Tests
   - UI Tests
   - Security Tests
   - Compatibility Tests
   - Performance Tests
3. Document all test results, including:
   - Pass/Fail status
   - Actual results
   - Screenshots of issues
   - Environment details for failures

### 9.2 Automated Testing

For future implementation, automated tests should be created for:
- Unit testing of all core classes and methods
- Integration testing of major workflows
- UI testing of critical paths

## 10. Test Deliverables

The following deliverables should be produced during testing:
- Completed test results log
- Issue reports for all failures
- Performance measurements
- Recommendations for improvements
- Final test summary report

## 11. Test Exit Criteria

Testing is considered complete when:
1. All critical and high-priority test cases pass
2. No critical or high-severity issues remain unresolved
3. All core functionality works as specified
4. Application meets performance requirements
5. All databases are created and populated correctly

---

*"Project Himalaya redefines software development by elevating AI to the role of primary implementer while positioning humans as strategic architects. Through rigorous standards, comprehensive testing, and database-driven accountability, we establish a new paradigm where quality, transparency, and continuity are inherent to the process rather than aspirational goals."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/00-00 INDEX-DocumentMaster.md
================
# INDEX-DocumentMaster
**Created: March 22, 2025 5:00 PM**
**Last Modified: March 22, 2025  5:00PM**

[Context: Knowledge_Organization]
[Status: Active]
[Version: 1.0]

## 1. Project Himalaya Documentation Structure

This document serves as the master index for all Project Himalaya framework documentation. It defines the organization, naming conventions, and expected document types within each category.

## 2. Document Categories and Filenames

### 2.1 Navigation & Status (00-series)
Documents that help navigate the knowledge base and track project status.

| Filename | Purpose | Content Type |
|----------|---------|--------------|
| 00-00 INDEX-DocumentMaster.md | Master index of all documents | Index |
| 00-10 GUIDE-DocumentMap.md | Guide to document organization | Guide |
| 00-20 STATUS-ProjectHimalaya.md | Current project status | Status Report |
| 00-30 GUIDE-ActiveSessions.md | Tracks current and recent sessions | Guide/Log |
| 00-40 LOG-Decisions.md | Record of key decisions | Log |
| 00-50 INDEX-DocumentRegistry.md | Detailed listing of all documents | Index |
| 00-60 GUIDE-AIAssistantOnboarding.md | Guidance for AI assistants | Guide |

### 2.2 Project Vision (10-series)
Documents defining the project's purpose, scope, and high-level plans.

| Filename | Purpose | Content Type |
|----------|---------|--------------|
| 10-10 VISION-ProjectHimalaya.md | Core vision and mission | Vision |
| 10-20 PLAN-ProjectRoadmap.md | Project timeline and milestones | Plan |
| 10-30 SCOPE-ProjectHimalaya.md | Project scope definition | Scope |
| 10-40 CHARTER-ProjectValues.md | Core values and principles | Charter |
| 10-50 REQ-ProjectRequirements.md | High-level project requirements | Requirements |
| 10-60 REQ-ComponentRequirements.md | Component-specific requirements | Requirements |

### 2.3 Standards (20-series)
Documents defining technical standards and conventions.

| Filename | Purpose | Content Type |
|----------|---------|--------------|
| 20-10 STANDARD-AIDEV-PascalCase.md | Coding standard definition | Standard |
| 20-20 STANDARD-CodingConventions.md | General coding practices | Standard |
| 20-30 STANDARD-ArchitecturalPrinciples.md | Architectural guidelines | Standard |
| 20-40 STANDARD-DocumentationRequirements.md | Documentation requirements | Standard |
| 20-50 STANDARD-DatabaseSchema.md | Database design standards | Standard |
| 20-60 STANDARD-SecurityPrinciples.md | Security guidelines | Standard |
| 20-70 STANDARD-ErrorHandling.md | Error handling approach | Standard |

### 2.4 Templates (30-series)
Reusable document templates for various purposes.

| Filename | Purpose | Content Type |
|----------|---------|--------------|
| 30-10 TEMPLATE-ImplementationPlan.md | Template for implementation plans | Template |
| 30-20 TEMPLATE-ComponentSpecification.md | Template for component specs | Template |
| 30-30 TEMPLATE-SubProjectReference.md | Template for sub-project reference | Template |
| 30-40 TEMPLATE-SessionContinuity.md | Template for session handover | Template |
| 30-50 TEMPLATE-TestCase.md | Template for test cases | Template |
| 30-60 TEMPLATE-APIDocumentation.md | Template for API docs | Template |
| 30-70 TEMPLATE-RequirementsSpecification.md | Template for requirements | Template |

### 2.5 Knowledge Organization (40-series)
Documents about the knowledge management system itself.

| Filename | Purpose | Content Type |
|----------|---------|--------------|
| 40-10 ARCH-KnowledgeStructure.md | Overall knowledge organization | Architecture |
| 40-20 ARCH-KnowledgeDatabase.md | Knowledge database design | Architecture |
| 40-30 STANDARD-MetadataSchema.md | Metadata standards | Standard |
| 40-40 GUIDE-DocumentationStyle.md | Writing style guidelines | Guide |
| 40-50 TAXONOMY-ProjectTerminology.md | Standard terminology | Taxonomy |
| 40-60 MATRIX-RequirementsTraceability.md | Requirements mapping | Matrix |

### 2.6 Framework Implementation (50-series)
Implementation details for core framework components.

| Filename | Purpose | Content Type |
|----------|---------|--------------|
| 50-10 IMPL-DocumentManagerComponent.md | Document manager implementation | Implementation |
| 50-20 IMPL-StateManagerComponent.md | State manager implementation | Implementation |
| 50-30 IMPL-StandardsValidatorComponent.md | Standards validator implementation | Implementation |
| 50-40 IMPL-TaskManagerComponent.md | Task manager implementation | Implementation |
| 50-50 IMPL-AIInterfaceComponent.md | AI interface implementation | Implementation |

### 2.7 Testing (60-series)
Documents related to testing strategy and execution.

| Filename | Purpose | Content Type |
|----------|---------|--------------|
| 60-10 PLAN-TestStrategy.md | Overall testing approach | Plan |
| 60-20 SPEC-TestRequirements.md | Test requirements | Specification |
| 60-30 GUIDE-TestingProcedures.md | Testing procedures | Guide |
| 60-40 TEMPLATE-TestSuite.md | Test suite template | Template |
| 60-50 LOG-TestResults.md | Test results records | Log |
| 60-60 MATRIX-RequirementsCoverage.md | Test coverage matrix | Matrix |

### 2.8 User Documentation (70-series)
End-user facing documentation.

| Filename | Purpose | Content Type |
|----------|---------|--------------|
| 70-10 GUIDE-UserManual.md | User manual | Guide |
| 70-20 GUIDE-APIReference.md | API reference | Guide |
| 70-30 GUIDE-InstallationSetup.md | Installation instructions | Guide |
| 70-40 GUIDE-Troubleshooting.md | Troubleshooting guide | Guide |

### 2.9 Archives (80-series)
Archives of historical data and completed components.

| Filename | Purpose | Content Type |
|----------|---------|--------------|
| 80-10 ARCHIVE-SessionLogs.md | Historical session logs | Archive |
| 80-20 ARCHIVE-CompletedComponents.md | Completed component archive | Archive |
| 80-30 INDEX-HistoricalSessions.md | Index of past sessions | Index |
| 80-40 ARCHIVE-RequirementsVersions.md | Past requirements versions | Archive |

### 2.10 External References (90-series)
References to external resources and standards.

| Filename | Purpose | Content Type |
|----------|---------|--------------|
| 90-10 REF-ExternalLibraries.md | External library references | Reference |
| 90-20 REF-ResearchPapers.md | Research paper references | Reference |
| 90-30 REF-ToolingEnvironment.md | Development tools reference | Reference |
| 90-40 REF-AICollaborationTechniques.md | AI collaboration methods | Reference |
| 90-50 STANDARD-IndustryRequirements.md | Industry standards reference | Reference |

## 3. Document Prefixes

The document prefix indicates the type of content within the document.

| Prefix | Description | Example |
|--------|-------------|---------|
| ARCH- | Architectural documentation | ARCH-KnowledgeStructure.md |
| ARCHIVE- | Archived historical content | ARCHIVE-SessionLogs.md |
| CHARTER- | Foundational principles | CHARTER-ProjectValues.md |
| GUIDE- | Instructions and guidance | GUIDE-DocumentMap.md |
| IMPL- | Implementation details | IMPL-DocumentManagerComponent.md |
| INDEX- | Document listings | INDEX-DocumentRegistry.md |
| LOG- | Records of activities | LOG-Decisions.md |
| MATRIX- | Relationship mapping | MATRIX-RequirementsTraceability.md |
| PLAN- | Planning documentation | PLAN-TestStrategy.md |
| REF- | Reference information | REF-ExternalLibraries.md |
| REQ- | Requirements documentation | REQ-ProjectRequirements.md |
| SCOPE- | Scope definition | SCOPE-ProjectHimalaya.md |
| SPEC- | Detailed specifications | SPEC-TestRequirements.md |
| STANDARD- | Standards definition | STANDARD-AIDEV-PascalCase.md |
| STATUS- | Status reporting | STATUS-ProjectHimalaya.md |
| TAXONOMY- | Classification system | TAXONOMY-ProjectTerminology.md |
| TEMPLATE- | Reusable document templates | TEMPLATE-TestCase.md |
| VISION- | Vision statements | VISION-ProjectHimalaya.md |

## 4. Sub-Project Integration

### 4.1 Sub-Project Structure
Sub-projects should maintain a similar structure but with project-specific prefixes:

```
SubProject/
├── README.md
├── docs/
│   ├── 00-10 GUIDE-ProjectOverview.md
│   ├── 10-10 SCOPE-ProjectScope.md
│   ├── 20-10 SPEC-ComponentSpecifications.md
│   ├── 30-10 IMPL-CoreImplementation.md
│   └── 40-10 GUIDE-UserManual.md
├── src/
│   └── [Implementation files]
└── tests/
    └── [Test files]
```

### 4.2 Cross-Referencing
Documents should cross-reference between the framework and sub-projects using:

- Framework to Sub-project: `[SubProject/docs/10-10]`
- Sub-project to Framework: `[Framework/10-30]`

## 5. Document Creation Process

1. Identify the appropriate category for the new document
2. Select the next available number in that series
3. Choose the appropriate prefix for the document type
4. Create document using corresponding template
5. Add to document registry (00-50)
6. Update document map (00-10) if necessary

## 6. Standard Metadata

All documents should include standard metadata:

```markdown
# [Document Title]
**Created: [Month Day, Year] [Time AM/PM]**
**Last Modified: [Month Day, Year] [Time AM/PM]**

[Context: Category_Name]
[Status: Status_Value]
[Version: X.Y]
```

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/00-10 GUIDE-DocumentMap.md
================
# GUIDE-DocumentMap
**Created: March 22, 2025 2:30 PM**
**Last Modified: March 22, 2025  2:30PM**

[Context: Knowledge_Organization]
[Status: Active]
[Version: 1.0]

## 1. Document Numbering System

The Project Himalaya Knowledge Database uses a hierarchical numbering system to organize all documents. This system ensures intuitive navigation and clear relationships between documents.

### 1.1 Numbering Format

Documents follow this naming pattern:
```
[Series]-[Subseries] [Type]-[Topic].md
```

Example: `10-20 SCOPE-ProjectHimalaya.md`

- **Series (first two digits)**: Major category
- **Subseries (second two digits)**: Specific area within category
- **Type**: Document purpose (e.g., SPEC, PLAN, GUIDE)
- **Topic**: Subject matter

### 1.2 Series Categories

| Series | Purpose | Key Documents |
|--------|---------|---------------|
| 00     | Status & Navigation | Current project status, document maps, active sessions |
| 10     | Vision & Scope | Project vision, scope definition, roadmap |
| 20     | Standards | Coding standards, design principles, documentation standards |
| 30     | Templates | Reusable document templates for various purposes |
| 40     | Knowledge Organization | Database structure, metadata standards, taxonomy |
| 50     | Implementation | Implementation plans and details for active components |
| 60     | Testing | Test plans, test cases, testing frameworks |
| 70     | Documentation | User guides, API documentation, tutorials |
| 80     | Session Archives | Historical development session records |
| 90     | Reference Materials | External references, research notes, examples |

## 2. Core Documents

### 2.1 Project Foundation

| Document | Purpose | Update Frequency |
|----------|---------|------------------|
| [00-20 STATUS-ProjectHimalaya.md](00-20%20STATUS-ProjectHimalaya.md) | Current project status | Every session |
| [00-30 GUIDE-ActiveSessions.md](00-30%20GUIDE-ActiveSessions.md) | Tracks ongoing and recent sessions | Every session |
| [00-40 LOG-Decisions.md](00-40%20LOG-Decisions.md) | Record of key project decisions | As decisions occur |
| [10-10 VISION-ProjectHimalaya.md](10-10%20VISION-ProjectHimalaya.md) | Project vision and philosophy | Quarterly review |
| [10-20 SCOPE-ProjectHimalaya.md](10-20%20SCOPE-ProjectHimalaya.md) | Comprehensive scope definition | Monthly review |
| [20-10 STANDARD-AIDEV-PascalCase.md](20-10%20STANDARD-AIDEV-PascalCase.md) | Coding standards | As needed |
| [20-30 STANDARD-FoundationDesignPrinciples.md](20-30%20STANDARD-FoundationDesignPrinciples.md) | Core design principles | Quarterly review |

### 2.2 Implementation Documents

| Document | Purpose | Update Frequency |
|----------|---------|------------------|
| [50-10 IMPL-DocumentManager.md](50-10%20IMPL-DocumentManager.md) | DocumentManager implementation | As developed |
| [50-20 IMPL-StateManager.md](50-20%20IMPL-StateManager.md) | StateManager implementation | As developed |
| [50-30 IMPL-StandardsValidator.md](50-30%20IMPL-StandardsValidator.md) | StandardsValidator implementation | As developed |

### 2.3 Templates

| Document | Purpose | Usage |
|----------|---------|-------|
| [30-10 TEMPLATE-ComponentPlan.md](30-10%20TEMPLATE-ComponentPlan.md) | Planning component implementation | New components |
| [30-20 TEMPLATE-ComponentSpec.md](30-20%20TEMPLATE-ComponentSpec.md) | Component specification | New components |
| [30-30 TEMPLATE-ReferenceSubproject.md](30-30%20TEMPLATE-ReferenceSubproject.md) | Subproject reference | New subprojects |
| [30-40 TEMPLATE-SessionContinuity.md](30-40%20TEMPLATE-SessionContinuity.md) | Session handover | End of sessions |
| [30-50 TEMPLATE-TestCase.md](30-50%20TEMPLATE-TestCase.md) | Test case definition | Component testing |

## 3. Navigation Guidance

### 3.1 For First-Time AI Assistants

If you're an AI assistant joining this project for the first time, follow this sequence:

1. Review [00-20 STATUS-ProjectHimalaya.md](00-20%20STATUS-ProjectHimalaya.md) for current status
2. Examine [10-20 SCOPE-ProjectHimalaya.md](10-20%20SCOPE-ProjectHimalaya.md) for project scope
3. Study [20-30 STANDARD-FoundationDesignPrinciples.md](20-30%20STANDARD-FoundationDesignPrinciples.md) for design principles
4. Check [30-40 TEMPLATE-SessionContinuity.md](30-40%20TEMPLATE-SessionContinuity.md) for previous session context
5. Refer to [50-series documents](50-10%20IMPL-DocumentManager.md) for current implementation details

### 3.2 For Recurring AI Assistants

If you're returning to the project:

1. Note any updates in [00-20 STATUS-ProjectHimalaya.md](00-20%20STATUS-ProjectHimalaya.md)
2. Review recent sessions in [00-30 GUIDE-ActiveSessions.md](00-30%20GUIDE-ActiveSessions.md)
3. Check for new decisions in [00-40 LOG-Decisions.md](00-40%20LOG-Decisions.md)
4. Focus on the current implementation documents in the 50-series

### 3.3 For Human Developers

Human developers should:

1. Update [00-20 STATUS-ProjectHimalaya.md](00-20%20STATUS-ProjectHimalaya.md) at the beginning and end of each session
2. Record key decisions in [00-40 LOG-Decisions.md](00-40%20LOG-Decisions.md)
3. Ensure the latest implementation details are reflected in 50-series documents
4. Create session continuity documents using [30-40 TEMPLATE-SessionContinuity.md](30-40%20TEMPLATE-SessionContinuity.md)

## A4. Cross-Referencing System

All documents should use the following cross-referencing approaches:

1. **Document References**: Use bracketed document numbers, e.g., [10-20]
2. **Section References**: Use document number plus section, e.g., [10-20 §3.2]
3. **Decision References**: Use decision log ID, e.g., [DECISION-2025-03-22-1]
4. **Component References**: Use component name with layer, e.g., [Layer1_DocumentManager]

## 5. Document Lifecycle

### 5.1 Creation Guidelines

1. Use the appropriate template from the 30-series
2. Assign the next available number in the appropriate series
3. Include all required metadata headers
4. Add cross-references to related documents
5. Add to this document map

### 5.2 Update Process

1. Update the "Last Modified" timestamp
2. Add entry to version history section
3. Update cross-references if needed
4. Note significant changes in STATUS document

### 5.3 Archiving Process

1. Move deprecated documents to the 80-series
2. Update references in this map
3. Maintain a reference in the original location

## 6. Document Map Maintenance

This document map itself should be updated:

1. Whenever a new document is added to the knowledge base
2. When document relationships change significantly
3. When the document organization system is modified
4. After any major project milestone

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/00-20 STATUS-ProjectHimalaya.md
================
# STATUS-ProjectHimalaya
**Created: March 22, 2025 1:45 PM**
**Last Modified: March 22, 2025  1:45PM**

[Context: Project_Status]
[Status: Active]
[Version: 0.1]

## 1. Current Development Status

### 1.1 Overall Project Status
- **Phase**: Foundation (Layer 1 components)
- **Current Milestone**: Infrastructure Components
- **Progress**: 10% complete
- **Recent Activity**: Initial scope and foundation documents created

### 1.2 Active Components and Status

| Component | Layer | Status | Progress | Current Focus | Next Steps |
|-----------|-------|--------|----------|--------------|------------|
| DocumentManager | 1 | Specification | 30% | API design | Data models |
| StateManager | 1 | Planning | 10% | Initial concepts | Detailed design |
| StandardsValidator | 1 | Concept | 5% | Requirements | Initial design |
| OllamaModelEditor | 4 | Planning | 15% | Architecture | Component design |

### 1.3 Recent Achievements
- Completed Project Himalaya scope definition
- Established Knowledge Database structure
- Created foundational document templates
- Defined architectural principles
- Established core design standards

## 2. Current Session Information

### 2.1 Active Session
- **Session ID**: [Current Session ID]
- **Start Time**: [Current Session Start Time]
- **Focus**: [Current Session Focus]
- **Participants**: [Participants in Current Session]

### 2.2 Recent Sessions

| Session ID | Date | Focus | Key Outcomes |
|------------|------|-------|--------------|
| [Previous Session ID] | [Date] | [Focus] | [Brief summary of outcomes] |
| [Previous Session ID] | [Date] | [Focus] | [Brief summary of outcomes] |

## 3. Development Priorities

### 3.1 Immediate Priorities (Next 1-2 Sessions)
1. Complete DocumentManager detailed specification
2. Begin DocumentManager implementation
3. Start StateManager detailed design
4. Set up initial Project Knowledge Database structure

### 3.2 Short-Term Priorities (Next 2-4 Weeks)
1. Complete Layer 1 (Core Infrastructure) components
2. Begin TaskManager design (first Layer 2 component)
3. Create testing infrastructure for components
4. Establish automated validation of standards

### 3.3 Medium-Term Priorities (Next 1-2 Months)
1. Complete Layer 2 (Communication Framework) components
2. Begin Layer 3 (Development Tools) components
3. Start OllamaModelEditor core framework
4. Implement advanced DocumentManager features

## 4. Open Issues and Decisions

### 4.1 Pending Decisions

| Decision | Options | Status | Impact | Deadline |
|----------|---------|--------|--------|----------|
| Vector database selection | Chroma vs. Qdrant | Under evaluation | Affects semantic search | Week 2 |
| Database schema approach | Centralized vs. Distributed | Under discussion | Affects all components | Week 1 |
| Testing framework | pytest vs. custom | Under evaluation | Affects all components | Week 2 |

### 4.2 Technical Challenges

| Challenge | Description | Severity | Components Affected | Status |
|-----------|-------------|----------|---------------------|--------|
| Session continuity | Maintaining state between sessions | High | All | Working solution defined |
| RAG implementation | Efficient document retrieval | Medium | DocumentManager | Initial design |
| Performance optimization | Ensuring responsive components | Medium | All | Planning stage |

### 4.3 Risks and Mitigations

| Risk | Likelihood | Impact | Mitigation Strategy | Owner |
|------|------------|--------|---------------------|-------|
| Scope creep | High | High | Regular scope reviews, clear boundaries | Project Management |
| Technical debt | Medium | High | Regular refactoring, standards enforcement | Development |
| Knowledge fragmentation | Medium | High | Centralized knowledge management | Documentation |

## 5. Resource Allocation

### 5.1 Current Resources
- **Development**: Primary developer plus AI assistance
- **Design**: Architecture and UI design resources
- **Testing**: Manual testing with automation planned
- **Documentation**: Integrated with development process

### 5.2 Resource Constraints
- Limited development time availability
- AI session context limitations
- Single-developer scenario for most tasks

### 5.3 Resource Needs
- Additional testing automation
- Improved knowledge management tools
- Better session continuity mechanisms

## 6. Metrics and Progress Tracking

### 6.1 Key Performance Indicators
- **Documentation Coverage**: 90% (goal: 100%)
- **Standards Compliance**: 95% (goal: 100%)
- **Component Completion**: 5% (goal: 100%)
- **Test Coverage**: 0% (goal: 80%+)

### 6.2 Milestone Progress
- **Foundation Establishment**: 40% complete
- **Layer 1 Components**: 10% complete
- **Documentation Framework**: 70% complete
- **Standards Implementation**: 30% complete

## 7. Next Session Planning

### 7.1 Proposed Focus
- Complete DocumentManager specification
- Define database schema for DocumentManager
- Begin implementation plan for DocumentManager
- Set up initial directory structure for Knowledge Database

### 7.2 Required Preparation
- Review current DocumentManager specification
- Research SQLite optimization techniques
- Prepare metadata schema examples
- Review standard file operations in Python

### 7.3 Expected Outcomes
- Complete DocumentManager spec document
- Database schema definition
- Implementation plan for DocumentManager
- Initial Knowledge Database structure

---

*This status document should be updated at the beginning and end of each development session to maintain continuity and track progress.*

================
File: cs/KnowledgeDatabaseIndex/00-40 LOG-Decisions.md
================
# LOG-Decisions
**Created: March 22, 2025 3:00 PM**
**Last Modified: March 22, 2025  3:00PM**

[Context: Project_Governance]
[Status: Active]
[Version: 1.0]

## 1. Decision Log Purpose

This document maintains a chronological record of all significant project decisions, providing:
- Clear documentation of decision rationale
- Traceability for architectural and design choices
- Historical context for future development
- Reference for onboarding new participants

Each decision includes background information, alternatives considered, rationale, and implementation implications.

## 2. Recent Decisions

### DECISION-20250322-1: Bottom-Up Development Approach
**Date**: March 22, 2025
**Decision Maker**: Herbert J. Bowers
**Type**: Architectural/Process

**Context**:
Initial project planning used a top-down approach, starting with applications and working downward. This approach proved challenging due to the complexity of implementing higher-level components without a solid foundation.

**Alternatives Considered**:
1. Continue top-down approach with temporary implementations
2. Switch to bottom-up approach, building foundation first
3. Mixed approach with parallel development streams

**Decision**:
Adopt a strict bottom-up development approach, starting with Layer 1 infrastructure components.

**Rationale**:
- Foundation components can be used to build and test higher layers
- Reduced interdependency issues during development
- More modular and testable architecture
- Allows for iterative refinement of the architecture
- Better supports AI-human collaborative development

**Implementation**:
1. Focus immediate development on DocumentManager
2. Follow with StateManager and StandardsValidator
3. Only begin Layer 2 components after Layer 1 is operational
4. Reorganize project scope [10-20] to reflect new approach

**References**:
- [10-20 §2.1] - Component Hierarchy
- [10-30] - Comprehensive Scope Definition
- [00-20] - Project Status

### DECISION-20250322-2: Three-Tier Database Architecture
**Date**: March 22, 2025
**Decision Maker**: Herbert J. Bowers
**Type**: Architectural/Technical

**Context**:
The project requires persistent storage for various components, including documents, state, validation rules, and application data. A clear database architecture is needed to ensure proper data organization and access.

**Alternatives Considered**:
1. Single database for all components
2. Database per component
3. Three-tier architecture with shared core, project-specific, and user databases
4. Cloud-based solution with remote synchronization

**Decision**:
Implement a three-tier database architecture:
1. Himalaya Core Database (shared across projects)
2. Project-specific databases (e.g., "AIDEV-Validate.db")
3. User-facing help system database

**Rationale**:
- Clear separation of concerns
- Reduced complexity for individual components
- Appropriate isolation for project-specific data
- Flexibility for future evolution
- Simplified deployment and management

**Implementation**:
1. Define standard schema for core database [20-50]
2. Create database manager component in Layer 1
3. Establish standard interfaces for database access
4. Implement SQLite for initial implementation

**References**:
- [20-30 §1.3] - Database Architecture
- [50-10 §3.2] - DocumentManager Database Schema
- [10-20 §4.1] - Resource Requirements

### DECISION-20250322-3: Document Numbering System
**Date**: March 22, 2025
**Decision Maker**: Herbert J. Bowers
**Type**: Process/Administrative

**Context**:
Project documents need a consistent organization system that supports easy navigation, clear categorization, and future expansion.

**Alternatives Considered**:
1. Simple categorization with descriptive names
2. UUID-based identification
3. Hierarchical numbering system
4. Tag-based organization

**Decision**:
Implement a hierarchical numbering system with series and subseries designations (nn-nn) followed by document type and topic.

**Rationale**:
- Intuitive navigation and organization
- Clear visual identification of document types
- Supports insertion of new documents between existing ones
- Facilitates cross-referencing
- Similar to established systems in technical documentation

**Implementation**:
1. Define standard series numbers (00-90)
2. Establish document types (SPEC, PLAN, etc.)
3. Create document map [00-10]
4. Update existing documents to follow new system

**References**:
- [00-10] - Document Map
- [40-20] - Project Knowledge Database Structure
- [30-series] - Document Templates

### DECISION-20250322-4: DocumentManager as First Component
**Date**: March 22, 2025
**Decision Maker**: Herbert J. Bowers
**Type**: Implementation/Priority

**Context**:
With the bottom-up approach decided, a starting component needed to be selected that would provide the most foundational capabilities for other components.

**Alternatives Considered**:
1. StateManager (for session persistence)
2. DocumentManager (for knowledge storage)
3. StandardsValidator (for ensuring code quality)
4. Parallel implementation of all Layer 1 components

**Decision**:
Implement DocumentManager as the first component, followed by StateManager and StandardsValidator.

**Rationale**:
- DocumentManager provides immediate utility for storing project documentation
- Creates foundation for knowledge management across components
- Relatively self-contained with minimal dependencies
- Can be used to document its own implementation
- Supports RAG capabilities needed by other components

**Implementation**:
1. Complete the DocumentManager specification [50-10]
2. Define database schema for document metadata
3. Implement core storage and retrieval functions
4. Add search and indexing capabilities

**References**:
- [10-20 §2.1.1] - DocumentManager Component
- [50-10] - DocumentManager Implementation
- [00-20 §3.1] - Immediate Priorities

## 3. Legacy Decisions

### DECISION-20250320-1: AIDEV-PascalCase as Coding Standard
**Date**: March 20, 2025
**Decision Maker**: Herbert J. Bowers
**Type**: Technical/Standards

**Context**:
A consistent coding standard was needed across the project to ensure readability, maintainability, and a distinctive visual signature.

**Alternatives Considered**:
1. Standard PEP 8 Python style guide
2. Google Python Style Guide
3. Custom AIDEV-PascalCase standard
4. Mixed approach depending on component

**Decision**:
Adopt AIDEV-PascalCase as the standard coding convention for all Project Himalaya components.

**Rationale**:
- Creates distinctive visual style
- Improves readability with clear word boundaries
- Reduces eye strain compared to snake_case
- Maintains consistency across all components
- Aligns with project creator's preferences and background

**Implementation**:
1. Document the standard in detail [20-10]
2. Create examples and templates
3. Implement validation tools
4. Ensure AI assistants understand and follow the standard

**References**:
- [20-10] - AIDEV-PascalCase Standards 1.6
- [20-30 §2.1] - Coding Standards
- [20-20] - Authorship & Attribution

## 4. Decision Process

### 4.1 Decision Requirements
A formal decision entry is required when:
- Making architectural changes
- Establishing technical standards
- Setting implementation priorities
- Making significant process changes
- Resolving conflicting approaches
- Selecting technologies or frameworks

### 4.2 Decision Format
All decisions must include:
1. Unique identifier (DECISION-YYYYMMDD-N)
2. Date and decision maker
3. Context and background
4. Alternatives considered
5. The decision itself
6. Rationale with supporting arguments
7. Implementation details
8. References to related documentation

### 4.3 Decision Authority
- **Project Architecture**: Herbert J. Bowers
- **Implementation Details**: Development team with approval
- **Process Changes**: Herbert J. Bowers
- **Standards Updates**: Herbert J. Bowers with team input

### 4.4 Decision Updates
If a decision needs to be revised:
1. Create a new decision entry
2. Reference the original decision being updated
3. Explain the rationale for the change
4. Document the transition plan

## 5. Cross-Reference Matrix

| Decision ID | Related Documents | Components Affected | Status |
|-------------|-------------------|---------------------|--------|
| DECISION-20250322-1 | [10-20], [10-30], [00-20] | All | Active |
| DECISION-20250322-2 | [20-30], [50-10], [10-20] | All | Active |
| DECISION-20250322-3 | [00-10], [40-20], [30-series] | Documentation | Active |
| DECISION-20250322-4 | [10-20], [50-10], [00-20] | DocumentManager | Active |
| DECISION-20250320-1 | [20-10], [20-30], [20-20] | All | Active |

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/00-60 GUIDE-ActiveSessions.md
================
# GUIDE-ActiveSessions
**Created: March 22, 2025 2:45 PM**
**Last Modified: March 22, 2025  2:45PM**

[Context: Project_Tracking]
[Status: Active]
[Version: 1.0]

## 1. Active Development Session

### 1.1 Current Session
- **Session ID**: SESSION-20250322-01
- **Start Time**: March 22, 2025 10:30 AM
- **Focus**: Project foundation and knowledge structure
- **Participants**: Herbert J. Bowers (human), Claude (AI assistant)
- **Status**: In progress

### 1.2 Session Objectives
- Establish comprehensive project scope
- Define knowledge database structure
- Create foundational document templates
- Implement session continuity process

### 1.3 Key Artifacts Created/Modified
- Project scope definition document [10-20]
- Knowledge database structure specification [40-20]
- Core document templates [30-series]
- Foundation design principles [20-30]

### 1.4 Decisions Made
- Adopted bottom-up development approach [DECISION-20250322-1]
- Established 3-tier database architecture [DECISION-20250322-2]
- Standardized document numbering system [DECISION-20250322-3]
- Selected DocumentManager as first component for implementation [DECISION-20250322-4]

## 2. Recent Sessions

### 2.1 Session: SESSION-20250321-01
- **Date**: March 21, 2025
- **Duration**: 2.5 hours
- **Focus**: Initial project conceptualization
- **Participants**: Herbert J. Bowers (human), Claude (AI assistant)
- **Key Accomplishments**:
  - Created initial project vision document
  - Identified key components and relationships
  - Established AIDEV-PascalCase standards 1.6
  - Explored collaboration process options

### 2.2 Session: SESSION-20250320-01
- **Date**: March 20, 2025
- **Duration**: 1.5 hours
- **Focus**: Standards development
- **Participants**: Herbert J. Bowers (human), Claude (AI assistant)
- **Key Accomplishments**:
  - Finalized AIDEV-PascalCase standard updates
  - Created templates for code files
  - Established documentation format requirements

## 3. Upcoming Sessions

### 3.1 Next Planned Session
- **Tentative Date**: March 23, 2025
- **Focus**: DocumentManager detailed design and implementation
- **Objectives**:
  - Complete DocumentManager API specification
  - Design database schema for metadata
  - Begin implementation plan
  - Define integration points with other components

### 3.2 Future Sessions
- **DocumentManager Implementation**: 1-2 sessions
- **StateManager Design**: 1 session
- **Project Knowledge Database Setup**: 1 session
- **Standards Validator Conceptualization**: 1 session

## 4. Session Management Guidelines

### 4.1 Session Preparation
1. Review the STATUS document [00-20]
2. Identify priority tasks from active components
3. Prepare relevant documentation and references
4. Set clear session objectives and boundaries

### 4.2 During Session
1. Begin by confirming session objectives
2. Create or modify artifacts according to standards
3. Document key decisions
4. Track progress against objectives

### 4.3 Session Closure
1. Update the STATUS document [00-20]
2. Create session continuity document
3. Update this ACTIVE-SESSIONS document
4. Record any decisions in the DECISIONS log [00-40]

### 4.4 Session Identification
- **Format**: SESSION-[YYYYMMDD]-[NN]
- **Example**: SESSION-20250322-01
- **Rationale**: Date-based with sequence number for multiple sessions per day

## 5. Context Transfer Between Sessions

### 5.1 Session Continuity Documents
- Created at the end of each session
- Based on template [30-40]
- Stored in SESSION-CONTINUITY directory
- Named according to session ID

### 5.2 Minimum Continuity Information
- Session accomplishments
- Current project status
- Next steps and priorities
- Open issues and questions
- References to modified documents

### 5.3 AI Assistant Handover
When transitioning between different AI assistants:
1. Provide the STATUS document [00-20]
2. Share the most recent session continuity document
3. Include any component-specific documentation
4. Reference this ACTIVE-SESSIONS document

## 6. Session Metrics

### 6.1 Productivity Metrics
- **Documents Created/Modified**: Count and total word count
- **Decisions Made**: Number of formal decisions
- **Tasks Completed**: Number versus planned
- **Issues Resolved**: Count and complexity

### 6.2 Quality Metrics
- **Standards Compliance**: Percentage adherence to project standards
- **Documentation Completeness**: Coverage of implemented features
- **Cross-Reference Quality**: Proper linking between documents
- **Session Continuity Quality**: Effectiveness of handover information

## 7. Session History Archive

Complete session history is maintained in the Session Archives section (80-series documents). Each completed session's continuity document is archived with:
- Final version of all artifacts created
- Decision log entries
- Time metrics
- Outcome assessment

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/10-10 Project Himalaya: Strategic Roadmap & Evolution Plan.md
================
# Project Himalaya: Strategic Roadmap & Evolution Plan
**Created: March 15, 2025 9:30 AM**

## 1. Project Vision & Philosophy

### 1.1 Core Mission
Project Himalaya aims to create a comprehensive framework demonstrating optimal AI-human collaboration, manifested through the development of practical applications that themselves leverage AI capabilities.

### 1.2 Dual-Purpose Goals
1. **Process Goal**: Establish effective methodologies for AI-human collaborative development
2. **Product Goal**: Create useful, powerful applications that leverage AI capabilities

### 1.3 Guiding Principles
- **Modularity**: No module exceeds 500 lines; clear separation of concerns
- **Documentation-Driven Development**: Documentation precedes implementation
- **Progressive Enhancement**: Start with core functionality, then expand methodically
- **Knowledge Persistence**: Establish mechanisms to maintain context across development sessions
- **Systematic Testing**: Comprehensive testing approach integrated from the beginning

## 2. Project Architecture

### 2.1 Dual-Layer Structure
1. **Inner Layer**: Application-specific components (OllamaModelEditor)
2. **Outer Layer**: AI-human collaboration framework and tools

### 2.2 Key Architectural Components
- **Core Application Framework**: Base infrastructure and shared services
- **Module System**: Pluggable component architecture with clear interfaces
- **State Management**: Consistent approach to managing application state
- **UI Component Library**: Reusable, well-tested interface components
- **Documentation System**: Integrated documentation with project code

### 2.3 Technical Standards
- **Coding Standard**: PEP 8 with AIDEV-PascalCase naming conventions
- **Documentation Standard**: Comprehensive docstrings and markdown documentation
- **Testing Strategy**: Unit tests, integration tests, and UI tests
- **Performance Metrics**: Defined standards for response times and resource usage

## 3. Development Phases

### 3.1 Phase 1: Foundation (Current)
- Establish basic architecture and component structure
- Develop core UI framework with essential components
- Implement basic parameter editing functionality
- Create initial configuration management system
- Set up project documentation structure

### 3.2 Phase 2: Enhanced Functionality
- Implement advanced UI components (dual-slider controls, etc.)
- Develop model comparison and benchmarking capability
- Create preset management system
- Add basic visualization tools for parameter effects
- Implement configuration import/export capabilities

### 3.3 Phase 3: Intelligence Layer
- Add AI-driven parameter recommendation system
- Implement model analysis capabilities
- Develop intelligent preset suggestions
- Create natural language interface for model adjustment
- Implement performance prediction features

### 3.4 Phase 4: Advanced Features
- Add vector database integration for RAG support
- Implement voice interface for parameter adjustment
- Develop collaborative editing capabilities
- Create cloud synchronization for configurations
- Implement advanced visualization and analysis tools

## 4. Component Roadmap

### 4.1 Core Components
- **ConfigManager**: Configuration storage and retrieval
- **ModelManager**: Interface with Ollama API
- **StateManager**: Track and manage application state
- **ParameterManager**: Handle parameter definitions and constraints

### 4.2 UI Components
- **ParameterEditor**: Edit and visualize model parameters
- **ModelSelector**: Browse and select available models
- **BenchmarkView**: Compare model performance
- **PresetManager**: Create and apply parameter presets
- **DashboardView**: Overview of models and configurations

### 4.3 Intelligence Components
- **ParameterAnalyzer**: Analyze parameter effects and dependencies
- **OptimizationAdvisor**: Suggest parameter improvements
- **ModelProfiler**: Profile model characteristics
- **UsagePatternAnalyzer**: Learn from user behavior

### 4.4 Integration Components
- **DataSourceConnector**: Connect to external data sources
- **WorkflowIntegrator**: Integrate with external workflows
- **APIProvider**: Expose application capabilities via API
- **ExtensionSystem**: Support for third-party extensions

## 5. Collaboration Methodology

### 5.1 Session Structure
- **Session Initialization**: Review previous work and establish objectives
- **Planning Phase**: Define specific tasks and expected outcomes
- **Development Phase**: Implement planned functionality
- **Documentation Phase**: Document implemented functionality
- **Testing Phase**: Verify functionality works as expected
- **Session Closure**: Summarize progress and plan next steps

### 5.2 Knowledge Management
- **Project Knowledge Database**: Central repository for project information
- **Session Handover Documentation**: Structured notes for context transfer
- **Component Interfaces**: Clear definition of component boundaries
- **Decision Log**: Record of key decisions and their rationale

### 5.3 Task Workflow
1. **Component Design**: Create detailed component specification
2. **Interface Definition**: Define component interfaces
3. **Test Definition**: Create test cases
4. **Implementation**: Develop component functionality
5. **Documentation**: Document component functionality
6. **Testing**: Verify component behavior
7. **Integration**: Integrate component with application
8. **Validation**: Validate end-to-end functionality

## 6. OllamaModelEditor Roadmap

### 6.1 Version 0.1: Core Functionality
- Basic UI with parameter editing capabilities
- Model selection and configuration
- Simple presets for common use cases
- Configuration persistence

### 6.2 Version 0.2: Enhanced Experience
- Improved UI with dual-slider controls
- Visual parameter feedback
- Extended preset capabilities
- Basic benchmarking tools

### 6.3 Version 0.3: Intelligence Features
- Parameter recommendations
- Performance analysis
- Smart presets
- Usage pattern learning

### 6.4 Version 1.0: Complete Solution
- Comprehensive model management
- Advanced visualization
- Integration with external workflows
- Collaboration capabilities

## 7. Implementation Strategy

### 7.1 Component Development Approach
1. **Design First**: Create detailed component specification
2. **Small Iterations**: Develop in small, testable increments
3. **Continuous Testing**: Test each increment thoroughly
4. **Regular Refactoring**: Continuously improve code quality
5. **Documentation Updates**: Keep documentation current

### 7.2 Development Environment
- **Version Control**: Git with structured commit messages
- **Virtual Environment**: Isolated Python environment
- **Dependency Management**: Clear requirements specification
- **Development Tools**: Consistent editor configuration and linting

### 7.3 Quality Assurance
- **Automated Testing**: Unit and integration tests
- **Code Review**: Systematic code inspection
- **Static Analysis**: Automated code quality checks
- **User Testing**: Regular testing with target users

## 8. Challenges & Mitigations

### 8.1 Context Maintenance
- **Challenge**: Maintaining development context across AI sessions
- **Mitigation**: Comprehensive session handover documentation and project knowledge database

### 8.2 Architectural Consistency
- **Challenge**: Ensuring consistent application of architectural principles
- **Mitigation**: Clear architecture documentation and regular architecture reviews

### 8.3 Component Integration
- **Challenge**: Ensuring components work together seamlessly
- **Mitigation**: Well-defined interfaces and comprehensive integration testing

### 8.4 Evolution Management
- **Challenge**: Balancing stability with continuous improvement
- **Mitigation**: Clearly defined development phases and version roadmap

## 9. Success Metrics

### 9.1 Process Metrics
- **Development Efficiency**: Time to implement new functionality
- **Documentation Quality**: Completeness and accuracy of documentation
- **Code Quality**: Adherence to standards and best practices
- **Test Coverage**: Percentage of code covered by tests

### 9.2 Product Metrics
- **Functionality**: Implementation of planned features
- **Usability**: Ease of use for target audience
- **Performance**: Response times and resource usage
- **Reliability**: Stability and error rates

## 10. Next Steps

### 10.1 Immediate Actions
1. **Architecture Review**: Assess current codebase architecture
2. **Component Identification**: Identify key components and interfaces
3. **Documentation Update**: Create/update component documentation
4. **Refactoring Plan**: Develop plan for code refactoring

### 10.2 Short-Term Goals (1-2 Weeks)
1. **Refactor ParameterEditor**: Implement improved dual-slider version
2. **Enhance StateManager**: Improve state tracking and visualization
3. **Develop Component Library**: Create reusable UI component library
4. **Improve Documentation**: Update project documentation

### 10.3 Medium-Term Goals (1-2 Months)
1. **Complete Version 0.2**: Implement all planned 0.2 features
2. **Enhance Testing**: Develop comprehensive testing framework
3. **Implement Benchmarking**: Create benchmarking functionality
4. **Improve User Experience**: Refine UI based on feedback

## 11. Conclusion

Project Himalaya represents an ambitious effort to demonstrate the potential of AI-human collaboration while creating valuable AI-enhanced applications. This roadmap provides a structured approach to achieving both the process and product goals of the project.

As a living document, this plan will evolve as the project progresses, incorporating lessons learned and adapting to changing requirements and technologies.

================
File: cs/KnowledgeDatabaseIndex/10-20 Project Himalaya: Vision Document.md
================
# Project Himalaya: Vision Document
**Created: March 15, 2025 3:15 PM**

## 1. Project Vision & Philosophy

### 1.1 Core Mission
Project Himalaya aims to create a comprehensive framework demonstrating optimal AI-human collaboration, manifested through the development of practical applications that themselves leverage AI capabilities. This project acknowledges and embraces the constraints of current AI technology while pioneering new approaches to collaborative development.

### 1.2 Dual-Purpose Goals
1. **Process Goal**: Establish effective methodologies for AI-human collaborative development that respect technological, resource, and personal constraints
2. **Product Goal**: Create useful, powerful applications that leverage AI capabilities while remaining accessible to the broader community

### 1.3 Guiding Principles
- **Modularity**: No module exceeds 500 lines; clear separation of concerns
- **Documentation-Driven Development**: Documentation precedes implementation
- **Progressive Enhancement**: Start with core functionality, then expand methodically
- **Knowledge Persistence**: Establish mechanisms to maintain context across development sessions
- **Systematic Testing**: Comprehensive testing approach integrated from the beginning
- **Resource Efficiency**: Respect computational and financial resource limitations
- **Accessibility**: Design development processes that accommodate varying abilities and preferences

## 2. Development Constraints & Solutions

### 2.1 Technological Constraints
- **Context Window Limitations**: Current AI systems have finite context windows
- **Session Continuity**: AI sessions terminate and lose context
- **Computational Resource Limitations**: Local hardware has performance boundaries
- **Implementation Scale**: Large-scale code modifications are challenging for human-AI interaction

### 2.2 Personal Constraints
- **Physical Limitations**: Acknowledging challenges with manual coding tasks
- **Attention Management**: Designing processes that respect attention span limitations
- **Visual Accessibility**: Ensuring processes work with varying levels of visual acuity
- **Resource Boundaries**: Working within the constraints of retirement-based resources

### 2.3 Mitigation Strategies
- **Role Specialization**: Assign tasks based on strengths of each participant
- **Structured Documentation**: Comprehensive documentation to maintain context
- **Implementation Delegation**: Provide detailed specifications for local AI implementation
- **Resource Optimization**: Efficient distribution of tasks between cloud and local AI resources
- **Modular Approach**: Break development into manageable, self-contained units

## 3. Collaborative Workflow Model

### 3.1 Role Definitions
- **Project Owner (Human)**: Provides vision, requirements, and critical decisions
- **Lead Architect (Cloud AI)**: Designs architecture, creates specifications, and maintains continuity
- **Implementation Assistant (Local AI)**: Handles code implementation based on specifications

### 3.2 Communication Protocols
- **Specification Format**: Standardized format for component specifications
- **Implementation Instructions**: Structured prompts for local AI implementation
- **Progress Tracking**: Consistent documentation of completed work
- **Handover Documentation**: Detailed summaries at the end of each session

### 3.3 Implementation Process
1. **Design Phase**: Cloud AI creates detailed specification and implementation plan
2. **Instruction Formulation**: Cloud AI creates structured implementation instructions
3. **Local Implementation**: Local AI implements code changes based on instructions
4. **Verification**: Human reviews and confirms implementation meets requirements
5. **Documentation Update**: Cloud AI updates project documentation

### 3.4 Knowledge Management
- **Central Documentation Repository**: GitHub or similar platform
- **Session Continuity Documents**: Summaries and context for future sessions
- **Code Repository**: Structured organization with clear documentation
- **Component Interface Specifications**: Clear definitions of component boundaries

## 4. Project Architecture

### 4.1 Dual-Layer Structure
1. **Inner Layer**: Application-specific components (OllamaModelEditor)
2. **Outer Layer**: AI-human collaboration framework and tools

### 4.2 Modular Component Design
- **Small, Focused Components**: Easier to design, implement, and maintain
- **Clear Interfaces**: Well-defined APIs between components
- **State Isolation**: Components manage their own state with clear ownership
- **Implementation Independence**: Components can be implemented separately

### 4.3 Technical Standards
- **Coding Standard**: AIDEV-PascalCase-1.2 naming conventions
- **Documentation Standard**: Comprehensive docstrings and markdown documentation
- **Testing Strategy**: Unit tests, integration tests, and UI tests
- **Performance Metrics**: Defined standards for response times and resource usage

## 5. OllamaModelEditor Specific Vision

### 5.1 Application Purpose
Create a powerful, user-friendly tool for customizing and optimizing Ollama AI models, demonstrating the practical results of AI-human collaboration.

### 5.2 Key Features
- **Intuitive Parameter Editing**: Visual controls for adjusting model parameters
- **Real-time Feedback**: Immediate visualization of parameter effects
- **Preset Management**: Create, share, and apply parameter presets
- **Performance Benchmarking**: Compare model performance across configurations
- **Model Analysis**: Gain insights into model behavior

### 5.3 User Experience Goals
- **Accessibility**: Usable by developers of all experience levels
- **Transparency**: Clear visualization of how parameters affect models
- **Efficiency**: Streamlined workflows for common tasks
- **Educational Value**: Helps users understand model parameters

### 5.4 Technical Implementation Principles
- **Separation of UI and Logic**: Clear distinction between interface and business logic
- **State Management**: Consistent, predictable state handling
- **Performance Optimization**: Responsive UI even with complex operations
- **Cross-platform Compatibility**: Works across different operating systems

## 6. Resource Utilization Strategy

### 6.1 Cloud AI Utilization (Claude)
- **Architecture Design**: High-level system design and component specifications
- **Interface Definition**: Clear definition of component interfaces
- **Implementation Planning**: Detailed step-by-step implementation instructions
- **Documentation Generation**: Creation and maintenance of project documentation
- **Code Review**: Analysis and feedback on implemented code
- **Project Continuity**: Maintaining context across development sessions

### 6.2 Local AI Utilization (20B Model)
- **Code Implementation**: Generating code based on specifications
- **Refactoring**: Implementing code changes according to instructions
- **Testing Support**: Generating unit and integration tests
- **Documentation Support**: Creating code-level documentation

### 6.3 Human Focus Areas
- **Vision & Direction**: Setting overall project direction
- **Critical Decision Making**: Making key architecture and design decisions
- **Quality Assurance**: Final review and approval of implementations
- **User Experience Feedback**: Providing real-world usability feedback
- **Resource Coordination**: Managing the interaction between different AI systems

### 6.4 Resource Conservation Measures
- **Structured Sessions**: Well-defined objectives for each development session
- **Efficient Documentation**: Comprehensive but concise documentation
- **Task Batching**: Grouping similar tasks for efficient processing
- **Local Processing**: Using local AI for implementation to conserve cloud resources
- **Incremental Development**: Building the system in small, manageable increments

## A7. Open Source Vision

### 7.1 Community Contribution
- **Free, Open Access**: Project available to the broader community without cost
- **Educational Value**: Demonstrating effective AI-human collaboration techniques
- **Developer Tools**: Providing valuable tools for Ollama users
- **Documentation**: Sharing methodologies and lessons learned

### 7.2 Distribution Strategy
- **GitHub Repository**: Public repository with comprehensive documentation
- **Clear Licensing**: Open source license that promotes reuse and modification
- **Installation Guides**: Easy setup instructions for various platforms
- **Usage Examples**: Demonstrations of common use cases

### 7.3 Sustainability Model
- **Community Maintenance**: Structure to allow community contributions
- **Documentation Standards**: Clear standards for ongoing documentation
- **Modular Architecture**: Allows incremental improvements and extensions
- **Knowledge Transfer**: Clear paths for new contributors to understand the system

## 8. Implementation Artifact Standard

### 8.1 Development Artifact Types
- **Enhancement Plans**: Detailed specifications for planned changes
- **Implementation Guides**: Step-by-step instructions for local AI implementation
- **Implementation Reports**: Documentation of completed changes
- **Testing Guides**: Comprehensive testing instructions
- **Session Summaries**: Context preservation for future development sessions

### 8.2 Artifact Format Standards
- **Plan Documents**: Markdown with clear sections and hierarchical structure
- **Implementation Instructions**: Structured prompts with code snippets and detailed steps
- **Code Files**: Complete source files with proper headers and documentation
- **Test Files**: Comprehensive test cases with clear expected results
- **Reports**: Markdown documents describing implemented changes and next steps

### 8.3 Artifact Creation Workflow
1. **Assessment**: Evaluate current state and requirements
2. **Planning**: Create detailed enhancement plan
3. **Implementation Guide**: Develop step-by-step implementation instructions
4. **Implementation**: Execute changes according to guide (delegated to local AI)
5. **Documentation**: Update project documentation with changes
6. **Testing**: Verify implementation meets requirements

## 9. Success Metrics

### 9.1 Process Success Metrics
- **Development Efficiency**: Ability to implement components within resource constraints
- **Knowledge Persistence**: Effectiveness of context maintenance between sessions
- **Implementation Quality**: Code quality achieved through the collaborative process
- **Documentation Effectiveness**: Clarity and usefulness of generated documentation

### 9.2 Product Success Metrics
- **User Adoption**: Number of users adopting the OllamaModelEditor
- **Feature Completeness**: Implementation of planned features
- **User Experience**: User feedback on usability and utility
- **Community Engagement**: Contributions and feedback from the open source community

## 10. Next Steps Toward Project Plan

### 10.1 Project Plan Development
1. **Current State Assessment**: Evaluate existing codebase
2. **Component Identification**: Identify and prioritize key components
3. **Resource Allocation**: Define specific responsibilities for each participant
4. **Timeline Development**: Create realistic timelines respecting constraints
5. **Documentation Templates**: Develop templates for specifications and handovers

### 10.2 Initial Implementation Focus
1. **Refactor ParameterEditor**: Starting point for demonstrating the collaborative approach
2. **Component Library**: Develop reusable UI component foundation
3. **State Management**: Implement robust state tracking foundation
4. **Documentation System**: Establish project documentation structure

## 11. Conclusion

Project Himalaya represents a pioneering effort in AI-human collaboration, deliberately designed to acknowledge and work within the constraints of current technology and personal circumstances. By leveraging the complementary strengths of cloud AI, local AI, and human guidance, this project aims to create a valuable open-source tool while simultaneously developing innovative approaches to collaborative development.

This vision document serves as the foundation for a detailed project plan that will guide the actual implementation of both the collaborative methodology and the OllamaModelEditor application.

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/10-30 Project Himalaya: Comprehensive Scope Definition.md
================
# Project Himalaya
**Created: March 22, 2025 12:30 PM**
**Last Modified: March 22, 2025  12:30PM**

[Context: Project_Overview]
[Status: Active_Development]
[Version: 0.1]

## 1. Project Overview

Project Himalaya is a comprehensive framework demonstrating optimal AI-human collaboration, manifested through the development of practical applications that themselves leverage AI capabilities. The project follows a layered architecture with bottom-up development approach.

### 1.1 Dual-Purpose Goals

1. **Process Goal**: Establish effective methodologies for AI-human collaborative development
2. **Product Goal**: Create useful, powerful applications that leverage AI capabilities

### 1.2 Core Principles

- **Bottom-up Development**: Build foundation components first, then build upward
- **Documentation-Driven Development**: Documentation precedes implementation
- **Progressive Enhancement**: Start with core functionality, then expand methodically
- **Knowledge Persistence**: Establish mechanisms to maintain context across development sessions
- **Systematic Testing**: Comprehensive testing approach integrated from the beginning

## 2. Project Structure

Project Himalaya follows a layered architecture:

### Layer 1: Core Infrastructure
- **DocumentManager**: Document storage and retrieval with metadata
- **StateManager**: Session state persistence and context management
- **StandardsValidator**: Validation against AIDEV-PascalCase and other standards

### Layer 2: Communication Framework
- **TaskManager**: Task definition and tracking
- **AIInterface**: Communication with cloud and local AI systems
- **KnowledgeTransfer**: Knowledge packaging and transfer

### Layer 3: Development Tools
- **CodeGenerator**: Standards-compliant code generation
- **TestFramework**: Test case creation and execution
- **DocumentationGenerator**: Automated documentation creation

### Layer 4: Applications
- **OllamaModelEditor**: Tool for customizing and optimizing Ollama AI models
- **AIDEV-Deploy**: File deployment with validation and rollback

## 3. Core Design Principles

### 3.1 Documentation Standards
- All documentation produced in Markdown (.md) format
- All code documentation using appropriate docstrings
- Session artifacts as either Markdown documents or code artifacts
- Standardized metadata headers for all documents

### 3.2 Code Organization
- Highly modular design with clear separation of concerns
- Module size limit of ~500 lines of code
- Well-defined interfaces between components
- Independent testability of components

### 3.3 Database Architecture
- **Three-tier database structure**:
  1. Himalaya Core Database (shared across projects)
  2. Project-specific databases (e.g., "AIDEV-Validate.db")
  3. User-facing help system database
- SQLite for lightweight usage scenarios
- Fully documented database schemas
- Version-controlled migration scripts

## 3. Current Status

### 3.1 Development Status
- **Phase**: Foundation (Layer 1 components)
- **Current Focus**: DocumentManager design and implementation
- **Next Up**: StateManager detailed design

### 3.2 Active Sub-Projects
- **OllamaModelEditor**: Core application (in planning)
- **AIDEV-PascalCase**: Coding standards (version 1.6)
- **AIDEV-Deploy**: File deployment system (preliminary design)
- **AIDEV-State**: State management utility (conceptual)
- **AIDEV-Hub**: Collaboration framework (planning)

## 4. Key Documentation

### 4.1 Project Foundation
- [SCOPE-ProjectHimalaya.md](SCOPE-ProjectHimalaya.md): Comprehensive scope definition
- [STRUCTURE-KnowledgeDatabase.md](STRUCTURE-KnowledgeDatabase.md): Knowledge organization
- [TEMPLATE-SessionContinuity.md](TEMPLATE-SessionContinuity.md): Session handover format
- [STANDARD-FoundationDesignPrinciples.md](STANDARD-FoundationDesignPrinciples.md): Core design principles

### 4.2 Standards and Processes
- [STANDARD-AIDEV-PascalCase-1.6.md](STANDARD-AIDEV-PascalCase-1.6.md): Coding standards
- [GUIDE-AICollaboration.md](GUIDE-AICollaboration.md): AI-Human collaboration process

### 4.3 Sub-Project References
- [REF-OllamaModelEditor.md](REF-OllamaModelEditor.md): Model editor application
- [REF-AIDEV-Deploy.md](REF-AIDEV-Deploy.md): File deployment system
- [REF-AIDEV-State.md](REF-AIDEV-State.md): State management utility
- [REF-AIDEV-Hub.md](REF-AIDEV-Hub.md): Collaboration framework

## 5. Getting Started

### 5.1 For AI Assistants
1. Review the [SCOPE-ProjectHimalaya.md](SCOPE-ProjectHimalaya.md) document
2. Examine the current [TEMPLATE-SessionContinuity.md](TEMPLATE-SessionContinuity.md) for latest status
3. Check component-specific documentation for the current focus area
4. Reference [STANDARD-AIDEV-PascalCase-1.6.md](STANDARD-AIDEV-PascalCase-1.6.md) for coding standards

### 5.2 For Developers
1. Review the project structure and current focus
2. Set up the development environment
3. Create a branch for the component being developed
4. Follow the documentation-driven development approach

## 6. Communication Protocol

### 6.1 Between Sessions
- Use session continuity template to document progress
- Store context in StateManager (when implemented)
- Create detailed component documentation

### 6.2 Between AI Systems
- Human-mediated knowledge transfer (current approach)
- Structured documentation for sharing context
- Standardized prompts for consistency

## 7. Next Steps

1. Complete DocumentManager detailed design
2. Implement DocumentManager MVP
3. Begin StateManager detailed design
4. Establish initial Project Knowledge Database
5. Refine session continuity process

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/10-40 Project Himalaya: Comprehensive Scope Definition.md
================
# Project Himalaya: Comprehensive Scope Definition
**Created: March 22, 2025 10:30 AM**

## 1. Project Vision and Boundaries

### 1.1 Project Purpose
- Create a comprehensive framework for AI-human collaborative development
- Build practical applications that leverage AI capabilities (Ollama Model Editor as flagship)
- Establish reusable patterns and tools for maintaining development continuity
- Develop standards and methodologies for AI-assisted software development

### 1.2 Project Scope Includes
- Core infrastructure components for document and state management
- Communication protocols between cloud and local AI systems
- Development tools that enforce standards and streamline workflows
- Application-specific components for Ollama Model Editor and supporting utilities
- Documentation and knowledge management systems

### 1.3 Project Scope Excludes
- Creating new LLM models or training methodologies
- General-purpose RAG systems not specific to development workflows
- Consumer-facing applications beyond the demonstration projects
- Commercial deployment infrastructure

## 2. Component Hierarchy and Development Sequence

### 2.1 Layer 1: Core Infrastructure (Build First)

#### 2.1.1 DocumentManager
- **Purpose**: Store, retrieve, and track project documentation
- **Key Capabilities**:
  - File storage with metadata
  - Simple search capabilities
  - Change tracking
  - Version control integration
- **Dependencies**: None (foundation component)
- **Estimated Size**: Small to Medium (2-3 weeks)
- **Success Criteria**:
  - Documents reliably stored and retrieved
  - Metadata accurately tracks document properties
  - Search returns relevant results quickly
  - Changes properly tracked and recorded

#### 2.1.2 StateManager
- **Purpose**: Track and persist session state and development context
- **Key Capabilities**:
  - Session tracking
  - Context persistence
  - Action recording
  - Crash recovery
- **Dependencies**: DocumentManager
- **Estimated Size**: Medium (3-4 weeks)
- **Success Criteria**:
  - Session state persists across interruptions
  - Context accurately maintained between sessions
  - Actions properly recorded with parameters and results
  - Recovery from crashes maintains data integrity

#### 2.1.3 StandardsValidator
- **Purpose**: Validate compliance with AIDEV-PascalCase and other standards
- **Key Capabilities**:
  - Code structure checking
  - Naming convention enforcement
  - Documentation validation
  - Automated correction suggestions
- **Dependencies**: DocumentManager
- **Estimated Size**: Medium (3-4 weeks)
- **Success Criteria**:
  - Accurately identifies standards violations
  - Provides clear guidance for corrections
  - Integrates with development workflow
  - Maintains customizable rule sets

### 2.2 Layer 2: Communication Framework

#### 2.2.1 TaskManager
- **Purpose**: Define, track, and manage development tasks
- **Key Capabilities**:
  - Task definition templates
  - Status tracking
  - Priority management
  - Dependency handling
- **Dependencies**: StateManager
- **Estimated Size**: Medium (3-4 weeks)
- **Success Criteria**:
  - Tasks clearly defined and tracked
  - Status updates properly recorded
  - Priorities and dependencies managed effectively
  - Integration with state management system

#### 2.2.2 AIInterface
- **Purpose**: Standardize communication with local and cloud AIs
- **Key Capabilities**:
  - Prompt template management
  - Context injection
  - Response formatting
  - Model-specific optimizations
- **Dependencies**: StateManager, DocumentManager
- **Estimated Size**: Medium to Large (4-5 weeks)
- **Success Criteria**:
  - Consistent communication with different AI systems
  - Effective context transfer between systems
  - Properly formatted responses for downstream processing
  - Adaptability to different model capabilities

#### 2.2.3 KnowledgeTransfer
- **Purpose**: Package and transfer knowledge between sessions and systems
- **Key Capabilities**:
  - Context packaging
  - Reference compilation
  - Need-to-know filtering
  - Cross-session continuity
- **Dependencies**: DocumentManager, StateManager
- **Estimated Size**: Medium to Large (4-5 weeks)
- **Success Criteria**:
  - Effective knowledge preservation between sessions
  - Relevant reference materials properly compiled
  - Information appropriately filtered for specific needs
  - Reduced context loss during transitions

### 2.3 Layer 3: Development Tools

#### 2.3.1 CodeGenerator
- **Purpose**: Generate code that adheres to project standards
- **Key Capabilities**:
  - Template-based generation
  - Standards compliance
  - Customization options
  - Integration with existing codebases
- **Dependencies**: AIInterface, StandardsValidator
- **Estimated Size**: Large (5-6 weeks)
- **Success Criteria**:
  - Generated code meets all project standards
  - Templates properly parameterized for flexibility
  - Seamless integration with existing code
  - Customization options meet diverse needs

#### 2.3.2 TestFramework
- **Purpose**: Create and manage test cases for project components
- **Key Capabilities**:
  - Test case generation
  - Automated execution
  - Results reporting
  - Coverage analysis
- **Dependencies**: AIInterface, CodeGenerator
- **Estimated Size**: Large (5-6 weeks)
- **Success Criteria**:
  - Comprehensive test case generation
  - Reliable automated execution
  - Clear, actionable test results
  - Accurate coverage measurement

#### 2.3.3 DocumentationGenerator
- **Purpose**: Automatically create and update project documentation
- **Key Capabilities**:
  - Template-based generation
  - Code-documentation synchronization
  - Format standardization
  - Multi-format output
- **Dependencies**: AIInterface, DocumentManager
- **Estimated Size**: Medium (3-4 weeks)
- **Success Criteria**:
  - Documentation accurately reflects code
  - Consistent formatting across all documents
  - Automatic updates when code changes
  - Multiple output formats supported

### 2.4 Layer 4: Applications

#### 2.4.1 OllamaModelEditor
- **Purpose**: Allow users to customize and optimize Ollama AI models
- **Key Components**:
  - Core Framework
  - Parameter Editor
  - Model Manager
  - Visualization Tools
- **Dependencies**: All Layer 1-3 components
- **Estimated Size**: Very Large (8-10 weeks)
- **Success Criteria**:
  - Intuitive parameter editing
  - Reliable model management
  - Effective visualization of results
  - Performance improvements for edited models

#### 2.4.2 AIDEV-Deploy
- **Purpose**: Manage file deployment with validation and rollback
- **Key Components**:
  - Transaction Manager
  - Validation System
  - Backup Manager
  - Deployment Engine
- **Dependencies**: Layer 1-2 components
- **Estimated Size**: Large (6-8 weeks)
- **Success Criteria**:
  - Reliable transaction-based deployments
  - Accurate validation against standards
  - Effective backup and rollback
  - Clear visual feedback on operations

## 3. Development Approach and Milestones

### 3.1 Development Principles
- Build foundation components first, then build upward
- Complete components to usable state before moving to next
- Implement with minimal viable features, then enhance
- Use completed components in the development of subsequent components
- Document as you go, with clear interfaces and examples
- Test thoroughly at each stage
- Refactor regularly to maintain code quality

### 3.2 Major Milestones

1. **Infrastructure Foundation (Month 1-2)**
   - DocumentManager operational
   - StateManager with session persistence
   - StandardsValidator for basic validation

2. **Communication Framework (Month 2-3)**
   - TaskManager with basic tracking
   - AIInterface with template management
   - KnowledgeTransfer with context packaging

3. **Development Tools (Month 3-5)**
   - CodeGenerator with template support
   - TestFramework with basic automation
   - DocumentationGenerator with synchronization

4. **Application Foundations (Month 5-6)**
   - OllamaModelEditor core framework
   - Basic parameter editing functionality
   - Model management capabilities

5. **Complete Applications (Month 6-8)**
   - Full OllamaModelEditor functionality
   - AIDEV-Deploy system operational
   - Integrated workflow across all components

6. **Refinement and Integration (Month 8-9)**
   - Performance optimization
   - User experience enhancements
   - Comprehensive documentation
   - Final integration testing

### 3.3 Incremental Delivery Strategy
Each component will be developed through these stages:
1. **Minimum Viable Implementation**: Core functionality only
2. **Basic Usability**: Sufficient for development purposes
3. **Integration**: Connected with dependent components
4. **Enhancement**: Additional features and optimizations
5. **Stabilization**: Bug fixes and performance tuning

## 4. Resource Requirements and Constraints

### 4.1 Technical Resources
- Python 3.8+ development environment
- SQLite or similar for lightweight database needs
- Vector database (Chroma, Qdrant, or similar)
- Local Ollama installation for testing
- PySide6 for GUI development
- Git for version control
- Testing frameworks (pytest, etc.)

### 4.2 Knowledge Resources
- RAG system implementation best practices
- Vector database optimization techniques
- State management patterns for complex applications
- GUI development with PySide6
- Prompt engineering for development tasks
- Software testing methodologies

### 4.3 Constraints
- Session limitations with cloud AI services
- Context window limitations for large projects
- Evolving best practices for emerging technologies
- Single-developer resource limitations
- API rate limits and costs
- Long-term maintenance considerations

## 5. Success Criteria and Metrics

### 5.1 Technical Success Metrics
- Components function according to specifications
- Integration between components is seamless
- Standards are consistently applied
- Performance meets defined benchmarks
- Error rates below acceptable thresholds
- Test coverage exceeds 80% for critical components

### 5.2 Process Success Metrics
- Reduced context loss between development sessions
- Improved knowledge transfer efficiency
- Decreased time spent on repetitive tasks
- Enhanced consistency in code and documentation
- Faster onboarding for new development sessions
- Reduced error rates in development workflows

### 5.3 User Experience Metrics
- Intuitive interfaces for all tools
- Clear feedback on actions and errors
- Consistent visual design across components
- Performance acceptable for interactive use
- Learning curve appropriate for target users

## 6. Risk Management

### 6.1 Key Risks
- Session termination causing loss of work
- Technology evolution requiring significant redesign
- Scope creep extending development timeline
- Technical debt from rapid prototyping
- Integration challenges between components
- Performance issues with complex operations

### 6.2 Mitigation Strategies
- Regular state persistence and documentation generation
- Modular design allowing component replacement
- Clear scope boundaries with prioritized features
- Scheduled refactoring sessions
- Comprehensive interface definitions
- Performance testing throughout development

### 6.3 Contingency Plans
- Simplified fallback implementations for critical features
- Manual workarounds for automated processes
- Version rollback procedures
- Alternative technology options identified in advance
- Feature prioritization for minimum viable product

## 7. Maintenance and Evolution

### 7.1 Maintenance Strategy
- Regular code reviews and refactoring
- Documentation updates with each significant change
- Automated testing to catch regressions
- Version control best practices
- Clear deprecation paths for evolving components

### 7.2 Evolution Planning
- Quarterly architecture reviews
- Technology monitoring for relevant advances
- User feedback collection and analysis
- Prioritized enhancement backlog
- Backward compatibility considerations

### 7.3 Knowledge Preservation
- Comprehensive documentation of design decisions
- Recorded explanations of complex algorithms
- Clear notation of assumptions and constraints
- Preservation of key development artifacts
- Session logs for significant decisions

## 8. Project Knowledge Database Structure

### 8.1 Top-Level Organization
- Project Vision and Roadmap
- Technical Standards and Guides
- Component Specifications
- Development Processes
- Sub-Project Documentation
- Session Archives
- Reference Materials

### 8.2 Cross-Referencing System
- Consistent document naming conventions
- Hyperlinked references between documents
- Tag-based categorization
- Version indicators for evolving documents
- Relationship mapping between components

### 8.3 Access Patterns
- Quick reference guides for common tasks
- Comprehensive specifications for detailed work
- Searchable by component, feature, or concept
- Historical records for understanding evolution
- Template access for standardized documents

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/20-10 STANDARD-AIDEV-PascalCase Standards 1.6.md
================
# AIDEV-PascalCase Standards 1.6
**Created: March 16, 2025 11:45 PM**
**Last Modified: March 16, 2025  11:45 PM**

[Context: Development_Standards]
[Pattern_Type: Naming_Convention]
[Implementation_Level: Project_Wide]
[Version: 1.6]

## Change Log from v1.5
- Added new core principle: "Interface Boundary Preservation"
- Expanded rules for handling standard library interface methods
- Added detailed examples showing standard library integration
- Clarified validation rules for variables inside override methods
- Improved documentation for common Python framework interactions

## Design Philosophy and Justification

[Context: Standards_Rationale] 
[Priority: Highest]

### Developer Fingerprint

The AIDEV-PascalCase standard serves as a distinct fingerprint of its creator's work—a visual signature that marks code with a sense of craftsmanship and individual style. Just as master typographers and printers developed recognizable styles, this coding standard carries forward that tradition into software development. This fingerprint:

1. **Establishes Provenance**: Makes code immediately recognizable to collaborators
2. **Reflects Craftsmanship**: Demonstrates attention to both function and form
3. **Honors Tradition**: Connects modern software development to traditional design arts
4. **Ensures Consistency**: Creates a unified visual language across projects

### Visual Clarity in Code

The AIDEV-PascalCase standard is founded on principles of typography and visual design. Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in this standard prioritize:

1. **Axis of Symmetry**: Code should exhibit balance and visual harmony, facilitating easier scanning and comprehension
2. **Character Distinction**: Each identifier should be visually distinct without relying on hard-to-discern characters
3. **Readability at Scale**: Standards must remain effective when viewing large codebases or printed materials
4. **Visual Hierarchy**: Different elements (classes, functions, variables) should have visual patterns that aid in rapid identification

### Practical Benefits

This standard offers several tangible benefits over conventional Python style guides:

1. **Rapid Visual Parsing**: PascalCase creates clear word boundaries without sacrificing visual flow, unlike snake_case where underscores can be difficult to see, especially in printed code or certain fonts
2. **Consistency Across Languages**: Maintains visual consistency when working in multi-language environments (JavaScript, C#, Java, etc.)
3. **Reduced Eye Strain**: Eliminates the need to focus on low-visibility characters like underscores
4. **Clear Scope Identification**: Variable scopes and types can be more easily distinguished
5. **Enhanced Refactoring**: Makes variable names more visually distinct during search-and-replace operations

## Core Principles

[Context: Fundamental_Rules]
[Priority: Highest]

### 1. Capitalization Immutability

[Pattern: Name_Preservation]

```python
# Once capitalized, a name's format becomes immutable
ExistingName = "Value"    # Will always remain "ExistingName"
```

### 2. Special Terms Recognition

[Pattern: Reserved_Terms]
[Priority: High]

```
Preserved Terms:
- AI  (Artificial Intelligence)
- DB  (Database)
- GUI (Graphical User Interface)
- API (Application Programming Interface)
- UI  (User Interface)
- UX  (User Experience)
- ID  (Identifier)
- IO  (Input/Output)
- OS  (Operating System)
- IP  (Internet Protocol)
- URL (Uniform Resource Locator)
- HTTP (Hypertext Transfer Protocol)
```

### 3. System Element Preservation

[Pattern: System_Preservation]

```python
# Python keywords and system elements remain lowercase
def FunctionName():    # System-level element
    pass               # Python keyword
```

### 4. Interface Boundary Preservation

[Pattern: Interface_Preservation]
[Priority: High]

```python
# Methods that override standard library or framework interfaces must maintain
# their original naming conventions to ensure compatibility

# AST Visitor Pattern
class CustomVisitor(ast.NodeVisitor):
    def visit_ClassDef(self, Node):  # Maintains library interface naming
        ClassName = Node.name        # Custom variable follows PascalCase
        return self.ProcessClass(ClassName)  # Custom method follows PascalCase

# Django Class-Based View
class UserView(View):
    def get(self, request):  # Django method override
        UserID = request.GET.get('id')  # Custom variable follows PascalCase
        return self.RenderUserProfile(UserID)  # Custom method follows PascalCase
```

### 5. Timestamp Documentation

[Pattern: Time_Tracking]

```python
# File: Example.py
# Path: Project/Component/Example.py
# Standard: AIDEV-PascalCase-1.6
# Created: 2025-03-16
# Last Modified: 2025-03-16  11:45PM
# Description: Brief description of the file's purpose
```

Note the exactly two spaces between the date and time in the Last Modified timestamp.

### 6. Symbol Reference Consistency

[Pattern: Reference_Consistency]
[Priority: Highest]

```python
# All references to a symbol must be consistent throughout the codebase
UserName = GetUserInput()
ProcessInput(UserName)   # Not processInput(UserName) or ProcessInput(userName)
```

## Character Usage Guidelines

[Context: Visual_Design]
[Priority: High]

### Dash (-) Character Usage

[Pattern: Dash_Constraints]

The dash character impairs visual balance and should be used only in specific circumstances:

1. **Joining Acronyms with Words**:

   ```
   AIDEV-PascalCase    # Correct - connects acronym to words
   Model-Manager       # Incorrect - use ModelManager instead
   ```
2. **Sequential or Enumerated Elements**:

   ```
   Page-2-Section-3    # Correct - represents a sequence
   PG2-SEC3            # Correct - abbreviated sequence
   ```
3. **Standard Date Formats**:

   ```
   2025-03-16          # Correct - standard date format
   ```
4. **Avoid in All Other Cases**:

   ```
   Process-Data        # Incorrect - use ProcessData instead
   User-Input          # Incorrect - use UserInput instead
   ```

### Underscore (_) Character Usage

[Pattern: Underscore_Constraints]

The underscore character has poor visibility and should be limited to:

1. **Constants (ALL_CAPS)**:

   ```python
   MAX_RETRY_COUNT = 5    # Correct - constant with underscore separation
   DEFAULT_TIMEOUT = 30   # Correct - constant with underscore separation
   ```
2. **Pattern Markers in Comments/Documentation**:

   ```python
   # [Pattern: Name_Preservation]  # Correct - used in metadata/documentation
   ```
3. **Global Variable Prefixing (Optional)**:

   ```python
   g_ActiveUsers = []     # Correct - 'g' prefix for global variable
   _GlobalConfig = {}     # Alternative - underscore prefix
   ```
4. **Standard Library Interface Methods**:

   ```python
   def visit_ClassDef(self, Node):  # Correct - preserves AST visitor interface
   ```
5. **Avoid in All Other Cases**:

   ```python
   process_data()         # Incorrect - use ProcessData() instead
   user_input             # Incorrect - use UserInput instead
   ```

## Implementation Rules

[Context: Practical_Application]

### Module Declaration

[Pattern: Standard_Header]

```python
# File: ModuleName.py
# Path: Project/Component/ModuleName.py
# Standard: AIDEV-PascalCase-1.6
# Created: 2025-03-16
# Last Modified: 2025-03-16  11:45PM
# Description: Brief description of module functionality
```

### Import Statement Formatting

[Pattern: Import_Declaration]

Import statements follow Python conventions but should be organized in a specific order:

```python
# Standard library imports
import os
import sys
from datetime import datetime

# Third-party library imports
import numpy as np
from PySide6.QtWidgets import QApplication, QMainWindow

# Application imports
from Core.ConfigManager import ConfigManager
from Utils.ValidationUtils import ValidateInput
```

Group imports by type with a single blank line between groups. Within each group, order alphabetically. For multi-line imports, align the imported elements for visual clarity.

### Variable Naming

[Pattern: Variable_Declaration]

All variables, including function parameters, should use PascalCase:

```python
class ExampleClass:
    def ProcessData(self, InputText: str, MaxLength: int = 100) -> None:
        self.CurrentValue = InputText[:MaxLength]
        self.LastModified = self.GetTimestamp()
        
        # Local variables use PascalCase as well
        ResultString = f"Processed: {self.CurrentValue}"
        return ResultString
```

### Function and Method Naming

[Pattern: Function_Declaration]

All custom functions and methods should use PascalCase without underscore prefixes:

```python
def ProcessInput(Data: dict, DefaultMode: str = "Standard") -> str:
    """Process the input data and return a formatted string."""
    Result = FormatData(Data, Mode=DefaultMode)
    return Result
```

### Standard Library Interface Methods

[Pattern: Interface_Method]

Methods that override standard library or framework interfaces must maintain their original naming conventions to ensure compatibility:

```python
# AST visitor pattern
def visit_ClassDef(self, Node):
    """Process a class definition node."""
    # Use PascalCase for your own variables
    ClassName = Node.name
    BaseClasses = Node.bases
    
    # Call your custom methods with PascalCase
    return self.ProcessClass(ClassName, BaseClasses)

# Django model hooks
def save(self, *args, **kwargs):
    """Override Django model save method."""
    # Use PascalCase for your own variables
    CurrentTime = datetime.now()
    self.UpdatedAt = CurrentTime
    
    # Call parent method with original naming
    super().save(*args, **kwargs)
    
    # Call your custom methods with PascalCase
    self.LogChange(CurrentTime)
```

### Class Naming

[Pattern: Class_Declaration]

```python
class DataProcessor:
    """A class that processes various types of data."""
  
    def __init__(self):
        self.ProcessedItems = 0
```

### Constants

[Pattern: Constant_Declaration]

Constants should be defined using ALL_CAPS with underscore separation:

```python
MAX_ITEMS = 100               # Module-level constant
DEFAULT_TIMEOUT = 30          # Module-level constant
COLOR_DARK_BACKGROUND = QColor(53, 53, 53)  # GUI color constants

class Config:
    API_KEY = "abc123"        # Class-level constant
    DEFAULT_RETRY_COUNT = 3   # Class-level constant
```

### Global Variables

[Pattern: Global_Variable]

```python
g_ActiveSessions = {}   # Global with 'g' prefix
_GlobalRegistry = []    # Alternative style with underscore
```

### GUI-Specific Naming

[Pattern: GUI_Element_Naming]

GUI elements should follow PascalCase with their element type included in the name:

```python
# Widgets
MainWindow = QMainWindow()
SettingsButton = QPushButton("Settings")
UserNameLabel = QLabel("Username:")
PasswordInput = QLineEdit()

# Layouts
MainLayout = QVBoxLayout()
ButtonsLayout = QHBoxLayout()

# Actions and connections
SaveAction = QAction("Save", self)
SaveAction.triggered.connect(self.SaveDocument)

# Colors
BackgroundColor = QColor(240, 240, 240)
HighlightColor = QColor(42, 130, 218)
```

## Common Framework Integration Patterns

[Context: Framework_Integration]
[Priority: Medium]

### AST Module

```python
class CustomVisitor(ast.NodeVisitor):
    def visit_ClassDef(self, Node):  # Standard library method
        ClassName = Node.name        # Your variable -> PascalCase
        ParentClasses = []           # Your variable -> PascalCase
        
        for Base in Node.bases:      # Base is your variable -> PascalCase
            ParentClasses.append(self.GetClassName(Base))  # Your method -> PascalCase
            
        return self.ProcessClass(ClassName, ParentClasses)  # Your method -> PascalCase
```

### Django Framework

```python
class UserProfile(models.Model):
    name = models.CharField(max_length=100)  # Django model field
    email = models.EmailField(unique=True)   # Django model field
    
    def save(self, *args, **kwargs):  # Django method override
        CurrentTime = timezone.now()   # Your variable -> PascalCase
        self.UpdateLog(CurrentTime)    # Your method -> PascalCase
        super().save(*args, **kwargs)  # Call to Django method
        
    def UpdateLog(self, Timestamp):    # Your method -> PascalCase
        LogEntry = f"Updated user {self.name} at {Timestamp}"  # Your variable -> PascalCase
        logger.info(LogEntry)
```

### Flask Framework

```python
@app.route('/users/<user_id>')  # Flask decorator with its parameters
def get_user(user_id):          # Flask endpoint function
    UserID = int(user_id)       # Your variable -> PascalCase
    UserData = FetchUser(UserID)  # Your variable and method -> PascalCase
    return jsonify(UserData)
```

### SQLAlchemy ORM

```python
class User(Base):
    __tablename__ = 'users'  # SQLAlchemy attribute
    
    id = Column(Integer, primary_key=True)     # SQLAlchemy field
    username = Column(String, unique=True)     # SQLAlchemy field
    
    def __repr__(self):                        # Python dunder method
        UserString = f"User({self.username})"  # Your variable -> PascalCase
        return UserString
```

## Docstring Formatting

[Pattern: Documentation_Format]

Docstrings should be comprehensive and follow a consistent format:

### Module Docstrings

```python
"""
Module for handling configuration data.

This module provides functionality to load, save, and validate
configuration settings for the application.
"""
```

### Class Docstrings

```python
class ConfigManager:
    """A class that manages application configuration.
    
    This class provides methods for loading configuration from files,
    saving configuration to files, and validating configuration values.
    
    Attributes:
        DefaultConfig: The default configuration dictionary
        ConfigPath: Path to the configuration file
        IsModified: Flag indicating if config has been modified
    """
```

### Method Docstrings

```python
def ProcessData(self, InputData: dict, ValidateOnly: bool = False) -> bool:
    """Process the input data and update internal state.
    
    Args:
        InputData: Dictionary containing data to process
        ValidateOnly: If True, only validate but don't process
    
    Returns:
        bool: True if processing was successful, False otherwise
    
    Raises:
        ValueError: If InputData is not properly formatted
    """
```

## Module Organization

[Pattern: Code_Organization]

Modules should be organized in a consistent structure:

```python
# File header with timestamp information
# Module docstring

# Imports (organized as described above)

# Constants

# Global variables

# Classes
class MainClass:
    """Class docstring."""
    # Class constants
    
    # Initialization methods
    def __init__(self):
        pass
    
    # Public methods
    
    # Private methods

# Functions outside classes

# Main entry point (if applicable)
def Main():
    pass

if __name__ == "__main__":
    Main()
```

## Special Cases

[Pattern: Edge_Case_Handling]

### 1. Compound Special Terms

```python
AIConfig      # Correct
DbConnection  # Incorrect - should be DBConnection
GuiWindow     # Incorrect - should be GUIWindow
```

### 2. System Integration

```python
__init__.py   # System file - preserved
requirements.txt  # Configuration file - preserved
```

### 3. Multi-Word Variables

```python
UserInputValue  # Correct - each word capitalized
UserinputValue  # Incorrect - inconsistent capitalization
```

### 4. Parameters and Arguments

Function parameters follow the same PascalCase convention as all other variables:

```python
def CalculateTotal(PriceList: list, TaxRate: float = 0.08) -> float:
    """Calculate the total price including tax."""
    Subtotal = sum(PriceList)
    Total = Subtotal * (1 + TaxRate)
    return Total
```

When calling functions, maintain variable naming consistency:

```python
# Variables used as arguments should follow PascalCase
ItemPrices = [10.99, 24.50, 5.75]
LocalTaxRate = 0.095
FinalTotal = CalculateTotal(PriceList=ItemPrices, TaxRate=LocalTaxRate)
```

## File Naming

[Pattern: File_Naming]
[Priority: High]

All Python source files should follow PascalCase naming:

```
# Correct file names
DataProcessor.py
UserManager.py
ConfigSettings.py

# Incorrect file names
data_processor.py
user-manager.py
configsettings.py
```

When converting file names from kebab-case or snake_case to PascalCase:

```
parameter-editor-patch.py → ParameterEditorPatch.py
user_authentication.py → UserAuthentication.py
```

## Implementation and Tooling Guidelines

[Context: Automated_Enforcement]
[Priority: High]

### Symbol Tracking Requirements

Any implementation of this standard should track all symbol references throughout the codebase:

1. **Symbol Table Construction**: Tools must build a complete symbol table for each module
2. **Reference Tracking**: All references to a symbol must be identified and updated consistently
3. **Context Awareness**: Tools must differentiate between identical strings that represent different symbols

### Interface Method Detection

Validators must be able to distinguish between:

1. **Custom Methods**: Which should follow PascalCase
2. **Interface Override Methods**: Which should maintain original naming
3. **Framework-Specific Methods**: Which should maintain framework conventions

This can be implemented by:

1. **Class Inheritance Analysis**: Checking what classes a module extends
2. **Method Pattern Matching**: Recognizing patterns like `visit_*` for AST visitors
3. **Framework Detection**: Identifying imports from known frameworks (Django, Flask, etc.)

### Database Approach for Analysis

Complex codebases benefit from a database-driven approach to standards enforcement:

1. **Symbol Database**: Store all symbols, their types, and locations in a queryable database
2. **Dependency Mapping**: Track symbol dependencies and references
3. **Scope Awareness**: Maintain information about variable scopes and visibility
4. **Multi-file Analysis**: Consider cross-file symbol references

### Timestamp Format Specification

The "Last Modified" timestamp must adhere to this exact format:
```
# Last Modified: YYYY-MM-DD  HH:MM{AM|PM}
```

Note the following requirements:
1. **Double Space**: Exactly two spaces between the date and time
2. **12-hour Format**: Time must use 12-hour format with AM/PM suffix
3. **No Seconds**: Hours and minutes only, no seconds
4. **No Zero Padding**: No leading zero in hours (e.g., 9:30AM not 09:30AM)

## AI-Assisted Development Guidelines

[Context: AI_Integration]
[Priority: Medium]

When using AI assistants to generate or modify code:

1. **Upfront Standards Declaration**: Provide the AIDEV-PascalCase standard reference at the beginning of the session
2. **Incremental Validation**: Validate each code segment for compliance before proceeding
3. **Symbol Tracking**: Maintain a list of named symbols (variables, functions, classes) and ensure consistent naming
4. **Prompt Engineering**: Use prompts that explicitly mention naming conventions
5. **Framework Context**: Inform the AI about which frameworks you're using to ensure proper interface method handling

### Example AI Instruction

```
Please follow AIDEV-PascalCase Standards 1.6 for this code:
- Class names in PascalCase (e.g., DataProcessor)
- Custom function and method names in PascalCase (e.g., ProcessData)
- Standard library interface methods should maintain their original naming (e.g., visit_ClassDef)
- All variables should use PascalCase, even inside interface methods (e.g., UserInput)
- Constants in UPPERCASE_WITH_UNDERSCORES (e.g., MAX_RETRY_COUNT)
- File names in PascalCase (e.g., DataProcessor.py)
- Two spaces between date and time in timestamps
```

## Contextual References

[Pattern: Context_Awareness]
[Priority: High]

When modifying variables or functions, all references must be updated consistently:

```python
# INCORRECT - inconsistent references
UserName = GetInputFromConsole()
ProcessData(userName)  # Inconsistent capitalization
DisplayResults(UserName)

# CORRECT - consistent references
UserName = GetInputFromConsole()
ProcessData(UserName)
DisplayResults(UserName)
```

Special attention is required for references in:

1. **F-strings and String Literals**:
   ```python
   # When variable InputFile is renamed to InputFile, all references must update
   LogMessage = f"Processing file {InputFile} with options {Options}"
   ```

2. **Function and Method Calls**:
   ```python
   # When function process_data is renamed to ProcessData
   Result = ProcessData(InputValue)  # Not process_data(InputValue)
   ```

3. **Keyword Arguments**:
   ```python
   # When parameter input_text is renamed to InputText
   ParseDocument(InputText="sample")  # Not input_text="sample"
   ```

## Real-World Examples

### 1. AST Visitor with Program Variables

```python
class CustomVisitor(ast.NodeVisitor):
    def __init__(self):
        self.ClassCount = 0           # Your variable -> PascalCase
        self.FunctionCount = 0        # Your variable -> PascalCase
        self.Results = {}             # Your variable -> PascalCase
    
    def visit_ClassDef(self, Node):   # AST interface method -> original naming
        ClassName = Node.name         # Your variable -> PascalCase
        self.ClassCount += 1
        self.ProcessClassMembers(Node)  # Your method -> PascalCase
        self.generic_visit(Node)        # AST method -> original naming
    
    def visit_FunctionDef(self, Node): # AST interface method -> original naming
        FunctionName = Node.name       # Your variable -> PascalCase
        self.FunctionCount += 1
        self.Results[FunctionName] = self.AnalyzeFunction(Node)  # Your method -> PascalCase
        self.generic_visit(Node)       # AST method -> original naming
    
    def ProcessClassMembers(self, ClassNode):  # Your method -> PascalCase
        MemberCount = len(ClassNode.body)      # Your variable -> PascalCase
        return MemberCount
    
    def AnalyzeFunction(self, FunctionNode):   # Your method -> PascalCase
        ArgCount = len(FunctionNode.args.args) # Your variable -> PascalCase
        return {
            "Arguments": ArgCount,                    # Your dictionary key -> regular string
            "LineCount": self.CountLines(FunctionNode)  # Your method -> PascalCase
        }
    
    def CountLines(self, Node):      # Your method -> PascalCase
        EndLine = Node.end_lineno    # Your variable -> PascalCase
        StartLine = Node.lineno      # Your variable -> PascalCase
        return EndLine - StartLine + 1
```

### 2. Django Model with Program Variables

```python
class UserProfile(models.Model):
    username = models.CharField(max_length=100)    # Django field
    email = models.EmailField(unique=True)         # Django field
    
    def save(self, *args, **kwargs):               # Django method
        CurrentTime = timezone.now()               # Your variable -> PascalCase
        IsNewUser = not self.pk                    # Your variable -> PascalCase
        
        super().save(*args, **kwargs)              # Call to parent method
        
        if IsNewUser:
            self.CreateDefaultSettings()           # Your method -> PascalCase
        self.LogUserActivity("profile_updated", CurrentTime)  # Your method -> PascalCase
    
    def CreateDefaultSettings(self):               # Your method -> PascalCase
        DefaultTheme = "light"                     # Your variable -> PascalCase
        Settings = UserSettings(user=self, theme=DefaultTheme)  # Your variable -> PascalCase
        Settings.save()
    
    def LogUserActivity(self, ActivityType, Timestamp):  # Your method -> PascalCase
        LogEntry = UserLog(                        # Your variable -> PascalCase
            user=self,
            activity_type=ActivityType,            # Your parameter -> PascalCase
            timestamp=Timestamp                    # Your parameter -> PascalCase
        )
        LogEntry.save()
```

## Final Notes

The AIDEV-PascalCase 1.6 standard recognizes the need to balance visual clarity and distinction with the practical reality of working with Python's standard libraries and frameworks. By maintaining PascalCase for custom program variables even within interface methods, the standard achieves its goal of making developer-created elements immediately recognizable while still ensuring compatibility with the broader Python ecosystem.

---

Last Updated: 2025-03-16
Status: Active
Version: 1.6

================
File: cs/KnowledgeDatabaseIndex/20-20 STANDARD-AUTHORSHIP.md
================
# Authorship & Attribution
[Context: Transparency]

## Project Creator
**Author**: Herbert J. Bowers (Herb@BowersWorld.com)  
**Project**: OllamaModelEditor  
**Standards**: AIDEV-PascalCase-1.2

## Development Approach
This project represents the culmination of decades of design experience and software development practice, combining principles from typography, visual design, and modern programming paradigms.

The unique AIDEV-PascalCase standard employed throughout this codebase reflects both functional considerations and aesthetic principles derived from the author's background in professional typography and print design.

## AI Collaboration Statement
This project was developed through human-AI collaboration. The author maintains full responsibility for the content, design decisions, and standards implementation, while the formalization of documentation and portions of code implementation were enhanced through collaboration with Claude AI (Anthropic).

This collaboration exemplifies a new paradigm in software development where human expertise, creativity, and design philosophy are augmented by AI capabilities without sacrificing the distinctive personal signature of the creator.

## Citation & Use
When referencing this project or its distinctive standards, please include attribution to Herbert J. Bowers and acknowledge the AI-human collaborative methodology employed in its creation.

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/20-30 STANDARD-FoundationDesignPrinciples.md
================
# STANDARD-FoundationDesignPrinciples
**Created: March 22, 2025 1:30 PM**
**Last Modified: March 22, 2025  1:30PM**

[Context: Technical_Standards]
[Status: Active]
[Version: 1.0]

## 1. Core Design Principles

Project Himalaya and all its sub-projects must adhere to these fundamental design principles to ensure consistency, maintainability, and scalability across the entire ecosystem.

### 1.1 Documentation Standards

- **Markdown Format**: All documentation must be produced in Markdown (.md) format
- **Code Documentation**: All code documentation should use appropriate docstrings
- **Artifacts**: Session artifacts should be either Markdown documents or code artifacts
- **Metadata**: All documents must include standardized metadata headers
- **Living Documentation**: Documentation should evolve alongside the codebase

### 1.2 Code Organization

- **Modularity**: Code must be highly modular with clear separation of concerns
- **Module Size Limit**: No module should exceed ~500 lines of code
- **Interface Boundaries**: Modules should interact through well-defined interfaces
- **Component Isolation**: Components should be independently testable
- **Dependency Direction**: Dependencies should flow from higher to lower layers

### 1.3 Database Architecture

#### 1.3.1 Three-Tier Database Structure

1. **Himalaya Core Database**
   - Shared across all projects
   - Contains cross-project metadata
   - Manages project relationships
   - Tracks standards and validation rules
   - Provides centralized configuration

2. **Project-Specific Databases**
   - Named according to project (e.g., "AIDEV-Validate.db")
   - Stores project-specific operational data
   - Contains validation rules and standards for the project
   - Maintains project state information
   - Tracks component relationships

3. **User-Facing Help System**
   - Documentation and help content
   - User operation monitoring
   - Diagnostic information
   - Training content
   - Usage analytics

#### 1.3.2 Database Implementation Guidelines

- **SQLite for Lightweight Use**: Use SQLite for single-user scenarios
- **Schema Documentation**: All database schemas must be fully documented
- **Migration Strategy**: Include version-controlled migration scripts
- **Query Abstraction**: Use query builders or ORM where appropriate
- **Performance Optimization**: Include appropriate indexes and query optimization

### 1.4 Development Practices

- **Test-Driven Development**: Write tests before implementation
- **Documentation-Driven Development**: Document before coding
- **Continuous Validation**: Validate against standards continuously
- **Code Review**: All code should undergo review (human or AI)
- **Refactoring**: Regular refactoring to maintain code quality

## 2. Technical Standards

### 2.1 Coding Standards

- **AIDEV-PascalCase**: Follow AIDEV-PascalCase standards for all code
- **Python Style**: Follow PEP 8 where not superseded by AIDEV-PascalCase
- **Error Handling**: Use explicit error handling with appropriate types
- **Type Hints**: Use type hints consistently in all code
- **Comments**: Comment "why" not "what"

### 2.2 Architecture Patterns

- **Model-View-Controller**: Use MVC pattern for UI components
- **Repository Pattern**: Use repositories for data access
- **Service Layer**: Implement business logic in service classes
- **Dependency Injection**: Use DI for component dependencies
- **Command Pattern**: Use for operations that can be undone

### 2.3 File Organization

- **Project Structure**: Follow standard project structure for all projects
- **Configuration Files**: Use YAML for configuration
- **Resource Files**: Organize by type and purpose
- **Package Structure**: Group by feature, not by type
- **Test Organization**: Mirror production code structure in tests

## 3. Implementation Guidelines

### 3.1 Module Implementation

```python
# File: ModuleName.py
# Path: ProjectName/ComponentName/ModuleName.py
# Standard: AIDEV-PascalCase-1.6
# Created: YYYY-MM-DD
# Last Modified: YYYY-MM-DD  HH:MMAM/PM
# Description: Brief description of module functionality

"""
Detailed module documentation.

This module provides [functionality] for [purpose].
"""

# Imports should be organized in sections
import standard_library_module
from package import specific_module

# Constants should be at the top
MAX_ITEMS = 100
DEFAULT_TIMEOUT = 30

# Classes should be documented with clear interfaces
class ExampleClass:
    """
    A class that demonstrates proper implementation patterns.
    
    Attributes:
        AttributeName: Description of attribute
    """
    
    def __init__(self, Parameter1: str, Parameter2: int = 10):
        """Initialize the class with required parameters."""
        self.AttributeName = Parameter1
        self._PrivateAttribute = Parameter2
    
    def PublicMethod(self, InputValue: str) -> bool:
        """
        Process the input and return a result.
        
        Args:
            InputValue: Description of input
            
        Returns:
            bool: Description of return value
            
        Raises:
            ValueError: When input is invalid
        """
        # Implementation (less than 500 lines)
        return True

# Module functions should be well-documented
def UtilityFunction(Parameter: str) -> int:
    """
    Convert the parameter to a numerical value.
    
    Args:
        Parameter: Description of parameter
        
    Returns:
        int: Description of return value
    """
    # Implementation
    return 0
```

### 3.2 Database Interaction Example

```python
# File: DatabaseAccess.py
# Path: ProjectName/Data/DatabaseAccess.py
# Standard: AIDEV-PascalCase-1.6
# Created: YYYY-MM-DD
# Last Modified: YYYY-MM-DD  HH:MMAM/PM
# Description: Provides database access functions

import sqlite3
from typing import Dict, List, Any, Optional

class DatabaseManager:
    """Manages database connections and operations."""
    
    def __init__(self, DatabasePath: str):
        """Initialize with database path."""
        self.DatabasePath = DatabasePath
        self.Connection = None
        
    def Connect(self) -> None:
        """Establish database connection."""
        self.Connection = sqlite3.connect(self.DatabasePath)
        self.Connection.row_factory = sqlite3.Row
        
    def ExecuteQuery(self, Query: str, Parameters: tuple = ()) -> List[Dict[str, Any]]:
        """
        Execute a query and return results.
        
        Args:
            Query: SQL query string
            Parameters: Query parameters
            
        Returns:
            List of dictionaries representing rows
            
        Raises:
            sqlite3.Error: Database errors
        """
        if not self.Connection:
            self.Connect()
            
        Cursor = self.Connection.cursor()
        Cursor.execute(Query, Parameters)
        Results = [dict(row) for row in Cursor.fetchall()]
        return Results
        
    def Close(self) -> None:
        """Close the database connection."""
        if self.Connection:
            self.Connection.close()
            self.Connection = None
```

## 4. Application to Development Process

### 4.1 Planning and Documentation

1. Start with SPEC document adhering to template
2. Document interfaces and data models
3. Create PLAN document for implementation
4. Define database schema if applicable
5. Create test specifications

### 4.2 Implementation Sequence

1. Implement core data models and interfaces
2. Implement database components if needed
3. Implement business logic
4. Implement user interface components
5. Connect components through defined interfaces

### 4.3 Documentation Updates

1. Update interface documentation with any changes
2. Document implementation decisions
3. Create usage guides and examples
4. Update database schema documentation
5. Generate API documentation

## 5. Compliance Validation

All Project Himalaya components should be regularly validated against these principles:

1. **Code Validation**:
   - Ensure adherence to AIDEV-PascalCase
   - Check module size limits
   - Verify documentation completeness
   - Validate interface documentation

2. **Architecture Validation**:
   - Verify component dependencies
   - Check database usage patterns
   - Validate module boundaries
   - Review error handling

3. **Documentation Validation**:
   - Ensure documentation is in Markdown
   - Verify metadata headers
   - Check cross-referencing
   - Validate examples

## 6. Exceptions and Overrides

Any exceptions to these principles must be:
1. Documented with clear rationale
2. Approved by project leadership
3. Limited in scope
4. Regularly re-evaluated

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/20-40 SPEC-DocumentManager.md
================
# SPEC-DocumentManager
**Created: March 22, 2025 1:00 PM**
**Last Modified: March 22, 2025  1:00PM**

[Context: Component_Specification]
[Component: Layer1_DocumentManager]
[Status: Draft]
[Version: 0.1]

## 1. Component Overview

### 1.1 Purpose
DocumentManager provides a centralized system for storing, retrieving, and tracking project documentation with comprehensive metadata management, versioning, and search capabilities.

### 1.2 Key Capabilities
- File storage with consistent organization and naming
- Rich metadata management for all documents
- Search functionality across document content and metadata
- Change tracking and version history
- Categorization and tagging
- Reference linking between documents

### 1.3 Scope
**Includes:**
- Storage and retrieval of textual documentation
- Metadata indexing and management
- Content-based and metadata-based search
- Version tracking of documents
- Document categorization and organization
- Integration with StateManager for context tracking

**Excludes:**
- Binary file management (images, executables, etc.)
- Collaborative editing features
- Advanced document comparison
- Authentication and authorization (assumed to be handled externally)
- Web-based document viewing

## 2. Architecture

### 2.1 Component Structure
```
DocumentManager/
├── Core/
│   ├── DocumentStore.py
│   ├── MetadataManager.py
│   ├── SearchEngine.py
│   └── VersionTracker.py
├── Utils/
│   ├── FileUtils.py
│   ├── MetadataParser.py
│   └── PathManager.py
├── Models/
│   ├── Document.py
│   └── Metadata.py
└── __init__.py
```

### 2.2 Dependencies
- **Required Dependencies**
  - Python 3.8+: Runtime environment
  - SQLite: Metadata storage and indexing
  - Git (optional): For advanced versioning capabilities
  
- **Optional Dependencies**
  - Vector database (e.g., Chroma): For semantic search capabilities
  - Markdown parser: For structured document parsing
  - YAML parser: For metadata extraction

### 2.3 Integration Points
- **StateManager**: Shares document references for context tracking
- **StandardsValidator**: Validates document compliance with standards
- **AIInterface**: Provides documents for AI context
- **Project Filesystem**: Reads and writes to the project file structure

## 3. Data Models

### 3.1 Core Data Structures

```python
class Document:
    """Represents a project document with content and metadata."""
    id: str                  # Unique document identifier
    path: str                # Relative path within project
    filename: str            # Document filename
    content_type: str        # MIME type or format (e.g., "text/markdown")
    created_at: datetime     # Creation timestamp
    modified_at: datetime    # Last modification timestamp
    metadata: Dict[str, Any] # Document metadata
    content: str             # Document content
    tags: List[str]          # Categorization tags
    version: str             # Document version identifier
    references: List[str]    # References to other documents
```

```python
class Metadata:
    """Represents document metadata."""
    context: str             # Document context (e.g., "Component_Specification")
    component: str           # Related component (e.g., "Layer1_DocumentManager")
    status: str              # Document status (e.g., "Draft")
    version: str             # Document version
    author: str              # Document author
    created_at: datetime     # Creation timestamp
    modified_at: datetime    # Last modification timestamp
    custom_fields: Dict[str, Any]  # Custom metadata fields
```

```python
class SearchQuery:
    """Represents a search query against the document store."""
    query_text: str          # Free text query
    metadata_filters: Dict[str, Any]  # Metadata-based filters
    content_type: Optional[str]  # Filter by content type
    tags: Optional[List[str]]  # Filter by tags
    date_range: Optional[Tuple[datetime, datetime]]  # Filter by date range
    sort_by: str             # Field to sort results by
    sort_order: str          # "asc" or "desc"
    limit: int               # Maximum number of results
    offset: int              # Pagination offset
```

### 3.2 Configuration Schema
```python
{
    "storage": {
        "base_path": {
            "type": "string",
            "default": "./Project-Knowledge",
            "description": "Base path for document storage"
        },
        "use_git": {
            "type": "boolean",
            "default": false,
            "description": "Use Git for version control"
        }
    },
    "metadata": {
        "required_fields": {
            "type": "array",
            "default": ["context", "status", "version"],
            "description": "Metadata fields that must be present"
        },
        "index_fields": {
            "type": "array",
            "default": ["context", "component", "status", "tags"],
            "description": "Metadata fields to index for searching"
        }
    },
    "search": {
        "enable_semantic_search": {
            "type": "boolean",
            "default": false,
            "description": "Enable semantic search capabilities"
        },
        "vector_db_path": {
            "type": "string",
            "default": "./Project-Knowledge/.vector_db",
            "description": "Path to vector database"
        }
    }
}
```

## 4. API Definition

### 4.1 Public API

#### Store Document
```python
def StoreDocument(content: str, metadata: Dict[str, Any], path: Optional[str] = None) -> str:
    """
    Store a document in the document manager.
    
    Args:
        content: Document content as string
        metadata: Document metadata dictionary
        path: Optional relative path for storage (will be generated if not provided)
    
    Returns:
        str: Document ID
    
    Raises:
        ValueError: If required metadata is missing
        FileExistsError: If document already exists and overwrite=False
        IOError: If storage operation fails
    """
```

#### Retrieve Document
```python
def GetDocument(document_id: str) -> Document:
    """
    Retrieve a document by its ID.
    
    Args:
        document_id: Unique document identifier
    
    Returns:
        Document: The document object
    
    Raises:
        KeyError: If document with given ID doesn't exist
        IOError: If retrieval operation fails
    """
```

#### Find Documents
```python
def FindDocuments(query: SearchQuery) -> List[Document]:
    """
    Search for documents matching the query.
    
    Args:
        query: SearchQuery object with search parameters
    
    Returns:
        List[Document]: List of matching documents
    
    Raises:
        ValueError: If query parameters are invalid
    """
```

#### Update Document
```python
def UpdateDocument(document_id: str, content: Optional[str] = None, 
                  metadata: Optional[Dict[str, Any]] = None) -> Document:
    """
    Update an existing document.
    
    Args:
        document_id: Unique document identifier
        content: New content (if None, content is unchanged)
        metadata: New metadata (if None, metadata is unchanged)
    
    Returns:
        Document: Updated document
    
    Raises:
        KeyError: If document with given ID doesn't exist
        ValueError: If required metadata is missing
        IOError: If update operation fails
    """
```

#### Delete Document
```python
def DeleteDocument(document_id: str) -> bool:
    """
    Delete a document by its ID.
    
    Args:
        document_id: Unique document identifier
    
    Returns:
        bool: True if document was deleted, False otherwise
    
    Raises:
        IOError: If deletion operation fails
    """
```

#### Get Document History
```python
def GetDocumentHistory(document_id: str) -> List[Dict[str, Any]]:
    """
    Retrieve version history for a document.
    
    Args:
        document_id: Unique document identifier
    
    Returns:
        List[Dict[str, Any]]: List of version information dictionaries
        Each dictionary contains version, timestamp, and change summary
    
    Raises:
        KeyError: If document with given ID doesn't exist
        IOError: If history retrieval fails
    """
```

#### Add Document Tag
```python
def AddDocumentTag(document_id: str, tag: str) -> bool:
    """
    Add a tag to a document.
    
    Args:
        document_id: Unique document identifier
        tag: Tag to add
    
    Returns:
        bool: True if tag was added, False if tag already existed
    
    Raises:
        KeyError: If document with given ID doesn't exist
    """
```

#### Export Document
```python
def ExportDocument(document_id: str, export_format: str = "markdown", 
                  output_path: Optional[str] = None) -> str:
    """
    Export a document to a specific format and/or location.
    
    Args:
        document_id: Unique document identifier
        export_format: Format to export to ("markdown", "html", "text", etc.)
        output_path: Path to export to (if None, returns content as string)
    
    Returns:
        str: Path to exported file or document content as string
    
    Raises:
        KeyError: If document with given ID doesn't exist
        ValueError: If export format is unsupported
        IOError: If export operation fails
    """
```

### 4.2 Internal API

#### ParseMetadata
```python
def ParseMetadata(content: str) -> Dict[str, Any]:
    """
    Extract metadata from document content.
    
    Args:
        content: Document content as string
    
    Returns:
        Dict[str, Any]: Extracted metadata
    """
```

#### GenerateDocumentPath
```python
def GenerateDocumentPath(metadata: Dict[str, Any]) -> str:
    """
    Generate a storage path for a document based on its metadata.
    
    Args:
        metadata: Document metadata
    
    Returns:
        str: Generated relative path
    """
```

#### IndexDocument
```python
def IndexDocument(document: Document) -> bool:
    """
    Index a document for searching.
    
    Args:
        document: Document to index
    
    Returns:
        bool: True if indexing was successful
    """
```

#### CreateDocumentBackup
```python
def CreateDocumentBackup(document_id: str) -> str:
    """
    Create a backup of a document before modifications.
    
    Args:
        document_id: Document to back up
    
    Returns:
        str: Backup identifier
    """
```

## 5. Behaviors and Algorithms

### 5.1 Core Workflows

1. **Document Storage Workflow**
   - Parse and validate document metadata
   - Generate appropriate storage path
   - Store document content in filesystem
   - Index document metadata in database
   - Create document vectors for semantic search (if enabled)
   - Return document identifier

2. **Document Retrieval Workflow**
   - Validate document identifier
   - Retrieve document metadata from database
   - Load document content from filesystem
   - Return document object with content and metadata

3. **Document Search Workflow**
   - Parse search query
   - Convert to appropriate database query
   - Execute query against metadata index
   - For content searches, filter results by content matching
   - For semantic searches, query vector database
   - Combine and rank results
   - Return list of matching documents

4. **Document Update Workflow**
   - Validate document identifier
   - Create backup of existing document
   - Update content and/or metadata
   - Validate updated document
   - Save changes to filesystem and database
   - Update search indices
   - Return updated document

### 5.2 Key Algorithms

```python
# Metadata Extraction Algorithm
def ExtractMetadata(content: str) -> Dict[str, Any]:
    """Extract metadata from document content."""
    metadata = {}
    
    # Look for metadata in standard format
    lines = content.split('\n')
    in_header = False
    
    for line in lines:
        # Check for metadata header section
        if line.startswith('**Created:'):
            in_header = True
            # Extract creation timestamp
            timestamp_str = line.replace('**Created:', '').strip()
            metadata['created_at'] = ParseTimestamp(timestamp_str)
            continue
            
        # Look for context markers [Key: Value]
        if in_header and line.startswith('[') and ']' in line:
            # Extract key-value pair
            kv_content = line[1:line.find(']')].strip()
            if ':' in kv_content:
                key, value = kv_content.split(':', 1)
                metadata[key.lower()] = value.strip()
            continue
            
        # End of metadata section
        if in_header and line.startswith('##'):
            in_header = False
    
    # Extract title from first heading
    for line in lines:
        if line.startswith('# '):
            metadata['title'] = line[2:].strip()
            break
    
    return metadata
```

```python
# Document Path Generation Algorithm
def GenerateDocumentPath(metadata: Dict[str, Any]) -> str:
    """Generate logical file path from metadata."""
    # Start with document type
    doc_type = metadata.get('context', '').split('_')[0]
    path_components = []
    
    if doc_type:
        path_components.append(doc_type)
    
    # Add component if available
    component = metadata.get('component', '')
    if component:
        # Extract layer if present
        if component.startswith('Layer'):
            layer, comp_name = component.split('_', 1)
            path_components.append(layer)
            path_components.append(comp_name)
        else:
            path_components.append(component)
    
    # Add document title or filename
    title = metadata.get('title', 'Untitled').replace(' ', '-')
    filename = f"{metadata.get('document_type', 'DOC')}-{title}.md"
    
    # Construct path
    path = '/'.join(path_components)
    return f"{path}/{filename}"
```

### 5.3 Error Handling

| Error Condition | Handling Strategy | User Impact |
|-----------------|-------------------|-------------|
| Document not found | Return clear KeyError with ID | Operation fails with clear message |
| Invalid metadata | Validate before storage, return specific validation errors | Prevented from storing invalid document |
| Storage failure | Create temporary backup, retry with exponential backoff | May experience slight delay, but data preserved |
| Search index corruption | Rebuild affected indices, log warning | Search may return incomplete results |
| Duplicate document | Check before storage, offer overwrite option | Prompted to confirm overwrite |
| Permission issues | Check permissions before operations, provide clear error | Operation fails with permissions message |

## 6. Implementation Considerations

### 6.1 Performance Requirements
- Document retrieval in under 100ms for individual documents
- Search results in under 500ms for basic queries
- Support for at least 10,000 documents without performance degradation
- Efficient handling of documents up to 1MB in size
- Minimal memory footprint during operation

### 6.2 Security Considerations
- Validate all file paths to prevent path traversal attacks
- Sanitize metadata to prevent injection attacks
- Handle sensitive information in metadata appropriately
- Implement proper error handling to avoid information leakage
- Consider encryption for document storage if needed

### 6.3 Scalability Factors
- Use database indexing for efficient metadata queries
- Implement pagination for large result sets
- Consider sharding for very large document collections
- Design for future distributed operation if needed
- Optimize vector storage for semantic search scalability

## 7. Testing Strategy

### 7.1 Unit Tests
- Metadata parsing and validation
- Document storage and retrieval
- Path generation and normalization
- Search query parsing and execution
- Document versioning and history

### 7.2 Integration Tests
- Integration with filesystem
- Database operations and transactions
- Vector database integration
- Error handling and recovery
- Performance under load

### 7.3 Performance Tests
- Bulk document import performance
- Search performance with large document sets
- Concurrent operation handling
- Memory usage monitoring
- Database index efficiency

## 8. Development Roadmap

### 8.1 Implementation Phases

1. **Phase 1 (MVP)**
   - Basic document storage and retrieval
   - Simple metadata management
   - File-based organization
   - Basic search by metadata

2. **Phase 2 (Enhancement)**
   - Full text search capabilities
   - Version history tracking
   - Improved metadata extraction
   - Document tagging and categorization

3. **Phase 3 (Advanced Features)**
   - Semantic search integration
   - Reference linking between documents
   - Export to multiple formats
   - Automated organization and cleanup

### 8.2 Estimated Timeline
- **Phase 1**: 2 weeks
- **Phase 2**: 3 weeks
- **Phase 3**: 4 weeks

## 9. Open Questions and Decisions

| Question/Decision | Status | Resolution/Notes |
|-------------------|--------|------------------|
| Vector database selection | Open | Evaluating Chroma vs. Qdrant for semantic search |
| Metadata schema standardization | Open | Need to finalize required and optional fields |
| Git integration approach | Open | Considering direct git commands vs. GitPython library |
| Search algorithm optimization | Open | Evaluating performance tradeoffs of different approaches |
| Document size limits | Decided | 10MB maximum document size |

## 10. References

- Project Himalaya Knowledge Database Structure
- AIDEV-PascalCase Standards 1.6
- SQLite Documentation
- Chroma Vector Database Documentation
- Python Markdown Documentation

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers
================
File: cs/KnowledgeDatabaseIndex/20-50 STANDARD-DatabaseSchema.md
================
# STANDARD-DatabaseSchema
**Created: March 22, 2025 3:15 PM**
**Last Modified: March 22, 2025  3:15PM**

[Context: Technical_Standards]
[Status: Active]
[Version: 1.0]

## 1. Overview

This document defines the standards for database schema design across Project Himalaya components. It covers naming conventions, structure principles, and implementation guidelines for the three-tier database architecture.

## 2. Three-Tier Database Architecture

### 2.1 Himalaya Core Database

**Purpose**: Store shared data and cross-project information
**File Name**: `himalaya-core.db`
**Scope**: Available to all Project Himalaya components

**Core ### 7.2 Schema Documentation Format

Each schema definition must be accompanied by documentation:

```
Table: document
Purpose: Stores document content and metadata
Core Entity: Yes

Columns:
- document_id (TEXT): Unique identifier for the document
- title (TEXT): Document title
- content_type (TEXT): MIME type or format of the document
- content (TEXT): Actual document content
- created_at (TEXT): ISO 8601 timestamp of creation
- created_by (TEXT): User or system that created the document
- updated_at (TEXT): ISO 8601 timestamp of last update
- updated_by (TEXT): User or system that last updated the document
- version (INTEGER): Document version number
- is_active (INTEGER): Soft deletion flag (1=active, 0=deleted)
- metadata_json (TEXT): JSON object containing document metadata

Indexes:
- idx_document_created_at: For sorting by creation date
- idx_document_updated_at: For sorting by update date
- idx_document_title: For searching by title

Notes:
- metadata_json must be valid JSON or NULL
- content_type should follow standard MIME type format
```

## 8. Himalaya Core Database Schema

The following tables represent the minimum required schema for the Himalaya Core Database:

### 8.1 Projects Table

```sql
CREATE TABLE IF NOT EXISTS project (
    project_id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    description TEXT NOT NULL,
    path TEXT NOT NULL,
    created_at TEXT NOT NULL,
    updated_at TEXT NOT NULL,
    version INTEGER NOT NULL DEFAULT 1,
    is_active INTEGER NOT NULL DEFAULT 1,
    
    -- Constraints
    UNIQUE(name)
);
```

### 8.2 Components Table

```sql
CREATE TABLE IF NOT EXISTS component (
    component_id TEXT PRIMARY KEY,
    project_id_fk TEXT NOT NULL,
    name TEXT NOT NULL,
    type TEXT NOT NULL,
    layer INTEGER NOT NULL,
    description TEXT NOT NULL,
    created_at TEXT NOT NULL,
    updated_at TEXT NOT NULL,
    version INTEGER NOT NULL DEFAULT 1,
    is_active INTEGER NOT NULL DEFAULT 1,
    
    -- Constraints
    FOREIGN KEY (project_id_fk) REFERENCES project(project_id),
    UNIQUE(project_id_fk, name)
);
```

### 8.3 Standards Table

```sql
CREATE TABLE IF NOT EXISTS standard (
    standard_id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    version TEXT NOT NULL,
    description TEXT NOT NULL,
    content TEXT NOT NULL,
    created_at TEXT NOT NULL,
    updated_at TEXT NOT NULL,
    is_active INTEGER NOT NULL DEFAULT 1,
    
    -- Constraints
    UNIQUE(name, version)
);
```

### 8.4 Validation Rules Table

```sql
CREATE TABLE IF NOT EXISTS validation_rule (
    rule_id TEXT PRIMARY KEY,
    standard_id_fk TEXT NOT NULL,
    name TEXT NOT NULL,
    description TEXT NOT NULL,
    rule_type TEXT NOT NULL,
    rule_pattern TEXT NOT NULL,
    severity TEXT NOT NULL,
    created_at TEXT NOT NULL,
    updated_at TEXT NOT NULL,
    is_active INTEGER NOT NULL DEFAULT 1,
    
    -- Constraints
    FOREIGN KEY (standard_id_fk) REFERENCES standard(standard_id),
    UNIQUE(standard_id_fk, name)
);
```

## 9. Project-Specific Database Example

The following represents a starter schema for a project-specific database:

### 9.1 Project Configuration Table

```sql
CREATE TABLE IF NOT EXISTS project_config (
    config_id TEXT PRIMARY KEY,
    config_key TEXT NOT NULL,
    config_value TEXT NOT NULL,
    config_type TEXT NOT NULL,
    description TEXT NOT NULL,
    created_at TEXT NOT NULL,
    updated_at TEXT NOT NULL,
    
    -- Constraints
    UNIQUE(config_key)
);
```

### 9.2 Project Components Table

```sql
CREATE TABLE IF NOT EXISTS project_component (
    component_id TEXT PRIMARY KEY,
    component_name TEXT NOT NULL,
    component_type TEXT NOT NULL,
    status TEXT NOT NULL,
    version TEXT NOT NULL,
    created_at TEXT NOT NULL,
    updated_at TEXT NOT NULL,
    
    -- Constraints
    UNIQUE(component_name)
);
```

### 9.3 Operational Data Example

```sql
CREATE TABLE IF NOT EXISTS document_metadata (
    metadata_id TEXT PRIMARY KEY,
    document_id_fk TEXT NOT NULL,
    context TEXT NOT NULL,
    component TEXT,
    status TEXT NOT NULL,
    version TEXT NOT NULL,
    tags TEXT,
    created_at TEXT NOT NULL,
    updated_at TEXT NOT NULL,
    
    -- Constraints
    UNIQUE(document_id_fk)
);
```

## 10. Migration and Versioning

### 10.1 Schema Migration Format

Schema migrations should be defined as numbered SQL scripts:

```
001_initial_schema.sql
002_add_tags_table.sql
003_modify_document_table.sql
```

Each migration script should:

1. Begin with a version update:
   ```sql
   INSERT INTO schema_version (version, applied_at, description)
   VALUES (1, datetime('now'), 'Initial schema creation');
   ```

2. Include all schema changes:
   ```sql
   CREATE TABLE ...
   ALTER TABLE ...
   ```

3. Be idempotent when possible:
   ```sql
   CREATE TABLE IF NOT EXISTS ...
   ```

### 10.2 Migration Application Process

1. Check current schema version:
   ```sql
   SELECT max(version) FROM schema_version;
   ```

2. Apply each missing migration in sequence
3. Verify schema integrity after migration
4. Document any manual data transformations needed

## 11. References

- [20-30] STANDARD-FoundationDesignPrinciples
- [50-10] IMPL-DocumentManager
- SQLite Documentation: https://www.sqlite.org/docs.html
- PEP 249 – Python Database API Specification v2.0

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowerss**:
- `projects`: Register of all projects
- `components`: Component catalog
- `standards`: Standards definitions
- `validation_rules`: Shared validation rules
- `global_config`: System-wide configuration
- `users`: User profiles (if applicable)

### 2.2 Project-Specific Databases

**Purpose**: Store data specific to a single project
**File Name**: `[ProjectName].db` (e.g., `aidev-validate.db`)
**Scope**: Limited to the specific project

**Core Tables**:
- `project_config`: Project-specific configuration
- `project_components`: Project component instances
- `operational_data`: Project-specific data tables
- `project_logs`: Operation and activity logs

### 2.3 User Help System Database

**Purpose**: Store user-facing help content and usage data
**File Name**: `[ProjectName]-help.db` (e.g., `aidev-validate-help.db`)
**Scope**: User interface layer

**Core Tables**:
- `help_topics`: Help documentation entries
- `usage_logs`: User interaction logs
- `diagnostics`: System diagnostics data
- `feedback`: User feedback information

## 3. Naming Conventions

### 3.1 Database Files

- Use lowercase hyphenated names for database files
- Include project name for project-specific databases
- Use `.db` extension for SQLite databases

Examples:
- `himalaya-core.db`
- `aidev-validate.db`
- `ollama-model-editor.db`

### 3.2 Table Names

- Use lowercase snake_case for table names
- Use singular nouns for entity tables
- Use plural nouns for collection tables
- Use descriptive prefixes to group related tables

Examples:
- `document` (entity table)
- `validation_rules` (collection table)
- `doc_versions` (prefixed related table)
- `user_preferences` (prefixed related table)

### 3.3 Column Names

- Use lowercase snake_case for column names
- Include table name as prefix for ID columns
- Use standard suffixes for common column types
- Include data type hints for non-obvious types

Examples:
- `document_id` (primary key)
- `created_at` (timestamp)
- `is_active` (boolean)
- `user_id_fk` (foreign key)
- `config_json` (JSON data)

### 3.4 Index Names

- Use `idx_` prefix for regular indexes
- Use `unq_` prefix for unique indexes
- Use `fk_` prefix for foreign key constraints
- Include table name and indexed columns

Examples:
- `idx_document_created_at` (index on created_at)
- `unq_user_email` (unique constraint on email)
- `fk_document_user_id` (foreign key to user table)

## 4. Data Types and Constraints

### 4.1 Primary Data Types

| Logical Type | SQLite Type | Description | Example |
|--------------|-------------|-------------|---------|
| Integer | INTEGER | Whole numbers | `user_id INTEGER PRIMARY KEY` |
| String | TEXT | Text of any length | `name TEXT NOT NULL` |
| Boolean | INTEGER | 0 (false) or 1 (true) | `is_active INTEGER NOT NULL` |
| Float | REAL | Floating point numbers | `price REAL DEFAULT 0.0` |
| DateTime | TEXT | ISO 8601 format | `created_at TEXT` |
| Enumeration | TEXT | Constrained text values | `status TEXT CHECK(status IN ('draft','active','archived'))` |
| JSON | TEXT | JSON formatted data | `metadata TEXT` |
| UUID | TEXT | Universal unique identifier | `session_id TEXT` |

### 4.2 Constraints

All tables must include appropriate constraints:

- **Primary Keys**: Every table must have a primary key
- **Foreign Keys**: Use foreign key constraints for relationships
- **Not Null**: Apply to required fields
- **Default Values**: Provide sensible defaults when appropriate
- **Check Constraints**: Enforce value ranges and enumerations
- **Unique Constraints**: Apply to fields that must be unique

### 4.3 NULL Handling

- Avoid NULL values when possible
- Provide default values for nullable fields
- Document fields where NULL has specific meaning
- Use empty strings instead of NULL for text fields
- Use 0 instead of NULL for numeric fields when appropriate

## 5. Schema Structure

### 5.1 Table Organization

Organize tables by entity type and relationship:

1. **Core Entities**: Primary business objects
2. **Supporting Entities**: Objects that relate to core entities
3. **Junction Tables**: For many-to-many relationships
4. **Configuration Tables**: For system or component configuration
5. **Log Tables**: For activity tracking and history

### 5.2 Required Metadata Columns

All entity tables should include these standard columns:

- `[table_name]_id`: Primary key (INTEGER or TEXT for UUID)
- `created_at`: Creation timestamp (TEXT in ISO 8601)
- `created_by`: User or system that created the record (TEXT)
- `updated_at`: Last update timestamp (TEXT in ISO 8601)
- `updated_by`: User or system that last updated the record (TEXT)
- `version`: Record version number (INTEGER, starting at 1)
- `is_active`: Soft deletion flag (INTEGER, 0 or 1)

### 5.3 Relationship Pattern

For one-to-many relationships:
- Add foreign key in the "many" table referencing the "one" table
- Name the column `[referenced_table]_id_fk`
- Add appropriate indexes on foreign key columns

For many-to-many relationships:
- Create a junction table named `[table1]_[table2]`
- Include foreign keys to both tables
- Add a composite primary key across both foreign keys
- Consider adding metadata about the relationship

## 6. Implementation Guidelines

### 6.1 SQLite Best Practices

- Enable foreign key constraints:
  ```sql
  PRAGMA foreign_keys = ON;
  ```
- Use transactions for multi-statement operations:
  ```sql
  BEGIN TRANSACTION;
  -- Operations here
  COMMIT;
  ```
- Create proper indexes for query optimization
- Use prepared statements for all queries
- Implement proper error handling and retry logic

### 6.2 Schema Versioning

- Include a `schema_version` table in each database:
  ```sql
  CREATE TABLE schema_version (
      version INTEGER PRIMARY KEY,
      applied_at TEXT NOT NULL,
      description TEXT NOT NULL
  );
  ```
- Create migration scripts for schema updates
- Version your schema changes incrementally
- Document all schema changes

### 6.3 Data Access Layer

- Implement a data access layer (DAL) for each database
- Use the repository pattern to abstract database operations
- Centralize SQL queries in the DAL
- Implement proper connection management
- Use parameterized queries to prevent SQL injection

## 7. Database Schema Definition

### 7.1 Schema Definition Format

Define all database schemas using SQL DDL statements:

```sql
-- Table: document
CREATE TABLE IF NOT EXISTS document (
    document_id TEXT PRIMARY KEY,
    title TEXT NOT NULL,
    content_type TEXT NOT NULL,
    content TEXT NOT NULL,
    created_at TEXT NOT NULL,
    created_by TEXT NOT NULL,
    updated_at TEXT NOT NULL,
    updated_by TEXT NOT NULL,
    version INTEGER NOT NULL DEFAULT 1,
    is_active INTEGER NOT NULL DEFAULT 1,
    
    -- Metadata
    metadata_json TEXT,
    
    -- Validation
    CHECK (json_valid(metadata_json) OR metadata_json IS NULL)
);

-- Indexes
CREATE INDEX idx_document_created_at ON document(created_at);
CREATE INDEX idx_document_updated_at ON document(updated_at);
CREATE INDEX idx_document_title ON document(title);
```

### 7.2 Schema Documentation Format

Each schema definition must be accompanied by documentation:

```
Table
================
File: cs/KnowledgeDatabaseIndex/30-10 TEMPLATE-Component Plan.md
================
# PLAN-[ComponentName]
**Created: [Month Day, Year] [Time AM/PM]**
**Last Modified: [Month Day, Year] [Time AM/PM]**

[Context: Implementation_Plan]
[Component: Layer#_ComponentName]
[Status: Draft|In_Progress|Completed]
[Version: 0.1]

## 1. Implementation Overview

### 1.1 Objectives
- [Primary objective 1]
- [Primary objective 2]
- [Primary objective 3]

### 1.2 Deliverables
- [Deliverable 1]
- [Deliverable 2]
- [Deliverable 3]

### 1.3 Success Criteria
- [Criterion 1]
- [Criterion 2]
- [Criterion 3]

## 2. Technical Approach

### 2.1 Implementation Strategy
[Description of the overall implementation approach]

### 2.2 Key Technologies
- [Technology 1]: [Purpose/Rationale]
- [Technology 2]: [Purpose/Rationale]
- [Technology 3]: [Purpose/Rationale]

### 2.3 Architecture Implementation
[Specific details about implementing the architecture]

## 3. Implementation Phases

### 3.1 Phase 1: Core Structure
**Duration**: [Estimated time]

**Tasks**:
1. [Task 1.1]
2. [Task 1.2]
3. [Task 1.3]

**Deliverables**:
- [Deliverable 1.1]
- [Deliverable 1.2]

### 3.2 Phase 2: Basic Functionality
**Duration**: [Estimated time]

**Tasks**:
1. [Task 2.1]
2. [Task 2.2]
3. [Task 2.3]

**Deliverables**:
- [Deliverable 2.1]
- [Deliverable 2.2]

### 3.3 Phase 3: Enhanced Features
**Duration**: [Estimated time]

**Tasks**:
1. [Task 3.1]
2. [Task 3.2]
3. [Task 3.3]

**Deliverables**:
- [Deliverable 3.1]
- [Deliverable 3.2]

### 3.4 Phase 4: Optimization
**Duration**: [Estimated time]

**Tasks**:
1. [Task 4.1]
2. [Task 4.2]
3. [Task 4.3]

**Deliverables**:
- [Deliverable 4.1]
- [Deliverable 4.2]

## 4. Implementation Details

### 4.1 Module: [Module1]

#### Purpose
[Description of module purpose]

#### Classes and Functions
```python
# Class: [Class1]
class [Class1]:
    """[Description]"""
    
    def __init__(self, [params]):
        """Initialize the class."""
        # Implementation details
    
    def [method1](self, [params]):
        """[Description]"""
        # Implementation details

# Function: [Function1]
def [Function1]([params]):
    """[Description]"""
    # Implementation details
```

#### Implementation Notes
- [Note 1]
- [Note 2]

### 4.2 Module: [Module2]

#### Purpose
[Description of module purpose]

#### Classes and Functions
```python
# Class: [Class2]
class [Class2]:
    """[Description]"""
    
    def __init__(self, [params]):
        """Initialize the class."""
        # Implementation details
    
    def [method1](self, [params]):
        """[Description]"""
        # Implementation details

# Function: [Function2]
def [Function2]([params]):
    """[Description]"""
    # Implementation details
```

#### Implementation Notes
- [Note 1]
- [Note 2]

## 5. Dependencies and Integration

### 5.1 Component Dependencies
- [Dependency 1]: [How it will be integrated]
- [Dependency 2]: [How it will be integrated]

### 5.2 Integration Points
- [Integration Point 1]: [Implementation approach]
- [Integration Point 2]: [Implementation approach]

### 5.3 API Implementation
- [API Method 1]: [Implementation details]
- [API Method 2]: [Implementation details]

## 6. Testing Approach

### 6.1 Unit Testing
- [Test Area 1]: [Test approach]
- [Test Area 2]: [Test approach]

### 6.2 Integration Testing
- [Test Scenario 1]: [Test approach]
- [Test Scenario 2]: [Test approach]

### 6.3 Performance Testing
- [Test Type 1]: [Test approach]
- [Test Type 2]: [Test approach]

## 7. Timeline and Milestones

| Milestone | Description | Estimated Completion |
|-----------|-------------|----------------------|
| M1        | [Description] | [Date]             |
| M2        | [Description] | [Date]             |
| M3        | [Description] | [Date]             |
| M4        | [Description] | [Date]             |

## 8. Risk Management

### 8.1 Identified Risks
| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| [Risk 1] | High/Medium/Low | High/Medium/Low | [Strategy] |
| [Risk 2] | High/Medium/Low | High/Medium/Low | [Strategy] |
| [Risk 3] | High/Medium/Low | High/Medium/Low | [Strategy] |

### 8.2 Contingency Plans
- [Contingency 1]
- [Contingency 2]

## 9. Resource Requirements

### 9.1 Development Resources
- [Resource 1]
- [Resource 2]

### 9.2 External Dependencies
- [Dependency 1]
- [Dependency 2]

## 10. Documentation Plan

### 10.1 Code Documentation
- [Documentation Approach]

### 10.2 User Documentation
- [Documentation Approach]

### 10.3 API Documentation
- [Documentation Approach]

## 11. References

- [Reference 1]
- [Reference 2]
- [Reference 3]

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/30-20 SPEC-[ComponentName].md
================
# SPEC-[ComponentName]
**Created: [Month Day, Year] [Time AM/PM]**
**Last Modified: [Month Day, Year] [Time AM/PM]**

[Context: Component_Specification]
[Component: Layer#_ComponentName]
[Status: Draft|In_Review|Approved|Implemented]
[Version: 0.1]

## 1. Component Overview

### 1.1 Purpose
[A concise statement of what this component does and why it exists]

### 1.2 Key Capabilities
- [Capability 1]
- [Capability 2]
- [Capability 3]
- [Capability 4]

### 1.3 Scope
**Includes:**
- [Functionality within scope]
- [Functionality within scope]

**Excludes:**
- [Functionality outside scope]
- [Functionality outside scope]

## 2. Architecture

### 2.1 Component Structure
[Diagram or description of internal structure]

```
ComponentName/
├── Core/
│   ├── [Module1].py
│   └── [Module2].py
├── Utils/
│   └── [UtilModule].py
└── __init__.py
```

### 2.2 Dependencies
- **Required Dependencies**
  - [Dependency 1]: [Purpose]
  - [Dependency 2]: [Purpose]
  
- **Optional Dependencies**
  - [Dependency 3]: [Purpose]
  - [Dependency 4]: [Purpose]

### 2.3 Integration Points
- [System 1]: [Description of integration]
- [System 2]: [Description of integration]

## 3. Data Models

### 3.1 Core Data Structures
```python
class [DataModel1]:
    """[Description]"""
    [property1]: [type]  # [description]
    [property2]: [type]  # [description]
```

### 3.2 Configuration Schema
```python
{
    "[setting1]": {
        "type": "[type]",
        "default": [default_value],
        "description": "[description]"
    },
    "[setting2]": {
        "type": "[type]",
        "default": [default_value],
        "description": "[description]"
    }
}
```

## 4. API Definition

### 4.1 Public API

#### [Method1]
```python
def [Method1]([param1]: [type], [param2]: [type]) -> [return_type]:
    """
    [Description]
    
    Args:
        [param1]: [description]
        [param2]: [description]
    
    Returns:
        [return_type]: [description]
    
    Raises:
        [exception_type]: [description]
    """
```

#### [Method2]
```python
def [Method2]([param1]: [type], [param2]: [type]) -> [return_type]:
    """
    [Description]
    
    Args:
        [param1]: [description]
        [param2]: [description]
    
    Returns:
        [return_type]: [description]
    
    Raises:
        [exception_type]: [description]
    """
```

### 4.2 Internal API

#### [InternalMethod1]
```python
def [InternalMethod1]([param1]: [type]) -> [return_type]:
    """
    [Description]
    
    Args:
        [param1]: [description]
    
    Returns:
        [return_type]: [description]
    """
```

## 5. Behaviors and Algorithms

### 5.1 Core Workflows
1. [Workflow 1]
   - [Step 1]
   - [Step 2]
   - [Step 3]

2. [Workflow 2]
   - [Step 1]
   - [Step 2]
   - [Step 3]

### 5.2 Key Algorithms
```python
# [Algorithm 1 Name]
# [Description]
def [algorithm1]([inputs]):
    # [Step 1]
    # [Step 2]
    # [Step 3]
    return [result]
```

### 5.3 Error Handling
| Error Condition | Handling Strategy | User Impact |
|-----------------|-------------------|-------------|
| [Condition 1]   | [Strategy]        | [Impact]    |
| [Condition 2]   | [Strategy]        | [Impact]    |

## 6. Implementation Considerations

### 6.1 Performance Requirements
- [Requirement 1]
- [Requirement 2]

### 6.2 Security Considerations
- [Consideration 1]
- [Consideration 2]

### 6.3 Scalability Factors
- [Factor 1]
- [Factor 2]

## 7. Testing Strategy

### 7.1 Unit Tests
- [Test Area 1]
- [Test Area 2]

### 7.2 Integration Tests
- [Test Scenario 1]
- [Test Scenario 2]

### 7.3 Performance Tests
- [Test Type 1]
- [Test Type 2]

## 8. Development Roadmap

### 8.1 Implementation Phases
1. **Phase 1 (MVP)**
   - [Feature 1]
   - [Feature 2]

2. **Phase 2 (Enhancement)**
   - [Feature 3]
   - [Feature 4]

3. **Phase 3 (Optimization)**
   - [Enhancement 1]
   - [Enhancement 2]

### 8.2 Estimated Timeline
- **Phase 1**: [duration]
- **Phase 2**: [duration]
- **Phase 3**: [duration]

## 9. Open Questions and Decisions

| Question/Decision | Status | Resolution/Notes |
|-------------------|--------|------------------|
| [Question 1]      | Open   | [Notes]          |
| [Decision 1]      | Decided| [Resolution]     |

## 10. References

- [Reference 1]
- [Reference 2]

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/30-30 REF-[SubProjectName].md
================
# REF-[SubProjectName]
**Created: [Month Day, Year] [Time AM/PM]**
**Last Modified: [Month Day, Year] [Time AM/PM]**

[Context: SubProject_Reference]
[Status: Conceptual|Planning|Development|Active]
[Version: 0.1]

## 1. SubProject Overview

### 1.1 Purpose
[A concise statement of what this sub-project does and why it exists]

### 1.2 Key Capabilities
- [Capability 1]
- [Capability 2]
- [Capability 3]
- [Capability 4]

### 1.3 Relationship to Project Himalaya
[Description of how this sub-project fits into the broader Project Himalaya]

## 2. Current Status

### 2.1 Development Phase
- **Current Phase**: [Conceptual/Planning/Early Development/Active Development/Maintenance]
- **Completion Status**: [Estimated percentage complete]
- **Recent Updates**: [Summary of recent changes]

### 2.2 Active Components
- [Component 1]: [Status]
- [Component 2]: [Status]
- [Component 3]: [Status]

### 2.3 Current Priorities
1. [Priority 1]
2. [Priority 2]
3. [Priority 3]

## 3. Architecture

### 3.1 Component Structure
```
SubProjectName/
├── Core/
│   ├── [Module1].py
│   └── [Module2].py
├── Utils/
│   └── [UtilModule].py
└── __init__.py
```

### 3.2 Key Interfaces
- [Interface 1]: [Purpose and usage]
- [Interface 2]: [Purpose and usage]
- [Interface 3]: [Purpose and usage]

### 3.3 Dependencies
- **Project Himalaya Dependencies**
  - [Dependency 1]: [Purpose]
  - [Dependency 2]: [Purpose]

- **External Dependencies**
  - [Dependency 3]: [Purpose]
  - [Dependency 4]: [Purpose]

## 4. Implementation Details

### 4.1 Technology Stack
- [Technology 1]: [Purpose/Usage]
- [Technology 2]: [Purpose/Usage]
- [Technology 3]: [Purpose/Usage]

### 4.2 Key Algorithms
- [Algorithm 1]: [Purpose and brief description]
- [Algorithm 2]: [Purpose and brief description]

### 4.3 Data Models
- [Model 1]: [Description]
- [Model 2]: [Description]

## 5. Usage Examples

### 5.1 Basic Usage
```python
# Example of basic usage
from [SubProjectName] import [MainClass]

instance = [MainClass]()
result = instance.[method]([params])
```

### 5.2 Common Patterns
```python
# Example of a common usage pattern
from [SubProjectName] import [Utility]

# Pattern description and code example
data = [Utility].[function]([params])
processed = [process](data)
```

### 5.3 Integration Examples
```python
# Example of integration with other Project Himalaya components
from [OtherComponent] import [SomeClass]
from [SubProjectName] import [Integration]

# Integration pattern
integrated = [Integration].[method]([SomeClass]())
```

## 6. Development Roadmap

### 6.1 Upcoming Features
- [Feature 1]: [Description and target milestone]
- [Feature 2]: [Description and target milestone]
- [Feature 3]: [Description and target milestone]

### 6.2 Known Issues
- [Issue 1]: [Description and status]
- [Issue 2]: [Description and status]
- [Issue 3]: [Description and status]

### 6.3 Future Directions
- [Direction 1]: [Description]
- [Direction 2]: [Description]
- [Direction 3]: [Description]

## 7. Documentation

### 7.1 Key Documents
- [Document 1]: [Description and link]
- [Document 2]: [Description and link]
- [Document 3]: [Description and link]

### 7.2 API Reference
- [API Category 1]:
  - [Method 1]: [Brief description]
  - [Method 2]: [Brief description]

- [API Category 2]:
  - [Method 3]: [Brief description]
  - [Method 4]: [Brief description]

### 7.3 Guides and Tutorials
- [Guide 1]: [Description and link]
- [Guide 2]: [Description and link]

## 8. Team and Contacts

### 8.1 Key Contributors
- [Contributor 1]: [Role]
- [Contributor 2]: [Role]

### 8.2 Primary Contact
[Contact information for the primary point of contact]

## 9. References

- [Reference 1]
- [Reference 2]
- [Reference 3]

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/30-40 TEMPLATE-Project Himalaya: Session Continuity.md
================
# Project Himalaya: Session Continuity Document
**Created: March 22, 2025 11:45 AM**

## Current Session Overview

In this session, we established the foundational structure for Project Himalaya through creating comprehensive scope documentation and knowledge database organization. We focused on developing a bottom-up approach to address the growing complexity of the project.

## Key Accomplishments

1. Created comprehensive Project Himalaya scope definition document
2. Designed Project Knowledge Database structure and organization
3. Established a session continuity template (this document)
4. Defined component hierarchy and development sequence
5. Restructured the development approach from top-down to bottom-up

## Current Project Status

### Active Components
- **Project-wide**: Refining scope definition and knowledge structure
- **DocumentManager**: Preliminary planning phase
- **StateManager**: Conceptual design
- **AIDEV-PascalCase**: Standards defined (v1.6), implementation planning

### Development Focus
The current priority is establishing the infrastructure layer, beginning with:
1. DocumentManager - Core document storage and retrieval system
2. StateManager - Session state persistence and management
3. StandardsValidator - Validation against AIDEV-PascalCase standards

## Next Steps

### Immediate Actions (Next Session)
1. Begin detailed design of DocumentManager
   - Define data models
   - Create API specification
   - Plan storage strategy
   - Design metadata schema

2. Establish initial Project Knowledge Database
   - Create directory structure
   - Set up initial README files
   - Migrate existing documentation

3. Refine session continuity process
   - Test this template's effectiveness
   - Create automation for continuity document generation
   - Establish handoff procedures

### Short-Term Goals (1-2 Weeks)
1. Complete DocumentManager MVP implementation
2. Begin StateManager detailed design
3. Set up basic search capabilities for Project Knowledge Database
4. Create templates for all standard project documents

## Reference Information

### Project Structure
The project follows a layered architecture:
1. **Layer 1: Core Infrastructure**
   - DocumentManager
   - StateManager
   - StandardsValidator

2. **Layer 2: Communication Framework**
   - TaskManager
   - AIInterface
   - KnowledgeTransfer

3. **Layer 3: Development Tools**
   - CodeGenerator
   - TestFramework
   - DocumentationGenerator

4. **Layer 4: Applications**
   - OllamaModelEditor
   - AIDEV-Deploy

### Key Documents
- Project Himalaya Scope Definition
- Project Knowledge Database Structure
- AIDEV-PascalCase Standards 1.6
- AI-Human Collaborative Development Process Reference

### Development Principles
- Bottom-up development approach
- Component completion before progression
- Documentation-driven development
- Progressive enhancement
- Regular state persistence

## Technical Considerations

- **RAG Implementation**: Needs to support both document storage and effective retrieval
- **State Persistence**: Must handle unexpected session terminations
- **Standard Enforcement**: Should balance consistency with practical application
- **Knowledge Transfer**: Must facilitate seamless continuation between sessions

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/40-20 Project Knowledge Database Structure.md
================
# Project Knowledge Database Structure
**Created: March 22, 2025 11:15 AM**

## 1. Overview

The Project Knowledge Database serves as the central repository for all information related to Project Himalaya and its sub-projects. This document defines the structure, organization, and maintenance procedures for the knowledge database to ensure information is accessible, up-to-date, and properly cross-referenced.

## 2. Top-Level Organization

### 2.1 Directory Structure

```
Project-Knowledge/
├── 00-Project-Core/
│   ├── Vision-and-Roadmap/
│   ├── Standards/
│   ├── Architecture/
│   └── Processes/
├── 01-Infrastructure/
│   ├── DocumentManager/
│   ├── StateManager/
│   └── StandardsValidator/
├── 02-Communication/
│   ├── TaskManager/
│   ├── AIInterface/
│   └── KnowledgeTransfer/
├── 03-Development-Tools/
│   ├── CodeGenerator/
│   ├── TestFramework/
│   └── DocumentationGenerator/
├── 04-Applications/
│   ├── OllamaModelEditor/
│   └── AIDEV-Deploy/
├── 05-Reference/
│   ├── Technical-References/
│   ├── Design-Patterns/
│   └── External-Resources/
├── 06-Session-Archives/
│   ├── Cloud-Sessions/
│   └── Local-AI-Sessions/
└── 07-Templates/
    ├── Document-Templates/
    ├── Code-Templates/
    └── Process-Templates/
```

### 2.2 Primary Categories

1. **Project Core**: Foundational documents about Project Himalaya
2. **Infrastructure**: Documentation for Layer 1 components
3. **Communication**: Documentation for Layer 2 components
4. **Development Tools**: Documentation for Layer 3 components
5. **Applications**: Documentation for Layer 4 components
6. **Reference**: Supporting technical information
7. **Session Archives**: Records of development sessions
8. **Templates**: Standardized templates for various artifacts

## 3. File Naming and Organization

### 3.1 File Naming Convention

All files should follow this naming pattern:
- `[Type]-[Component]-[Description].md`

Examples:
- `README-DocumentManager.md`
- `SPEC-StateManager-APIDocs.md`
- `GUIDE-StandardsValidator-Usage.md`

### 3.2 Document Types

Primary document types include:
- `README`: Overview and entry point for a component
- `SPEC`: Detailed specifications
- `GUIDE`: Usage and implementation guides
- `TEMPLATE`: Reusable document template
- `REPORT`: Analysis or evaluation
- `PLAN`: Implementation or development plan
- `ARCHIVE`: Historical development session

### 3.3 Metadata Format

Each document should begin with consistent metadata:

```
# [Document Title]
**Created: [Month Day, Year] [Time AM/PM]**
**Last Modified: [Month Day, Year] [Time AM/PM]**

[Context: Category_Name]
[Component: Component_Name]
[Version: X.Y]
[Status: Draft|Review|Approved|Deprecated]
```

## 4. Sub-Project Organization

### 4.1 Component Documentation Structure

Each component (e.g., DocumentManager) should include:

1. **README**: Component overview
   - Purpose and objectives
   - Key capabilities
   - Dependencies
   - Quick start guide

2. **Specifications**:
   - Technical architecture
   - API documentation
   - Data models
   - Interface definitions

3. **Implementation**:
   - Code organization
   - Key algorithms
   - Design patterns
   - Performance considerations

4. **User Guides**:
   - Installation
   - Configuration
   - Operation
   - Troubleshooting

5. **Development History**:
   - Design decisions
   - Version changelog
   - Known issues
   - Future enhancements

### 4.2 Cross-References

All documents should include:
- Links to related documents
- References to dependencies
- Version compatibility information
- Contributors and stakeholders

## 5. Session Documentation

### 5.1 Cloud AI Session Records

For sessions with cloud-based AI (e.g., Claude):
- Session ID and date
- Participants (human and AI)
- Session objectives
- Key decisions and outcomes
- Action items and next steps
- Continuity information for future sessions

### 5.2 Local AI Session Records

For sessions with local AI models:
- Session ID and date
- Model used and configuration
- Task summary
- Implementation details
- Validation results
- Issues encountered and resolutions

### 5.3 Continuity Documentation

Special documents to maintain continuity:
- Current project status
- Active development threads
- Open questions and research areas
- Pending decisions
- References to most recent sessions

## 6. Knowledge Acquisition and Retrieval

### 6.1 Document Indexing

All documents should be indexed by:
- Component name
- Document type
- Creation/modification date
- Status
- Key topics
- Relevant standards

### 6.2 Search Mechanisms

Implement search capabilities:
- Full-text search across all documents
- Metadata-based filtering
- Component-specific searches
- Version-aware searching

### 6.3 Vector Database Integration

For AI-assisted retrieval:
- Document embeddings
- Semantic search capabilities
- Relevance ranking
- Context-aware retrieval

## 7. Maintenance Procedures

### 7.1 Document Lifecycle

1. **Creation**: Initial draft with basic metadata
2. **Review**: Verification of accuracy and completeness
3. **Publication**: Addition to the knowledge database
4. **Updates**: Regular revisions as needed
5. **Archiving**: Preservation of outdated but historically important documents

### 7.2 Update Frequency

- Core documentation: Review quarterly
- Component specifications: Update with each major change
- User guides: Update with each feature addition
- Session archives: Preserve permanently
- Templates: Review semi-annually

### 7.3 Quality Standards

All documents must:
- Follow consistent formatting
- Include complete metadata
- Provide accurate information
- Maintain clear organization
- Include appropriate cross-references
- Be written for the intended audience

## 8. Implementation Guide

### 8.1 Initial Setup

1. Create the directory structure as defined
2. Populate with existing documentation
3. Add README files for each component
4. Create index documents for each category
5. Establish version control for all documents

### 8.2 Migration Strategy

For existing project documentation:
1. Audit current documentation
2. Map to new structure
3. Update metadata and formatting
4. Add missing cross-references
5. Create indexes for improved navigation

### 8.3 RAG System Integration

1. Create document embeddings for all content
2. Establish update triggers for new content
3. Configure search and retrieval interfaces
4. Define context packaging for AI interactions
5. Implement relevance feedback mechanisms

## 9. Usage Patterns

### 9.1 For Human Developers

- Quick reference via README files
- Detailed implementation guidance via SPEC documents
- Process guidance via templates and guides
- Historical context via session archives

### 9.2 For AI Assistance

- Context loading via relevant document subsets
- Need-to-know filtering based on current task
- Standards reference for validation
- Template access for generation tasks

### 9.3 For Project Planning

- Status tracking via component documentation
- Progress assessment via version histories
- Dependency management via architecture documents
- Resource planning via specification documents

## 10. Example Documents

### 10.1 Component README Example

```markdown
# DocumentManager
**Created: March 25, 2025 9:30 AM**
**Last Modified: March 25, 2025 9:30 AM**

[Context: Infrastructure]
[Component: DocumentManager]
[Version: 0.1]
[Status: Draft]

## Overview

DocumentManager provides storage, retrieval, and tracking for project documentation with metadata management and search capabilities.

## Key Capabilities

- File storage with metadata
- Simple search functionality
- Change tracking
- Version control integration

## Dependencies

- None (foundation component)

## Quick Start

1. Installation: `pip install project-himalaya-docmanager`
2. Basic usage:
   ```python
   from himalaya.docmanager import DocumentManager
   
   # Initialize with project path
   doc_manager = DocumentManager("/path/to/project")
   
   # Store a document with metadata
   doc_id = doc_manager.store_document("example.md", 
                                      {"title": "Example", 
                                       "version": "1.0"})
   
   # Retrieve document
   content = doc_manager.get_document(doc_id)
   ```

## Documentation

- [Technical Specification](SPEC-DocumentManager-Technical.md)
- [API Reference](SPEC-DocumentManager-API.md)
- [User Guide](GUIDE-DocumentManager-Usage.md)
- [Development History](HISTORY-DocumentManager.md)
```

### 10.2 Session Continuity Document Example

```markdown
# Session Continuity: DocumentManager Implementation
**Created: March 26, 2025 2:15 PM**

[Context: Development_Session]
[Component: DocumentManager]
[Session_ID: CLOUD-20250326-001]

## Session Summary

In this session, we designed and began implementing the DocumentManager component. We established the core data model, API interface, and storage strategy.

## Key Accomplishments

1. Finalized the DocumentManager data model
2. Designed the core API interface
3. Implemented the basic storage and retrieval functions
4. Created unit tests for core functionality
5. Documented the public API

## Current Development Focus

We are currently working on:
1. Metadata indexing implementation
2. Search functionality
3. Change tracking mechanism
4. File version handling

## Next Steps

1. Complete metadata indexing implementation
2. Implement basic search capabilities
3. Add change tracking with timestamps
4. Create integration tests
5. Update documentation with examples

## Open Questions

- Should we use SQLite or a dedicated document database?
- How should we handle large binary files?
- What's the optimal metadata schema for cross-referencing?

## Reference Materials

- [Data Model Diagram](SPEC-DocumentManager-DataModel.md)
- [API Design Document](SPEC-DocumentManager-API.md)
- [Test Cases](TEST-DocumentManager-CoreFunctions.md)
```

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/40-30 STANDARD-MetadataSchema.md
================
# STANDARD-MetadataSchema
**Created: March 22, 2025 3:45 PM**
**Last Modified: March 22, 2025  3:45PM**

[Context: Knowledge_Organization]
[Status: Active]
[Version: 1.0]

## 1. Overview

This document defines the standard metadata schema for all Project Himalaya documentation. Consistent metadata ensures documents can be properly categorized, searched, and linked within the knowledge management system.

## 2. Document Metadata Format

### 2.1 Required Header Structure

Every document must begin with the following metadata header:

```markdown
# [Document Title]
**Created: [Month Day, Year] [Time AM/PM]**
**Last Modified: [Month Day, Year] [Time AM/PM]**

[Context: Category_Name]
[Status: Status_Value]
[Version: X.Y]
```

### 2.2 Document Title Format

- Use title case for all document titles
- Start with the document type prefix (e.g., "SPEC-", "GUIDE-")
- Keep titles concise but descriptive (under 60 characters)
- Do not include version numbers in titles

Examples:
- "SPEC-DocumentManager"
- "GUIDE-AICollaboration"
- "STANDARD-DatabaseSchema"

### 2.3 Timestamp Format

Timestamps must adhere to the following format:
- **Created/Modified Date**: Month Day, Year (e.g., "March 22, 2025")
- **Time**: 12-hour format with AM/PM (e.g., "3:45 PM")
- **Spacing**: Two spaces between date and time
- **No leading zeros**: Use "3:45 PM" not "03:45 PM"

Examples:
- "March 22, 2025  3:45 PM"
- "January 5, 2025  11:30 AM"

## 3. Metadata Fields

### 3.1 Core Metadata Fields

| Field | Required | Format | Description | Example |
|-------|----------|--------|-------------|---------|
| Title | Yes | Text | Document title | "STANDARD-MetadataSchema" |
| Created | Yes | Timestamp | Creation date and time | "March 22, 2025  3:45 PM" |
| Last Modified | Yes | Timestamp | Last modification date and time | "March 22, 2025  3:45 PM" |
| Context | Yes | Category_Name | Primary categorization | "Knowledge_Organization" |
| Status | Yes | Status_Value | Current document status | "Active" |
| Version | Yes | X.Y | Document version number | "1.0" |

### 3.2 Optional Metadata Fields

| Field | Format | Description | Example |
|-------|--------|-------------|---------|
| Component | Layer#_ComponentName | Related component | "Layer1_DocumentManager" |
| Author | Name | Document author | "Herbert J. Bowers" |
| Priority | Priority_Value | Implementation priority | "High" |
| Related | [DocID, DocID, ...] | Related documents | "[20-10, 20-30]" |
| Supersedes | DocID | Document this replaces | "20-20-v0.9" |
| Review_Date | Date | Next review date | "June 22, 2025" |

## 4. Metadata Field Values

### 4.1 Context Values

Valid context values categorize the document's primary purpose:

| Context Value | Description | Document Types |
|---------------|-------------|----------------|
| Project_Overview | Project-wide documents | README, VISION, SCOPE |
| Knowledge_Organization | Knowledge management documents | STRUCTURE, GUIDE |
| Technical_Standards | Technical requirements | STANDARD, RULE |
| Component_Specification | Component designs | SPEC, ARCH |
| Implementation_Plan | Implementation details | PLAN, IMPL |
| Testing_Documentation | Testing information | TEST, QA |
| Process_Documentation | Process descriptions | PROCESS, WORKFLOW |
| Project_Tracking | Project status tracking | STATUS, PROGRESS |
| Project_Governance | Decision making | DECISION, POLICY |
| Reference_Material | Reference information | REF, EXAMPLE |

### 4.2 Status Values

Document status indicates its current state in the lifecycle:

| Status Value | Description |
|--------------|-------------|
| Draft | Initial creation, not ready for review |
| In_Review | Currently being reviewed |
| Approved | Reviewed and approved |
| Active | Current and in use |
| Superseded | Replaced by newer version |
| Deprecated | No longer relevant but kept for reference |
| Archived | No longer active but preserved for history |
| Template | Base document for creating other documents |

### 4.3 Priority Values

Priority indicates implementation importance:

| Priority Value | Description |
|----------------|-------------|
| Critical | Blocking other work, immediate attention required |
| High | Important for current development phase |
| Medium | Needed but not immediately blocking |
| Low | Nice to have, can be deferred |

### 4.4 Version Numbering

Version numbers use the X.Y format:

- **X**: Major version, incremented for significant changes
- **Y**: Minor version, incremented for small updates
- Start with 0.1 for initial drafts
- Move to 1.0 for first approved/active version
- Use 2.0, 3.0, etc. for major revisions

## 5. In-Document Metadata

### 5.1 Section Tagging

Sections within documents can be tagged with metadata:

```markdown
## 3. Component Design
[Priority: High]
[Status: In_Progress]
```

### 5.2 Code Block Metadata

Code blocks can include metadata for language and context:

````markdown
```python
# File: example.py
# Context: Implementation_Example
def example_function():
    pass
```
````

### 5.3 Decision Point Tagging

Important decisions in documents should be tagged:

```markdown
[Decision: DECISION-20250322-1]
We will use SQLite for the initial database implementation based on simplicity and portability.
```

## 6. Cross-Document References

### 6.1 Document Reference Format

References to other documents should use:

1. **Document Number**: For numbered documents, e.g., `[10-20]`
2. **Document ID**: For specific document ID, e.g., `[SPEC-DocumentManager]`
3. **Document with Section**: For specific section, e.g., `[10-20 §3.2]`
4. **Decision Reference**: For decisions, e.g., `[DECISION-20250322-1]`

### 6.2 External Reference Format

External references should use:

```markdown
[Name of Resource](URL)
```

### 6.3 Component Reference Format

References to components should use:

```markdown
[Layer#_ComponentName]
```

## 7. Metadata Extraction and Processing

### 7.1 Extraction Algorithm

Metadata is extracted from documents using the following algorithm:

```python
def ExtractMetadata(content: str) -> Dict[str, Any]:
    """Extract metadata from document content."""
    metadata = {}
    
    # Look for metadata in standard format
    lines = content.split('\n')
    in_header = False
    
    for line in lines:
        # Check for metadata header section
        if line.startswith('**Created:'):
            in_header = True
            # Extract creation timestamp
            timestamp_str = line.replace('**Created:', '').strip()
            metadata['created_at'] = ParseTimestamp(timestamp_str)
            continue
            
        # Look for context markers [Key: Value]
        if in_header and line.startswith('[') and ']' in line:
            # Extract key-value pair
            kv_content = line[1:line.find(']')].strip()
            if ':' in kv_content:
                key, value = kv_content.split(':', 1)
                metadata[key.lower()] = value.strip()
            continue
            
        # End of metadata section
        if in_header and line.startswith('##'):
            in_header = False
    
    # Extract title from first heading
    for line in lines:
        if line.startswith('# '):
            metadata['title'] = line[2:].strip()
            break
    
    return metadata
```

### 7.2 Validation Rules

Metadata validation rules include:

1. All required fields must be present
2. Timestamps must follow the correct format
3. Context values must be from the approved list
4. Status values must be from the approved list
5. Version numbers must follow X.Y format
6. If Component is specified, it must follow correct format

### 7.3 Indexing Approach

Metadata is indexed for searching with:

1. Full-text indexing of document title and content
2. Specific indexes for each metadata field
3. Cross-reference indexing for document relationships
4. Timestamp indexes for chronological queries

## 8. Integration with Knowledge Database

### 8.1 Storage Format

Metadata is stored in the database as:

```sql
CREATE TABLE document_metadata (
    document_id TEXT PRIMARY KEY,
    title TEXT NOT NULL,
    created_at TEXT NOT NULL,
    modified_at TEXT NOT NULL,
    context TEXT NOT NULL,
    status TEXT NOT NULL,
    version TEXT NOT NULL,
    component TEXT,
    author TEXT,
    priority TEXT,
    metadata_json TEXT,
    
    -- Constraints
    CHECK (json_valid(metadata_json) OR metadata_json IS NULL)
);
```

### 8.2 Searching By Metadata

Standard queries for metadata include:

```sql
-- Find all active component specifications
SELECT document_id, title 
FROM document_metadata 
WHERE context = 'Component_Specification' 
AND status = 'Active';

-- Find recently modified documents
SELECT document_id, title, modified_at 
FROM document_metadata 
ORDER BY modified_at DESC 
LIMIT 10;

-- Find documents by component
SELECT document_id, title 
FROM document_metadata 
WHERE component = 'Layer1_DocumentManager';
```

### 8.3 Metadata Synchronization

Metadata synchronization ensures database consistency:

1. On document save, extract and update metadata
2. On document move/rename, update references
3. On document delete, mark as deleted but maintain metadata
4. Periodic validation to ensure metadata integrity

## 9. Metadata Templates

### 9.1 Standard Document Header

```markdown
# [Document Title]
**Created: [Month Day, Year] [Time AM/PM]**
**Last Modified: [Month Day, Year] [Time AM/PM]**

[Context: Category_Name]
[Component: Layer#_ComponentName]
[Status: Status_Value]
[Version: X.Y]
[Priority: Priority_Value]
```

### 9.2 Meeting Notes Metadata

```markdown
# NOTES-Meeting-[Topic]
**Created: [Month Day, Year] [Time AM/PM]**
**Last Modified: [Month Day, Year] [Time AM/PM]**

[Context: Project_Tracking]
[Status: Active]
[Meeting_Date: Month Day, Year]
[Participants: Name1, Name2, ...]
[Agenda: Brief agenda description]
```

### 9.3 Decision Document Metadata

```markdown
# DECISION-[Topic]
**Created: [Month Day, Year] [Time AM/PM]**
**Last Modified: [Month Day, Year] [Time AM/PM]**

[Context: Project_Governance]
[Status: Active]
[Decision_ID: DECISION-YYYYMMDD-N]
[Decision_Maker: Name]
[Decision_Type: Architectural|Technical|Process|Priority]
```

## 10. References

- [00-10] GUIDE-DocumentMap
- [40-20] STRUCTURE-KnowledgeDatabase
- [20-50] STANDARD-DatabaseSchema
- [30-series] Document Templates

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/50-10 IMPL-DocumentManager.md
================
# IMPL-DocumentManager
**Created: March 22, 2025 4:00 PM**
**Last Modified: March 22, 2025  4:00PM**

[Context: Implementation_Plan]
[Component: Layer1_DocumentManager]
[Status: In_Progress]
[Version: 0.1]
[Priority: High]

## 1. Implementation Overview

### 1.1 Component Purpose
The DocumentManager provides a centralized system for storing, retrieving, and tracking project documentation with comprehensive metadata management, versioning, and search capabilities.

### 1.2 Current Implementation Status
- Component specification completed [20-40]
- Database schema defined [20-50]
- Core data structures designed
- Implementation in progress

### 1.3 Implementation Priorities
1. Core document storage and retrieval
2. Metadata extraction and storage
3. Basic search capabilities
4. Version tracking mechanisms
5. Integration with other components

## 2. Architecture Implementation

### 2.1 Module Structure

```
DocumentManager/
├── Core/
│   ├── DocumentStore.py       # Document storage and retrieval
│   ├── MetadataManager.py     # Metadata extraction and management
│   ├── SearchEngine.py        # Search functionality
│   └── VersionTracker.py      # Version history tracking
├── Utils/
│   ├── FileUtils.py           # File system operations
│   ├── MetadataParser.py      # Metadata parsing
│   └── PathManager.py         # Path generation and management
├── Models/
│   ├── Document.py            # Document data model
│   └── Metadata.py            # Metadata data model
├── Database/
│   ├── DatabaseManager.py     # Database connection management
│   ├── QueryBuilder.py        # SQL query construction
│   └── Migrations/            # Database migration scripts
└── __init__.py                # Package initialization
```

### 2.2 Key Interfaces

```python
# Main DocumentManager interface
class DocumentManager:
    def __init__(self, ConfigPath: str = None):
        """Initialize DocumentManager with optional configuration path."""
        # Implementation
        
    def StoreDocument(self, Content: str, Metadata: Dict[str, Any], Path: Optional[str] = None) -> str:
        """Store a document and return its ID."""
        # Implementation
        
    def GetDocument(self, DocumentID: str) -> Document:
        """Retrieve a document by its ID."""
        # Implementation
        
    def FindDocuments(self, Query: SearchQuery) -> List[Document]:
        """
================
File: cs/KnowledgeDatabaseIndex/60-50a STANDARD-AutomatedTesting.md
================
# STANDARD-AutomatedTesting
**Created: March 24, 2025  3:15PM**
**Last Modified: March 24, 2025  3:15PM**

[Context: Technical_Standards]
[Component: Layer1_Testing]
[Status: Active]
[Version: 1.0]

## 1. Overview

This document defines the standards for automated testing within Project Himalaya and conforming projects. It covers the requirements for test automation, execution, reporting, and integration within the development workflow.

## 2. Automated Testing Requirements

### 2.1 Core Principles

- **Test-First Development**: Tests should be written before or alongside implementation
- **Comprehensive Coverage**: All components must have automated tests
- **Self-Verification**: Tests must assert their own success criteria
- **Output Standardization**: Test output must follow defined formats
- **Report Generation**: Tests must generate machine and human-readable reports
- **Continuous Testing**: Tests must be run automatically on code changes

### 2.2 Test Automation Levels

| Level | Description | Required Coverage | Example Components |
|-------|-------------|-------------------|-------------------|
| L1 | Unit tests | 90% of code | Core module functions |
| L2 | Integration tests | 80% of interfaces | Component interfaces |
| L3 | System tests | All critical paths | End-to-end workflows |
| L4 | Performance tests | Key operations | Database operations |

### 2.3 Test Environment Requirements

- Tests must create and manage their own isolated test environment
- Test environments must be clean before and after test execution
- Environment setup/teardown must be visible in test output
- Tests must not depend on global state or specific machine configurations
- Test outputs (reports, logs) must be stored outside of temporary test environments
- Test environments must be ephemeral while test artifacts must be persistent

## 3. Test Report Requirements

### 3.1 Report Structure

All automated test reports must follow this hierarchical structure:

```
1. Test Execution Summary
   - Test suite name and version
   - Execution timestamp
   - Overall status (Pass/Fail)
   - Test counts (Total, Passed, Failed, Skipped)
   - Execution duration

2. Environment Information
   - Test environment details
   - System configuration
   - Test data locations
   - Relevant configuration settings

3. Test Cases Detail
   For each test case:
   - Test ID and name
   - Status (Pass/Fail/Skip)
   - Execution time
   - Setup information
   - Actions performed
   - Assertions checked
   - Actual vs. expected results
   - Cleanup operations

4. Failure Analysis (if applicable)
   - Failed test details
   - Error messages
   - Stack traces
   - Relevant state information
   - Troubleshooting suggestions

5. Coverage Report
   - Code coverage statistics
   - Component coverage metrics
   - Coverage gaps identified

6. Artifacts References
   - Paths to generated artifacts
   - Log file locations
   - Screenshots (if relevant)
   - Database snapshots (if created)
```

### 3.2 Report Format Standards

#### 3.2.1 Plain Text Format

Text reports must follow these formatting guidelines:

- Clear section headers with separators (e.g., ==== or ----)
- Hierarchical indentation for nested information
- Consistent spacing for readability
- Table-like formatting for structured data
- Standard timestamp format: YYYY-MM-DD HH:MM:SS
- Maximum line width of 100 characters

Example text report formatting:

```
============================================================
TEST EXECUTION SUMMARY
------------------------------------------------------------
Test Suite: DatabaseIntegration Tests
Version: 1.0
Executed: 2025-03-24 10:15:30
Status: PASSED
Tests: 5 total, 5 passed, 0 failed, 0 skipped
Duration: 3.45 seconds

============================================================
ENVIRONMENT INFORMATION
------------------------------------------------------------
Test Directory: /tmp/test_dir_20250324_101530
Python Version: 3.9.12
Database Engine: SQLite 3.36.0

============================================================
TEST CASE DETAIL: test_InitializeProjectDatabase
------------------------------------------------------------
Status: PASSED
Duration: 1.25 seconds

  Setup:
  - Created temporary directory
  - Initialized mock configuration
  
  Actions:
  - Called InitializeProjectDatabase
  - Verified database file created
  - Checked table structure
  - Validated initial data
  
  Results:
  - Database created successfully
  - 5 required tables found
  - Schema validation passed
  - Initial data confirmed
  
  Cleanup:
  - Removed test database
  - Deleted temporary directory
```

#### 3.2.2 JSON Format

Machine-readable reports must be provided in JSON format with the following structure:

```json
{
  "test_suite": {
    "name": "String",
    "version": "String",
    "timestamp": "ISO8601 String"
  },
  "summary": {
    "status": "String",
    "total_tests": Integer,
    "passed_tests": Integer,
    "failed_tests": Integer,
    "skipped_tests": Integer,
    "duration_seconds": Float
  },
  "environment": {
    "test_dir": "String",
    "platform": "String",
    "dependencies": {}
  },
  "test_cases": [
    {
      "id": "String",
      "name": "String",
      "status": "String",
      "duration_seconds": Float,
      "setup": ["String"],
      "actions": ["String"],
      "assertions": ["String"],
      "results": ["String"],
      "cleanup": ["String"],
      "error": {
        "message": "String",
        "trace": "String"
      }
    }
  ],
  "coverage": {
    "statement_coverage": Float,
    "branch_coverage": Float,
    "function_coverage": Float,
    "line_coverage": Float
  },
  "artifacts": {
    "log_file": "String",
    "database_files": ["String"],
    "screenshots": ["String"]
  }
}
```

### 3.3 Report Storage

- Test reports must be saved in a standardized location outside of temporary test directories:
  ```
  ProjectRoot/
  ├── TestReports/
  │   ├── test_report_YYYYMMDD_HHMMSS.txt  (human-readable)
  │   └── test_report_YYYYMMDD_HHMMSS.json (machine-readable)
  ```
- Reports must use timestamped filenames
- Historical reports must be preserved
- Reports must be version controlled
- Reports must NOT be saved within temporary test directories that are cleaned up during tearDown()
- Test implementations must ensure report paths are absolute or resolve to locations outside test environments

## 4. Database Testing Standards

### 4.1 Database Testing Requirements

All database-related components must have automated tests that:

1. Create temporary database files in isolated test directories
2. Initialize database schema(s) with proper tables
3. Insert test data
4. Execute operations against the test database
5. Verify database state changes
6. Document database structure through test output
7. Clean up database files after test completion

### 4.2 Database Test Output

Database test reports must include:

1. **Database Creation Information**
   - Database file paths
   - Database version
   - Connection parameters
   - File sizes

2. **Schema Information**
   - List of all tables
   - For each table:
     - Column names and types
     - Primary and foreign keys
     - Constraints
     - Indexes

3. **Data Samples**
   - Row counts for each table
   - Sample data (up to 5 rows) for each table
   - Data statistics when relevant

4. **Operation Results**
   - Operations performed
   - Affected rows
   - Query performance metrics
   - Transaction details

Example database test output format:

```
Database: /tmp/test_dir/project.db
Size: 24.5 KB
Engine: SQLite 3.36.0

Table: users (3 columns, 5 rows)
  Schema:
    - user_id INTEGER PRIMARY KEY
    - username TEXT NOT NULL
    - created_at TEXT
  
  Data Sample (3 of 5 rows):
    1: (1, 'admin', '2025-03-24T10:15:30')
    2: (2, 'test_user', '2025-03-24T10:15:31')
    3: (3, 'demo_user', '2025-03-24T10:15:32')

Table: settings (4 columns, 2 rows)
  Schema:
    - setting_id INTEGER PRIMARY KEY
    - key TEXT NOT NULL
    - value TEXT
    - user_id INTEGER REFERENCES users(user_id)
  
  Data Sample (2 of 2 rows):
    1: (1, 'theme', 'dark', 1)
    2: (2, 'language', 'en', 1)
```

## 5. Test Implementation Guidelines

### 5.1 Using pytest Framework

pytest is the recommended testing framework for Project Himalaya and conforming projects. The following guidelines ensure optimal usage:

#### 5.1.1 Basic Test Structure

```python
# File: test_component_name.py
# Path: Tests/unit/test_component_name.py
# Standard: AIDEV-PascalCase-1.6
# Created: [Date]
# Last Modified: [Date]  [Time]
# Description: [Test description]

"""
Test module for [ComponentName].

This module contains pytest tests for verifying the functionality
of the [ComponentName] component.
"""

import pytest
# Other imports

# Use fixtures for test environment setup
@pytest.fixture
def test_environment():
    """Create test environment."""
    # Setup code
    yield  # This is where the test runs
    # Cleanup code

def test_functionality(test_environment):
    """Test specific functionality."""
    # Test implementation
    assert result == expected_result
```

#### 5.1.2 Using pytest Fixtures

Use pytest's built-in fixtures for common test resources:

```python
def test_database_operations(tmp_path):
    """Test database operations using pytest's tmp_path fixture."""
    # tmp_path is a pathlib.Path to a temporary directory
    db_path = tmp_path / "test.db"
    
    # Initialize database
    result = DatabaseIntegration.InitializeDatabase(db_path)
    assert result is True
    
    # The temporary directory is automatically cleaned up by pytest
```

#### 5.1.3 Custom Configuration

Create a `conftest.py` file to define project-wide pytest configuration:

```python
# File: conftest.py
# Path: Tests/conftest.py

def pytest_configure(config):
    """Configure pytest for Project Himalaya standards."""
    # Set report format and location
    config.option.htmlpath = "TestReports/report.html"
    
    # Register custom markers
    config.addinivalue_line("markers", 
                            "database: marks tests that require database setup")

@pytest.fixture(scope="session")
def himalaya_db():
    """Create a Himalaya test database for the test session."""
    # Setup code
    db_path = Path(tempfile.mkdtemp()) / "Himalaya.db"
    # Initialize database
    yield db_path
    # Cleanup code
```

### 5.2 Report Generation with pytest

Rather than implementing custom report capture in each test file, use pytest's built-in report generation capabilities:

#### 5.2.1 Using pytest-html Plugin

Install and configure the pytest-html plugin:

```bash
pip install pytest-html
```

Run tests with HTML report generation:

```bash
pytest --html=TestReports/report.html
```

#### 5.2.2 Creating Custom Text Reports

Use pytest hooks in conftest.py to generate custom reports:

```python
def pytest_terminal_summary(terminalreporter, exitstatus, config):
    """Generate custom reports after all tests complete."""
    # Create timestamped report filename
    from datetime import datetime
    from pathlib import Path
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_dir = Path("TestReports")
    report_dir.mkdir(exist_ok=True)
    report_path = report_dir / f"test_report_{timestamp}.txt"
    
    # Write report using test results
    with open(report_path, "w") as f:
        # Write summary header
        f.write("=" * 60 + "\n")
        f.write("TEST EXECUTION SUMMARY\n")
        f.write("-" * 60 + "\n")
        f.write(f"Timestamp: {datetime.now().isoformat()}\n")
        f.write(f"Status: {'PASSED' if exitstatus == 0 else 'FAILED'}\n")
        
        # Write test counts
        stats = terminalreporter.stats
        f.write(f"Tests: {sum(len(x) for x in stats.values())} total, "
                f"{len(stats.get('passed', []))} passed, "
                f"{len(stats.get('failed', []))} failed, "
                f"{len(stats.get('skipped', []))} skipped\n\n")
        
        # Write detail for each test
        for when in ('setup', 'call', 'teardown'):
            for report in terminalreporter.getreports(when):
                if report.nodeid:
                    f.write(f"{'=' * 60}\n")
                    f.write(f"TEST: {report.nodeid}\n")
                    f.write(f"{'-' * 60}\n")
                    f.write(f"Status: {report.outcome.upper()}\n")
                    if hasattr(report, 'longrepr'):
                        f.write(f"Details:\n{report.longrepr}\n\n")
        
    print(f"\nTest report saved to: {report_path}")
```

#### 5.2.3. Database Test Reports

For database-specific test details, use a custom fixture that captures database information:

```python
@pytest.fixture
def db_reporter():
    """Fixture to capture and report database information."""
    reports = []
    
    def _report_db(db_path, description=""):
        """Capture database information."""
        # Connect to database
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Get tables
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [row[0] for row in cursor.fetchall()]
        
        # Build report
        report = {
            "path": str(db_path),
            "description": description,
            "tables": {},
        }
        
        # Get schema and sample data for each table
        for table in tables:
            cursor.execute(f"PRAGMA table_info({table})")
            columns = cursor.fetchall()
            
            cursor.execute(f"SELECT * FROM {table} LIMIT 3")
            rows = cursor.fetchall()
            
            report["tables"][table] = {
                "columns": columns,
                "rows": rows,
                "row_count": len(rows)
            }
        
        reports.append(report)
        conn.close()
    
    yield _report_db
    
    # After test completes, write all reports to a file
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = Path("TestReports") / f"db_report_{timestamp}.txt"
    
    with open(report_path, "w") as f:
        for report in reports:
            f.write(f"Database: {report['path']}\n")
            f.write(f"Description: {report['description']}\n")
            f.write(f"{'-' * 60}\n")
            
            for table, data in report["tables"].items():
                f.write(f"Table: {table}\n")
                f.write(f"Columns: {len(data['columns'])}\n")
                f.write(f"Rows: {data['row_count']}\n")
                f.write("Schema:\n")
                
                for col in data["columns"]:
                    f.write(f"  - {col[1]} ({col[2]})\n")
                
                f.write("Sample data:\n")
                for row in data["rows"]:
                    f.write(f"  {row}\n")
                
                f.write("\n")
    
    print(f"Database report saved to: {report_path}")
```

Usage in tests:

```python
def test_database_init(tmp_path, db_reporter):
    """Test database initialization with reporting."""
    db_path = tmp_path / "test.db"
    
    # Initialize database
    result = DatabaseIntegration.InitializeDatabase(db_path)
    assert result is True
    
    # Report database state
    db_reporter(db_path, "After initialization")
```
    
    # Custom TestRunner for output capture
    class TestRunner:
        def __init__(self, ReportPath):
            self.ReportPath = ReportPath
            self.OutputStream = StringIO()
            self.OriginalStdout = sys.stdout
            
        def __enter__(self):
            # Redirect stdout to capture output
            sys.stdout = self.__class__.TeeOutput(
                self.OriginalStdout, 
                self.OutputStream
            )
            return self
            
        def __exit__(self, exc_type, exc_val, exc_tb):
            # Restore original stdout
            sys.stdout = self.OriginalStdout
            
            # Write captured output to file
            with open(self.ReportPath, 'w') as f:
                f.write(self.OutputStream.getvalue())
                
            print(f"\nTest report saved to: {self.ReportPath}")
            
        class TeeOutput:
            """Class to duplicate output to console and file."""
            def __init__(self, original_stdout, string_buffer):
                self.original_stdout = original_stdout
                self.string_buffer = string_buffer
                
            def write(self, text):
                self.original_stdout.write(text)
                self.string_buffer.write(text)
                
            def flush(self):
                self.original_stdout.flush()
    
    # Run tests with output capture
    with TestRunner(ReportPath):
        unittest.main(exit=False)
```

## 6. Implementation Roadmap

### 6.1 Phase 1: Basic Test Automation
- Implement test structure template
- Create automated test output capture
- Generate basic test reports

### 6.2 Phase 2: Enhanced Reporting
- Add detailed schema reporting
- Implement performance metrics
- Create JSON report format

### 6.3 Phase 3: Continuous Integration
- Integrate with CI/CD pipeline
- Implement automatic test execution
- Build test result dashboard

## 7. References

- [20-30] STANDARD-FoundationDesignPrinciples
- [60-10] PLAN-TestStrategy
- [60-50] TEMPLATE-TestCase
- [50-10] IMPL-DocumentManager

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers

================
File: cs/KnowledgeDatabaseIndex/60-50 TEMPLATE-TestCase.md
================
# TEMPLATE-TestCase
**Created: March 22, 2025 3:30 PM**
**Last Modified: March 22, 2025  3:30PM**

[Context: Testing_Documentation]
[Component: Layer#_ComponentName]
[Status: Template]
[Version: 1.0]

## 1. Test Information

**Test ID**: TEST-[Component]-[Functionality]-[Sequence]  
**Test Name**: [Descriptive test name]  
**Component**: [Component being tested]  
**Test Type**: [Unit|Integration|System|Performance|Security]  
**Priority**: [Critical|High|Medium|Low]  
**Created By**: [Author name]  
**Created Date**: [YYYY-MM-DD]  

## 2. Test Objective

[Clear statement of what this test is verifying]

## 3. Requirements Coverage

**Requirements Tested**:
- [Requirement ID 1]: [Brief description]
- [Requirement ID 2]: [Brief description]

**Related Documents**:
- [Document reference 1]
- [Document reference 2]

## 4. Test Environment

### 4.1 Hardware Requirements
- [Hardware requirement 1]
- [Hardware requirement 2]

### 4.2 Software Requirements
- Python version: [e.g., 3.8+]
- Database: [e.g., SQLite 3.35+]
- Libraries: [Required libraries]
- OS: [Operating system requirements]

### 4.3 Test Data
- [Description of test data]
- [Source of test data]
- [Preparation steps]

## 5. Test Setup

### 5.1 Prerequisites
1. [Prerequisite 1]
2. [Prerequisite 2]
3. [Prerequisite 3]

### 5.2 Setup Procedure
1. [Setup step 1]
2. [Setup step 2]
3. [Setup step 3]

### 5.3 Initial State
[Description of the system state before test execution]

## 6. Test Procedure

### 6.1 Test Steps

| Step | Action | Expected Result | Status |
|------|--------|-----------------|--------|
| 1 | [Detailed action] | [Expected outcome] | [Pass/Fail/Blocked] |
| 2 | [Detailed action] | [Expected outcome] | [Pass/Fail/Blocked] |
| 3 | [Detailed action] | [Expected outcome] | [Pass/Fail/Blocked] |
| 4 | [Detailed action] | [Expected outcome] | [Pass/Fail/Blocked] |
| 5 | [Detailed action] | [Expected outcome] | [Pass/Fail/Blocked] |

### 6.2 Cleanup Procedure
1. [Cleanup step 1]
2. [Cleanup step 2]
3. [Cleanup step 3]

## 7. Test Data and Parameters

### 7.1 Input Parameters

| Parameter | Value | Description |
|-----------|-------|-------------|
| [Param 1] | [Value] | [Description] |
| [Param 2] | [Value] | [Description] |
| [Param 3] | [Value] | [Description] |

### 7.2 Expected Results

| Check Point | Expected Value | Description |
|-------------|----------------|-------------|
| [Check 1] | [Value] | [Description] |
| [Check 2] | [Value] | [Description] |
| [Check 3] | [Value] | [Description] |

## 8. Edge Cases and Boundary Values

### 8.1 Edge Cases

| Case ID | Description | Expected Behavior |
|---------|-------------|-------------------|
| EC-1 | [Edge case description] | [Expected behavior] |
| EC-2 | [Edge case description] | [Expected behavior] |
| EC-3 | [Edge case description] | [Expected behavior] |

### 8.2 Boundary Values

| Parameter | Min Value | Max Value | Invalid Values |
|-----------|-----------|-----------|----------------|
| [Param 1] | [Min] | [Max] | [Invalid] |
| [Param 2] | [Min] | [Max] | [Invalid] |

## 9. Automation Information

### 9.1 Automation Status
- [ ] Not Automated
- [ ] Partially Automated
- [ ] Fully Automated

### 9.2 Automation Details
- **Script Location**: [Path to test script]
- **Framework**: [Test framework]
- **Execution Command**: [Command to run the test]
- **Dependencies**: [Dependencies for automation]

### 9.3 Execution Schedule
- **Frequency**: [Ad-hoc | Daily | Weekly | On commit]
- **Duration**: [Expected execution time]
- **Timeout**: [Maximum allowed time]

## 10. Test Results

### 10.1 Test Execution History

| Execution Date | Executed By | Environment | Result | Notes |
|----------------|-------------|-------------|--------|-------|
| [YYYY-MM-DD] | [Name] | [Env] | [Pass/Fail] | [Notes] |
| [YYYY-MM-DD] | [Name] | [Env] | [Pass/Fail] | [Notes] |

### 10.2 Defects Found

| Defect ID | Description | Severity | Status |
|-----------|-------------|----------|--------|
| [ID] | [Description] | [Severity] | [Status] |
| [ID] | [Description] | [Severity] | [Status] |

### 10.3 Test Metrics
- **Pass Rate**: [Percentage]
- **Average Execution Time**: [Time]
- **Flakiness Score**: [Score]

## 11. Additional Information

### 11.1 Notes and Assumptions
- [Note 1]
- [Note 2]
- [Assumption 1]
- [Assumption 2]

### 11.2 Attachments
- [Attachment 1 description]
- [Attachment 2 description]

### 11.3 Related Tests
- [Related test 1]
- [Related test 2]

## 12. Review Information

### 12.1 Review Status
- [ ] Not Reviewed
- [ ] Under Review
- [ ] Reviewed and Approved

### 12.2 Reviewers
- [Reviewer 1]
- [Reviewer 2]

### 12.3 Review Comments
- [Comment 1]
- [Comment 2]

---

## Example Test Case

Below is an example test case using this template:

## 1. Test Information

**Test ID**: TEST-DocumentManager-Storage-001  
**Test Name**: Store New Document with Valid Metadata  
**Component**: DocumentManager  
**Test Type**: Unit  
**Priority**: Critical  
**Created By**: Herbert J. Bowers  
**Created Date**: 2025-03-22  

## 2. Test Objective

Verify that the DocumentManager correctly stores a new document with valid metadata and returns a unique document identifier.

## 3. Requirements Coverage

**Requirements Tested**:
- REQ-DM-001: Store document with metadata
- REQ-DM-002: Generate unique document identifier

**Related Documents**:
- [50-10] IMPL-DocumentManager
- [20-50] STANDARD-DatabaseSchema

## 4. Test Environment

### 4.1 Hardware Requirements
- Standard development machine

### 4.2 Software Requirements
- Python 3.8+
- SQLite 3.35+
- Project dependencies installed

### 4.3 Test Data
- Sample markdown document with valid metadata
- Test metadata dictionary

## 5. Test Setup

### 5.1 Prerequisites
1. DocumentManager component installed
2. Test database initialized
3. Test directory structure created

### 5.2 Setup Procedure
1. Initialize DocumentManager with test configuration
2. Clear any existing test documents
3. Prepare test document content and metadata

### 5.3 Initial State
Empty document store with initialized database schema

## 6. Test Procedure

### 6.1 Test Steps

| Step | Action | Expected Result | Status |
|------|--------|-----------------|--------|
| 1 | Create document content with valid metadata | Content created successfully | |
| 2 | Call StoreDocument(content, metadata) | Function returns valid document ID | |
| 3 | Verify document exists in storage | Document file exists in expected location | |
| 4 | Verify metadata stored in database | Metadata record exists with correct values | |
| 5 | Retrieve document using returned ID | Document content matches original | |

### 6.2 Cleanup Procedure
1. Remove test document from storage
2. Delete metadata from database
3. Reset DocumentManager state

## 7. Test Data and Parameters

### 7.1 Input Parameters

| Parameter | Value | Description |
|-----------|-------|-------------|
| content | "# Test Document\n\nTest content" | Simple markdown document |
| metadata | {"title": "Test Document", "status": "Draft"} | Valid metadata dictionary |

### 7.2 Expected Results

| Check Point | Expected Value | Description |
|-------------|----------------|-------------|
| document_id | Non-empty string | Unique document identifier |
| file_exists | True | Document file exists in storage |
| metadata_record | Matches input | Metadata stored correctly |

## 8. Edge Cases and Boundary Values

### 8.1 Edge Cases

| Case ID | Description | Expected Behavior |
|---------|-------------|-------------------|
| EC-1 | Empty content with valid metadata | Raise ValueError |
| EC-2 | Valid content with empty metadata | Raise ValueError |
| EC-3 | Duplicate document storage | Generate unique ID, store both |

### 8.2 Boundary Values

| Parameter | Min Value | Max Value | Invalid Values |
|-----------|-----------|-----------|----------------|
| content | 1 character | 10MB | Empty string, None |
| metadata | Required fields only | 100 fields | Missing required fields |

## 9. Automation Information

### 9.1 Automation Status
- [x] Fully Automated

### 9.2 Automation Details
- **Script Location**: tests/document_manager/test_storage.py
- **Framework**: pytest
- **Execution Command**: pytest tests/document_manager/test_storage.py::test_store_document_valid_metadata
- **Dependencies**: pytest, pytest-mock

### 9.3 Execution Schedule
- **Frequency**: On commit
- **Duration**: ~500ms
- **Timeout**: 5s

---

*"Code is not merely functional—it is a visual medium that developers interact with for extended periods. The choices made in these standards prioritize the axis of symmetry, character distinction, readability at scale, and visual hierarchy."*

— Herbert J. Bowers


================================================================
List of Program Files
================================================================

Program files included:
./Core/DatabaseIntegration.py
./Core/GitHubManager.py
./Core/ProjectInitializer.py
./..Exclude/conftest.py
./..Exclude/directory-parser-fix (1).py
./..Exclude/run-tests-script.py
./..Exclude/TestDatabaseIntegration.py
./GUI/DirectoryEditor.py.py
./SysUtils/AIDEV-DocMManager_Setup.py
./SysUtils/BuildDirectories.py
./SysUtils/MyDiff.py
./TestDatabaseIntegration.py
./Tests/conftest.py
./Tests/Unit/test_database_integration.py
./Tests/Unit/test_integration.py
./Tests/Unit/test_project_setup.py
./Utils/ConfigManager.py
./Utils/DirectoryParser.py
Docs/AIDEV-ProjectSetup Project Structure.md
Docs/AIDEV-ProjectSetup: Session Continuity Document.md
Docs/AIDEV-ProjectSetup Test Automation.md
Docs/AIDEV-ProjectSetup: Test Plan.md
Docs/KnowledgeDatabaseIndex/00-00 INDEX-DocumentMaster.md
Docs/KnowledgeDatabaseIndex/00-10 GUIDE-DocumentMap.md
Docs/KnowledgeDatabaseIndex/00-20 STATUS-ProjectHimalaya.md
Docs/KnowledgeDatabaseIndex/00-40 LOG-Decisions.md
Docs/KnowledgeDatabaseIndex/00-60 GUIDE-ActiveSessions.md
Docs/KnowledgeDatabaseIndex/10-10 Project Himalaya: Strategic Roadmap & Evolution Plan.md
Docs/KnowledgeDatabaseIndex/10-20 Project Himalaya: Vision Document.md
Docs/KnowledgeDatabaseIndex/10-30 Project Himalaya: Comprehensive Scope Definition.md
Docs/KnowledgeDatabaseIndex/10-40 Project Himalaya: Comprehensive Scope Definition.md
Docs/KnowledgeDatabaseIndex/20-10 STANDARD-AIDEV-PascalCase Standards 1.6.md
Docs/KnowledgeDatabaseIndex/20-20 STANDARD-AUTHORSHIP.md
Docs/KnowledgeDatabaseIndex/20-30 STANDARD-FoundationDesignPrinciples.md
Docs/KnowledgeDatabaseIndex/20-40 SPEC-DocumentManager.md
Docs/KnowledgeDatabaseIndex/20-50 STANDARD-DatabaseSchema.md
Docs/KnowledgeDatabaseIndex/30-10 TEMPLATE-Component Plan.md
Docs/KnowledgeDatabaseIndex/30-20 SPEC-[ComponentName].md
Docs/KnowledgeDatabaseIndex/30-30 REF-[SubProjectName].md
Docs/KnowledgeDatabaseIndex/30-40 TEMPLATE-Project Himalaya: Session Continuity.md
Docs/KnowledgeDatabaseIndex/40-20 Project Knowledge Database Structure.md
Docs/KnowledgeDatabaseIndex/40-30 STANDARD-MetadataSchema.md
Docs/KnowledgeDatabaseIndex/50-10 IMPL-DocumentManager.md
Docs/KnowledgeDatabaseIndex/60-50a STANDARD-AutomatedTesting.md
Docs/KnowledgeDatabaseIndex/60-50 TEMPLATE-TestCase.md

There are 45 program files included in the Files section of the CodebaseSummary document.

================================================================
List of Documents
================================================================

Documents included:
Docs/AIDEV-ProjectSetup Project Structure.md
Docs/AIDEV-ProjectSetup: Session Continuity Document.md
Docs/AIDEV-ProjectSetup Test Automation.md
Docs/AIDEV-ProjectSetup: Test Plan.md
Docs/KnowledgeDatabaseIndex/00-00 INDEX-DocumentMaster.md
Docs/KnowledgeDatabaseIndex/00-10 GUIDE-DocumentMap.md
Docs/KnowledgeDatabaseIndex/00-20 STATUS-ProjectHimalaya.md
Docs/KnowledgeDatabaseIndex/00-40 LOG-Decisions.md
Docs/KnowledgeDatabaseIndex/00-60 GUIDE-ActiveSessions.md
Docs/KnowledgeDatabaseIndex/10-10 Project Himalaya: Strategic Roadmap & Evolution Plan.md
Docs/KnowledgeDatabaseIndex/10-20 Project Himalaya: Vision Document.md
Docs/KnowledgeDatabaseIndex/10-30 Project Himalaya: Comprehensive Scope Definition.md
Docs/KnowledgeDatabaseIndex/10-40 Project Himalaya: Comprehensive Scope Definition.md
Docs/KnowledgeDatabaseIndex/20-10 STANDARD-AIDEV-PascalCase Standards 1.6.md
Docs/KnowledgeDatabaseIndex/20-20 STANDARD-AUTHORSHIP.md
Docs/KnowledgeDatabaseIndex/20-30 STANDARD-FoundationDesignPrinciples.md
Docs/KnowledgeDatabaseIndex/20-40 SPEC-DocumentManager.md
Docs/KnowledgeDatabaseIndex/20-50 STANDARD-DatabaseSchema.md
Docs/KnowledgeDatabaseIndex/30-10 TEMPLATE-Component Plan.md
Docs/KnowledgeDatabaseIndex/30-20 SPEC-[ComponentName].md
Docs/KnowledgeDatabaseIndex/30-30 REF-[SubProjectName].md
Docs/KnowledgeDatabaseIndex/30-40 TEMPLATE-Project Himalaya: Session Continuity.md
Docs/KnowledgeDatabaseIndex/40-20 Project Knowledge Database Structure.md
Docs/KnowledgeDatabaseIndex/40-30 STANDARD-MetadataSchema.md
Docs/KnowledgeDatabaseIndex/50-10 IMPL-DocumentManager.md
Docs/KnowledgeDatabaseIndex/60-50a STANDARD-AutomatedTesting.md
Docs/KnowledgeDatabaseIndex/60-50 TEMPLATE-TestCase.md
